/home/hongjixu/miniconda3/envs/alpha-beta-crown/lib/python3.11/site-packages/onnx2pytorch/convert/layer.py:29: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025845868/work/torch/csrc/utils/tensor_numpy.cpp:206.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))
/home/hongjixu/miniconda3/envs/alpha-beta-crown/lib/python3.11/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: max
  sparse_alpha: true
  sparse_interm: true
  save_adv_example: false
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: false
  complete_verifier: bab
  enable_incomplete_verification: false
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/vggnet16
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "default_optimizer")'
  buffer_has_batchdim: false
  save_output: true
  output_file: /home/hongjixu/Verifier_Development/tests/gpu_tests/vnncomp23/vggnet16/master_outputs/6.pkl
  return_optimized_model: false
model:
  name: null
  path: null
  onnx_path: null
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: default_onnx_and_vnnlib_loader
  onnx_optimization_flags: none
  onnx_vnnlib_joint_optimization_flags: none
  check_optmized: false
  flatten_final_output: false
  optimize_graph: null
  with_jacobian: false
data:
  start: 6
  end: 7
  select_instance: null
  num_outputs: 1000
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: null
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 1
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: forward+backward
  init_bound_prop_method: same
  prune_after_crown: false
  optimize_disjuncts_separately: false
  crown:
    batch_size: 16
    max_crown_size: 1000000000
    relu_option: adaptive
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_alphas: false
    lr_decay: 0.98
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    disable_optimization: []
  invprop:
    apply_output_constraints_to: []
    tighten_input_bounds: false
    best_of_oc_and_no_oc: false
    directly_optimize: []
    oc_lr: 0.1
    share_gammas: false
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 10
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: true
    max_dim: 100
    reset_threshold: 1.0
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: false
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 360
  timeout_scale: 1
  max_iterations: -1
  override_timeout: null
  get_upper_bound: false
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: -1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
    _tmp_cuts: null
    fixed_cuts: false
    add_implied_cuts: false
    add_input_cuts: false
  branching:
    method: sb
    candidates: 3
    reduceop: min
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      branching_point_node: ''
      branching_point_db: []
      num_branches: 2
      branching_point_refinement: false
      filter: false
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      use_min: false
      loose_tanh_threshold: null
      dynamic: false
      dynamic_bbps: false
      dynamic_beta_heuristic: false
      beta_heuristic: false
      dynamic_options: [uniform, three_left, three_right]
    input_split:
      enable: true
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
      sb_coeff_thresh: 0.001
      sort_index: null
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 30.0
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: input_bab
  pgd_steps: 100
  pgd_restarts: 30
  pgd_batch_size: 100000000
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: default_adv_saver
  early_stop_condition: default_early_stop_condition
  adv_example_finalizer: default_adv_example_finalizer
  pgd_loss: default_pgd_loss
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0
  attack_func: attack_with_general_specs
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: true
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0
  print_verbose_decisions: false

Experiments at Wed Mar 27 04:36:56 2024 on huan-c4140-server
customized start/end sample from instance 6 to 7 in instances.csv
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 6 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx onnx/vgg16-7.onnx
Using vnnlib vnnlib/spec6_groom.vnnlib
Precompiled vnnlib file found at ../../vnncomp2023_benchmarks/benchmarks/vggnet16/vnnlib/spec6_groom.vnnlib.compiled
Loading onnx ../../vnncomp2023_benchmarks/benchmarks/vggnet16/onnx/vgg16-7.onnx wih quirks {}
Total VNNLIB file length: 1, max property batch size: 1, total number of batches: 1

Properties batch 0, size 1
Remaining timeout: 1191.7944197654724
##### Instance 0 first 10 spec matrices: 
tensor([[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.]]], dtype=torch.float64)
thresholds: tensor([0.], device='cuda:0') ######
torch allclose failed: norm 3.884386842401e-06
Model: BoundedModule(
  (/input.1): BoundInput(name=/input.1, inputs=[], perturbed=False)
  (/52): BoundParams(name=/52, inputs=[], perturbed=False)
  (/53): BoundParams(name=/53, inputs=[], perturbed=False)
  (/54): BoundParams(name=/54, inputs=[], perturbed=False)
  (/55): BoundParams(name=/55, inputs=[], perturbed=False)
  (/56): BoundParams(name=/56, inputs=[], perturbed=False)
  (/57): BoundParams(name=/57, inputs=[], perturbed=False)
  (/58): BoundParams(name=/58, inputs=[], perturbed=False)
  (/59): BoundParams(name=/59, inputs=[], perturbed=False)
  (/60): BoundParams(name=/60, inputs=[], perturbed=False)
  (/61): BoundParams(name=/61, inputs=[], perturbed=False)
  (/62): BoundParams(name=/62, inputs=[], perturbed=False)
  (/63): BoundParams(name=/63, inputs=[], perturbed=False)
  (/64): BoundParams(name=/64, inputs=[], perturbed=False)
  (/65): BoundParams(name=/65, inputs=[], perturbed=False)
  (/66): BoundParams(name=/66, inputs=[], perturbed=False)
  (/67): BoundParams(name=/67, inputs=[], perturbed=False)
  (/68): BoundParams(name=/68, inputs=[], perturbed=False)
  (/69): BoundParams(name=/69, inputs=[], perturbed=False)
  (/70): BoundParams(name=/70, inputs=[], perturbed=False)
  (/71): BoundParams(name=/71, inputs=[], perturbed=False)
  (/72): BoundParams(name=/72, inputs=[], perturbed=False)
  (/73): BoundParams(name=/73, inputs=[], perturbed=False)
  (/74): BoundParams(name=/74, inputs=[], perturbed=False)
  (/75): BoundParams(name=/75, inputs=[], perturbed=False)
  (/76): BoundParams(name=/76, inputs=[], perturbed=False)
  (/77): BoundParams(name=/77, inputs=[], perturbed=False)
  (/78): BoundParams(name=/78, inputs=[], perturbed=False)
  (/79): BoundParams(name=/79, inputs=[], perturbed=False)
  (/80): BoundParams(name=/80, inputs=[], perturbed=False)
  (/81): BoundParams(name=/81, inputs=[], perturbed=False)
  (/82): BoundParams(name=/82, inputs=[], perturbed=False)
  (/83): BoundParams(name=/83, inputs=[], perturbed=False)
  (/84): BoundParams(name=/84, inputs=[], perturbed=False)
  (/85): BoundParams(name=/85, inputs=[], perturbed=False)
  (/86): BoundParams(name=/86, inputs=[], perturbed=False)
  (/87): BoundParams(name=/87, inputs=[], perturbed=False)
  (/88): BoundParams(name=/88, inputs=[], perturbed=False)
  (/89): BoundParams(name=/89, inputs=[], perturbed=False)
  (/90): BoundParams(name=/90, inputs=[], perturbed=False)
  (/91): BoundParams(name=/91, inputs=[], perturbed=False)
  (/92): BoundParams(name=/92, inputs=[], perturbed=False)
  (/93): BoundParams(name=/93, inputs=[], perturbed=False)
  (/94): BoundParams(name=/94, inputs=[], perturbed=False)
  (/95): BoundParams(name=/95, inputs=[], perturbed=False)
  (/96): BoundParams(name=/96, inputs=[], perturbed=False)
  (/97): BoundParams(name=/97, inputs=[], perturbed=False)
  (/98): BoundParams(name=/98, inputs=[], perturbed=False)
  (/input): BoundConv(name=/input, inputs=[/input.1, /52, /53], perturbed=False)
  (/100): BoundRelu(name=/100, inputs=[/input], perturbed=False)
  (/input.4): BoundConv(name=/input.4, inputs=[/100, /54, /55], perturbed=False)
  (/102): BoundRelu(name=/102, inputs=[/input.4], perturbed=False)
  (/input.8): BoundConv(name=/input.8, inputs=[/102, /56], perturbed=False)
  (/104): BoundRelu(name=/104, inputs=[/input.8], perturbed=False)
  (/input.12): BoundConv(name=/input.12, inputs=[/104, /57], perturbed=False)
  (/106): BoundRelu(name=/106, inputs=[/input.12], perturbed=False)
  (/input.16): BoundConv(name=/input.16, inputs=[/106, /58], perturbed=False)
  (/108): BoundRelu(name=/108, inputs=[/input.16], perturbed=False)
  (/input.20): BoundConv(name=/input.20, inputs=[/108, /59, /60], perturbed=False)
  (/110): BoundRelu(name=/110, inputs=[/input.20], perturbed=False)
  (/input.24): BoundConv(name=/input.24, inputs=[/110, /61, /62], perturbed=False)
  (/112): BoundRelu(name=/112, inputs=[/input.24], perturbed=False)
  (/input.28): BoundConv(name=/input.28, inputs=[/112, /63], perturbed=False)
  (/114): BoundRelu(name=/114, inputs=[/input.28], perturbed=False)
  (/input.32): BoundConv(name=/input.32, inputs=[/114, /64], perturbed=False)
  (/116): BoundRelu(name=/116, inputs=[/input.32], perturbed=False)
  (/input.36): BoundConv(name=/input.36, inputs=[/116, /65], perturbed=False)
  (/118): BoundRelu(name=/118, inputs=[/input.36], perturbed=False)
  (/input.40): BoundConv(name=/input.40, inputs=[/118, /66, /67], perturbed=False)
  (/120): BoundRelu(name=/120, inputs=[/input.40], perturbed=False)
  (/input.44): BoundConv(name=/input.44, inputs=[/120, /68, /69], perturbed=False)
  (/122): BoundRelu(name=/122, inputs=[/input.44], perturbed=False)
  (/input.48): BoundConv(name=/input.48, inputs=[/122, /70, /71], perturbed=False)
  (/124): BoundRelu(name=/124, inputs=[/input.48], perturbed=False)
  (/input.52): BoundConv(name=/input.52, inputs=[/124, /72], perturbed=False)
  (/126): BoundRelu(name=/126, inputs=[/input.52], perturbed=False)
  (/input.56): BoundConv(name=/input.56, inputs=[/126, /73], perturbed=False)
  (/128): BoundRelu(name=/128, inputs=[/input.56], perturbed=False)
  (/input.60): BoundConv(name=/input.60, inputs=[/128, /74], perturbed=False)
  (/130): BoundRelu(name=/130, inputs=[/input.60], perturbed=False)
  (/input.64): BoundConv(name=/input.64, inputs=[/130, /75, /76], perturbed=False)
  (/132): BoundRelu(name=/132, inputs=[/input.64], perturbed=False)
  (/input.68): BoundConv(name=/input.68, inputs=[/132, /77, /78], perturbed=False)
  (/134): BoundRelu(name=/134, inputs=[/input.68], perturbed=False)
  (/input.72): BoundConv(name=/input.72, inputs=[/134, /79, /80], perturbed=False)
  (/136): BoundRelu(name=/136, inputs=[/input.72], perturbed=False)
  (/input.76): BoundConv(name=/input.76, inputs=[/136, /81], perturbed=False)
  (/138): BoundRelu(name=/138, inputs=[/input.76], perturbed=False)
  (/input.80): BoundConv(name=/input.80, inputs=[/138, /82], perturbed=False)
  (/140): BoundRelu(name=/140, inputs=[/input.80], perturbed=False)
  (/input.84): BoundConv(name=/input.84, inputs=[/140, /83], perturbed=False)
  (/142): BoundRelu(name=/142, inputs=[/input.84], perturbed=False)
  (/input.88): BoundConv(name=/input.88, inputs=[/142, /84, /85], perturbed=False)
  (/144): BoundRelu(name=/144, inputs=[/input.88], perturbed=False)
  (/input.92): BoundConv(name=/input.92, inputs=[/144, /86, /87], perturbed=False)
  (/146): BoundRelu(name=/146, inputs=[/input.92], perturbed=False)
  (/input.96): BoundConv(name=/input.96, inputs=[/146, /88, /89], perturbed=False)
  (/148): BoundRelu(name=/148, inputs=[/input.96], perturbed=False)
  (/input.100): BoundConv(name=/input.100, inputs=[/148, /90], perturbed=False)
  (/150): BoundRelu(name=/150, inputs=[/input.100], perturbed=False)
  (/input.104): BoundConv(name=/input.104, inputs=[/150, /91], perturbed=False)
  (/152): BoundRelu(name=/152, inputs=[/input.104], perturbed=False)
  (/input.108): BoundConv(name=/input.108, inputs=[/152, /92], perturbed=False)
  (/154): BoundRelu(name=/154, inputs=[/input.108], perturbed=False)
  (/155): BoundFlatten(name=/155, inputs=[/154], perturbed=False)
  (/input.112): BoundLinear(name=/input.112, inputs=[/155, /93, /94], perturbed=False)
  (/157): BoundRelu(name=/157, inputs=[/input.112], perturbed=False)
  (/158): BoundFlatten(name=/158, inputs=[/157], perturbed=False)
  (/input.116): BoundLinear(name=/input.116, inputs=[/158, /95, /96], perturbed=False)
  (/160): BoundRelu(name=/160, inputs=[/input.116], perturbed=False)
  (/161): BoundFlatten(name=/161, inputs=[/160], perturbed=False)
  (/162): BoundLinear(name=/162, inputs=[/161, /97, /98], perturbed=False)
)
Model prediction is: tensor([-5.95619202e+00, -1.59758282e+00, -2.03805423e+00, -5.37915897e+00,
        -4.58737516e+00, -4.87127686e+00, -4.50406265e+00,  3.62466955e+00,
        -1.62702537e+00, -3.82896566e+00, -2.57870603e+00, -2.41970730e+00,
        -2.86613035e+00, -2.93506145e+00, -3.19913983e+00, -3.29361081e+00,
        -1.15267193e+00, -4.55688047e+00, -3.13905287e+00, -2.28616643e+00,
        -5.81616306e+00, -4.72114277e+00, -3.46732497e+00, -3.28697586e+00,
        -5.96822453e+00, -5.19011974e+00, -6.34336996e+00, -3.74671054e+00,
        -2.47168493e+00, -3.97763515e+00, -4.39711237e+00, -3.71085143e+00,
        -3.62344170e+00, -3.18542147e+00, -3.79325604e+00, -4.45352221e+00,
        -1.27813256e+00, -3.24017572e+00, -4.90463781e+00, -4.31245565e-01,
        -4.70191908e+00, -4.94969225e+00, -6.29722595e+00, -4.23437166e+00,
        -4.07975864e+00, -1.86284029e+00, -2.73830104e+00, -4.40284872e+00,
        -4.66370392e+00, -2.57946444e+00, -1.32665038e+00, -2.95231223e+00,
        -5.69916582e+00, -4.93765640e+00, -2.35682321e+00, -3.51102948e+00,
        -1.04100299e+00, -3.44558477e+00, -6.70886040e+00, -2.74264073e+00,
         2.22053170e+00, -1.61295176e+00, -1.25136065e+00,  1.87327206e+00,
        -4.48731804e+00, -3.95971107e+00, -6.64932060e+00, -2.16877604e+00,
        -5.68339443e+00, -4.94322538e+00, -6.80322123e+00, -1.20304298e+00,
        -4.14865637e+00, -4.82037497e+00, -2.73707747e+00, -6.13082314e+00,
        -4.22863781e-01, -5.01833868e+00, -2.38076162e+00, -6.22772992e-01,
        -3.64948368e+00, -5.86134291e+00, -3.87153435e+00, -5.39186382e+00,
        -3.40858674e+00, -3.99748349e+00, -3.20865512e+00, -3.58855695e-01,
         1.07689881e+00, -2.32953620e+00,  1.52013934e+00, -2.87779236e+00,
        -4.24943590e+00, -4.17046785e-01,  6.27726436e-01, -3.41616035e+00,
        -2.27207756e+00, -5.51751137e+00, -3.96248364e+00, -4.52341557e+00,
        -1.73448205e+00,  9.78704333e-01, -2.04851246e+00, -5.82181025e+00,
        -1.26094723e+00, -3.84058452e+00, -2.68060279e+00, -2.19938278e+00,
        -2.07744837e+00, -3.29615092e+00, -4.10925055e+00, -5.84860468e+00,
         1.10413218e+01,  2.17617124e-01, -1.74348283e+00, -1.37514770e+00,
        -2.43570876e+00, -3.81520224e+00,  1.36544621e+00, -1.03118336e+00,
        -3.21246219e+00,  1.64573348e+00,  4.58065891e+00,  1.00164616e+00,
         4.36017609e+00, -9.85903561e-01, -2.77911377e+00, -6.18389559e+00,
        -4.29598808e+00, -3.15716624e+00, -1.45658529e+00, -7.02671671e+00,
        -5.15340328e+00, -6.15034151e+00, -4.87799597e+00, -4.58805418e+00,
        -2.83831763e+00, -2.64672899e+00, -5.92462111e+00, -5.87790203e+00,
        -4.97599459e+00, -5.21609116e+00, -5.84879923e+00, -4.78561687e+00,
        -5.90356588e+00, -2.29191780e+00, -5.92232037e+00, -4.57125282e+00,
        -4.45862961e+00, -7.27996302e+00, -3.78902149e+00,  2.88398623e+00,
         1.52582562e+00,  9.14074540e-01,  1.25583005e+00,  2.90003872e+00,
         8.10424536e-02,  4.36537647e+00, -1.61798388e-01, -3.42316747e+00,
        -1.10128634e-01, -1.89064968e+00, -1.21458364e+00, -3.14651179e+00,
        -4.35647106e+00, -3.70917892e+00, -4.52645254e+00, -3.53268576e+00,
        -2.73340940e+00,  1.35274577e+00, -1.31991363e+00,  2.48073149e+00,
        -1.34806252e+00, -2.78709555e+00, -3.82324338e+00, -4.32796764e+00,
        -4.01101685e+00,  4.01364595e-01, -3.82199836e+00, -1.19134533e+00,
        -2.60259199e+00,  9.19456929e-02, -2.56574225e+00, -2.50251532e-01,
        -1.45639622e+00, -1.19995260e+00, -4.56737764e-02,  1.27363658e+00,
        -2.06649870e-01, -9.91563261e-01, -1.11612439e+00, -4.87148643e-01,
        -1.76057220e+00, -2.02200723e+00, -2.93929291e+00,  2.02928281e+00,
        -8.87377858e-01, -1.20486867e+00, -2.57531929e+00, -2.00913399e-01,
        -1.33725786e+00, -2.72458267e+00, -3.67527437e+00,  2.67720532e+00,
        -6.68860078e-01, -1.83711612e+00, -2.31133986e+00, -4.12081385e+00,
        -2.73745966e+00, -5.54036188e+00, -6.31526470e+00, -1.35419357e+00,
        -1.90153956e+00, -3.82278323e+00, -2.10395288e+00, -4.06459957e-01,
        -3.60424310e-01,  4.34736460e-01, -1.88026202e+00, -1.87897611e+00,
         1.94389358e-01, -2.30200028e+00,  1.55922675e+00,  1.74862599e+00,
        -1.34670985e+00, -3.01458454e+00, -1.91001761e+00, -3.37359476e+00,
        -1.20088005e+00,  9.31922972e-01,  3.69846129e+00,  1.47334230e+00,
         2.49894410e-01, -1.17151570e+00, -2.64899755e+00, -2.25604272e+00,
        -1.71306431e+00, -1.59412622e+00,  3.88389170e-01,  1.24220443e+00,
         4.56810892e-02,  3.42052150e+00, -2.01010680e+00, -4.60993385e+00,
        -4.91149694e-01, -2.12335438e-01, -1.98985708e+00, -1.26541841e+00,
        -2.14877796e+00,  9.55543160e-01, -6.42159700e-01,  1.69188663e-01,
        -1.04065284e-01,  2.45060205e-01,  5.64721406e-01, -2.02730775e+00,
        -2.14941406e+00,  2.14417189e-01,  3.87486982e+00,  3.77981186e+00,
        -6.19455874e-01,  3.55654806e-01, -1.77726924e-01,  6.84530377e-01,
         7.69575059e-01,  3.43147135e+00,  2.74779034e+00,  2.00526547e+00,
        -1.46111643e+00, -4.26686144e+00, -2.73555326e+00, -4.57237196e+00,
        -6.02316284e+00, -3.81663346e+00, -5.94649458e+00, -5.20943451e+00,
        -5.33724403e+00, -2.10847735e+00, -4.66896439e+00, -2.30082655e+00,
        -3.54538321e+00, -2.54516244e+00, -3.22298288e+00,  2.84935117e+00,
        -1.92845309e+00, -1.25203788e+00, -6.64600945e+00, -4.34650278e+00,
        -4.10391188e+00, -4.31855488e+00, -5.13469362e+00, -4.32328415e+00,
        -4.33431578e+00, -2.21577144e+00, -5.00434971e+00, -3.40375042e+00,
        -4.66374922e+00, -2.04006910e+00, -4.50845718e+00, -2.96391463e+00,
        -4.97244215e+00, -3.82221651e+00, -3.26612043e+00, -5.63830912e-01,
        -3.10180926e+00, -5.06313705e+00,  4.80193496e-01, -1.20458400e+00,
        -1.90798545e+00,  1.34551764e+00, -3.16597843e+00, -2.01941061e+00,
        -2.98135805e+00, -2.31274033e+00, -2.06196332e+00, -3.21430707e+00,
        -4.21903133e+00, -3.91968942e+00, -2.80637407e+00, -3.07477307e+00,
        -3.74540949e+00, -1.16136801e+00, -3.53413129e+00, -3.02007884e-01,
        -1.36348760e+00, -7.11661220e-01, -2.22034860e+00, -6.50478542e-01,
        -6.73156679e-02, -2.75320339e+00, -5.08327675e+00, -4.15374994e+00,
         7.62664318e-01,  1.25206339e+00, -2.81856918e+00, -5.48912525e+00,
        -3.57933640e+00, -4.49247122e+00,  2.19822717e+00, -5.71995974e+00,
        -4.63725996e+00, -2.13154221e+00, -4.10732412e+00, -5.27463579e+00,
        -3.77590346e+00, -1.14382875e+00, -2.24057269e+00, -5.25461864e+00,
        -4.03548956e+00, -6.17629910e+00, -5.98127079e+00, -7.36867571e+00,
        -6.07322168e+00, -6.57030296e+00, -2.77394676e+00, -4.07474875e-01,
        -1.68103671e+00, -3.82167029e+00,  9.98194218e-01, -2.05711946e-01,
        -5.91602755e+00,  2.99331784e-01,  3.31600189e-01, -1.26200950e+00,
        -4.14663506e+00, -4.04647875e+00, -3.22845268e+00, -9.77101862e-01,
        -2.19022274e+00, -5.37733126e+00, -3.52943158e+00, -2.90313220e+00,
        -2.88461399e+00, -1.40881389e-01, -2.86582518e+00, -4.12533569e+00,
        -4.06835318e+00, -2.00562167e+00,  9.14690048e-02, -4.06396866e+00,
        -2.46849209e-01, -3.73166725e-02,  8.82241845e-01, -2.56854057e+00,
        -3.61586261e+00,  1.58718109e+00, -2.86845899e+00, -4.51487303e+00,
        -6.71976447e-01, -5.10444164e+00, -4.46515894e+00, -2.36157537e+00,
        -5.94988298e+00, -3.81006145e+00, -5.02236223e+00, -7.34441757e+00,
        -1.57003307e+00, -2.64963794e+00,  4.08510685e+00,  5.25017166e+00,
         8.79927444e+00,  9.22994900e+00,  3.92161489e+00, -4.93828630e+00,
        -5.15013885e+00, -3.18156791e+00,  8.18340206e+00, -4.34742749e-01,
        -3.99503732e+00,  4.52411741e-01, -4.98373175e+00,  5.78565598e+00,
        -2.64405131e-01,  3.05039310e+00,  5.43898582e-01,  5.97056389e+00,
         1.07441151e+00,  3.43076539e+00,  4.17400503e+00,  3.85376644e+00,
         6.74429607e+00, -1.03247941e+00,  9.20303166e-01,  2.31546283e+00,
         3.09907055e+00, -2.37315750e+00, -1.59808636e+00, -2.00686240e+00,
        -2.83480811e+00,  1.48114240e+00, -9.65100884e-01, -1.56910372e+00,
         8.91620731e+00,  3.89967775e+00, -5.00981748e-01,  2.43446589e+00,
        -2.46082258e+00, -2.35733938e+00,  2.95967126e+00,  7.39615297e+00,
         4.98392534e+00,  3.62214351e+00,  2.32300401e+00,  2.20675993e+00,
        -9.80854869e-01,  2.86251879e+00,  1.35741174e+00,  4.75637865e+00,
         5.50404727e-01, -2.73120451e+00, -1.18835223e+00,  6.79035902e+00,
         8.88475132e+00,  2.18794441e+00,  6.12501717e+00,  4.57920313e+00,
         6.81857204e+00,  1.39725304e+01, -3.47660720e-01,  6.30766201e+00,
        -4.54717922e+00,  1.72955883e+00,  3.19401097e+00,  1.37932897e+00,
        -4.95913804e-01, -9.93974566e-01,  5.38376570e-02,  3.54015398e+00,
        -6.84511542e-01,  1.73111284e+00,  1.17388592e+01, -5.19458294e-01,
        -2.28103828e+00,  1.46271825e+00,  3.76573730e+00, -1.82573879e+00,
         2.64997602e+00, -1.57153189e+00,  3.69964099e+00, -3.05242205e+00,
         2.38030434e+00,  5.28465450e-01,  5.21438234e-02,  4.13550377e+00,
        -4.71814156e+00, -2.11069083e+00,  7.43739939e+00,  8.55145168e+00,
        -1.92441607e+00, -3.48172927e+00,  2.88428688e+00,  2.97251076e-01,
         8.25458229e-01, -3.43273616e+00,  5.78664970e+00,  1.30590963e+00,
         4.75542402e+00,  2.43150997e+00,  5.51014948e+00,  5.65756702e+00,
        -6.86516285e-01,  5.68939543e+00,  4.09970474e+00,  8.90974903e+00,
         3.45946693e+00,  2.18403482e+00, -2.66594625e+00, -1.47690415e+00,
        -1.27931130e+00,  7.24571371e+00, -4.46813488e+00, -1.51723838e+00,
         3.56876969e+00,  8.75300884e+00,  2.55587959e+00,  4.87236309e+00,
         2.10082769e+00, -4.70669794e+00, -9.38242435e-01, -1.13291478e+00,
         1.21823192e+00,  3.93389344e+00,  4.07068551e-01,  4.51047134e+00,
        -9.05425012e-01, -1.88128448e+00,  1.35575938e+00, -2.17638731e-01,
         3.48325396e+00,  5.18246746e+00,  1.53091681e+00,  4.28364325e+00,
         2.70741081e+00, -7.92815089e-01, -1.67466581e+00, -6.51108646e+00,
        -5.03657770e+00, -3.71149850e+00, -2.26224422e+00, -1.88532329e+00,
        -3.03797865e+00,  7.60242319e+00,  7.25498486e+00,  6.67022526e-01,
        -3.76011324e+00,  6.21026695e-01,  2.77384567e+00, -5.84251451e+00,
        -1.34079874e+00,  2.77293658e+00, -2.78671056e-01,  5.04304361e+00,
         1.05499735e+01, -2.89366508e+00, -1.35522568e+00,  2.84653163e+00,
        -1.19740987e+00, -2.38525141e-02,  1.25325394e+01,  3.45685458e+00,
        -7.10664690e-01, -2.97118735e+00,  6.06956005e-01,  3.70707011e+00,
         1.33815575e+00, -4.90664577e+00,  8.68927765e+00, -1.66533756e+00,
         4.46754313e+00,  2.43049800e-01,  1.88004541e+00, -9.45532501e-01,
         4.56598616e+00, -1.87636209e+00, -4.72736979e+00,  1.14561915e+00,
         6.50210261e-01,  7.50736856e+00,  1.48096857e+01,  4.97541285e+00,
         2.29321551e+00, -3.70093250e+00,  5.81301785e+00,  1.90383792e+00,
         7.90068913e+00,  1.17167978e+01, -2.54695988e+00,  2.09371591e+00,
         8.97942424e-01,  5.39621115e+00,  7.17261076e-01,  7.79229784e+00,
        -4.97544193e+00,  1.12616844e+01,  7.17249107e+00, -6.20367765e+00,
         9.78222907e-01,  5.00525236e-02,  1.61437023e+00, -4.97036409e+00,
        -2.06550330e-01,  6.77322531e+00, -1.14607811e-01, -1.41265738e+00,
         1.99734950e+00,  2.20222449e+00,  1.86288178e+00,  5.11767685e-01,
         5.33821821e+00, -4.64367485e+00,  3.66502953e+00,  3.74423862e+00,
         4.03638268e+00,  7.54101202e-02,  1.44687662e+01, -7.17471004e-01,
        -1.30744290e+00,  7.43842077e+00,  2.32416224e+00,  3.14585876e+00,
         2.18818569e+00, -2.59033966e+00,  3.10064387e+00,  7.24952221e-01,
         4.84180307e+00, -4.11686039e+00,  7.87555742e+00,  7.28848171e+00,
        -3.36859107e+00,  1.26252594e+01,  5.61164856e-01,  7.11485672e+00,
         2.50771070e+00,  3.42430043e+00, -4.53626108e+00, -1.07907581e+00,
         2.66399980e-01, -7.14415669e-01,  4.09829664e+00,  3.31546545e-01,
        -6.27642298e+00,  9.59673882e+00,  8.50249958e+00,  7.02924109e+00,
         1.82174253e+00,  3.50519037e+00,  3.09928000e-01,  2.11880589e+00,
         1.15779006e+00, -2.71216941e+00,  1.08381844e+01, -9.36515033e-01,
         7.42496157e+00,  3.10040927e+00,  1.47757459e+00,  5.45620251e+00,
        -9.65406179e-01,  5.69845438e-01,  1.05647731e+00, -1.68837774e+00,
        -3.09947371e+00, -1.37878811e+00, -4.00170040e+00,  3.19888449e+00,
         4.09293699e+00,  2.08439499e-01, -6.17463350e-01,  9.50178337e+00,
         1.69236028e+00, -1.10896671e+00, -4.81128514e-01, -2.53491831e+00,
        -5.33746672e+00, -4.03041780e-01, -1.25375473e+00, -3.51558614e+00,
        -3.11406779e+00,  7.91966379e-01,  4.52294731e+00,  2.55605388e+00,
         5.28642416e+00,  2.99547863e+00, -1.21793652e+00,  1.19890194e+01,
         1.41336050e+01, -4.21870375e+00, -4.67677212e+00,  3.85207629e+00,
        -2.42873371e-01,  7.19176579e+00, -1.09403837e+00,  2.90093279e+00,
         2.40929937e+00,  5.77476680e-01, -2.73825598e+00, -4.20346409e-01,
         4.93089962e+00,  8.62141418e+00,  2.64123559e+00,  1.20847387e+01,
         3.20163560e+00,  1.82828065e-02, -2.53568769e+00,  1.68844432e-01,
        -1.38734162e+00, -5.39671361e-01,  6.26399040e-01,  3.78154135e+00,
        -1.44603646e+00,  3.62094259e+00,  4.27015752e-01,  8.55703640e+00,
        -3.27997416e-01, -7.22892523e-01,  1.71054292e+00, -1.63295710e+00,
         6.94152403e+00, -3.80167484e+00, -2.12913966e+00,  3.23158097e+00,
         2.85428023e+00,  3.64996219e+00,  5.77141714e+00,  5.21080589e+00,
        -8.06536198e-01,  5.69135571e+00, -2.64102507e+00,  1.36245430e+00,
         5.17554379e+00, -4.57989454e+00, -6.95855427e+00,  8.14358902e+00,
        -1.25018013e+00,  7.67930090e-01, -1.70860660e+00,  3.88413954e+00,
         9.71800029e-01,  7.31338692e+00, -2.61684608e+00, -1.34339631e+00,
         2.85086250e+00,  3.36626267e+00, -1.93365350e-01,  1.44506800e+00,
         1.55295765e+00,  3.37194824e+00, -3.85353017e+00,  3.79228020e+00,
        -7.96432257e-01,  3.63358521e+00,  1.47053063e-01, -3.17763734e+00,
         6.06801033e-01,  4.51876283e-01, -2.83103287e-01, -2.13851094e+00,
        -9.97182727e-01, -2.68873525e+00,  1.95144683e-01,  3.11502504e+00,
         1.49993312e+00,  1.24946916e+00,  9.01723862e+00,  5.95677042e+00,
         4.03672647e+00,  3.36757362e-01,  9.86615598e-01,  3.77416420e+00,
        -2.19306135e+00,  2.72172952e+00, -1.87311101e+00,  2.45314091e-04,
         3.40489888e+00,  4.95307493e+00,  5.47031343e-01,  7.75023460e+00,
         7.21792269e+00,  2.78160524e+00,  1.74221873e+00, -2.23597139e-01,
        -5.41836500e+00, -9.03025210e-01, -2.77599812e-01, -1.42691278e+00,
         3.88976264e+00, -2.35397607e-01,  3.67205906e+00, -6.47095263e-01,
         3.81058383e+00,  3.85349703e+00,  1.40607870e+00,  9.26314890e-01,
        -1.87049818e+00,  6.33107185e+00,  2.07475901e+00, -6.07982934e-01,
         2.62817621e-01,  1.33949077e+00,  2.37122345e+00, -8.56272936e-01,
         6.60288095e+00, -1.05950725e+00, -4.92492819e+00, -7.28345490e+00,
         2.02007222e+00, -1.46165222e-01, -3.54922444e-01, -2.14956474e+00,
         6.88527012e+00,  6.15936875e-01, -2.04308569e-01, -6.31455779e-01,
         8.17636073e-01,  4.77770042e+00, -3.89938569e+00, -4.00856733e+00,
        -3.11721635e+00, -1.94814181e+00,  4.42964172e+00,  8.99354839e+00,
        -3.78289080e+00, -3.90486646e+00,  7.04165220e+00,  5.61456585e+00,
         5.64207888e+00, -5.35602617e+00, -5.73118150e-01,  7.83022404e-01,
         3.09969187e-01,  1.78385174e+00,  8.00202608e-01,  1.01662719e+00,
         2.07571626e+00, -4.22121716e+00,  8.12596416e+00, -3.27967763e+00,
         5.72772694e+00,  5.26709938e+00,  4.22519970e+00, -2.63554072e+00,
         3.97582912e+00,  1.08148420e+00,  3.01872849e+00, -7.60718226e-01,
        -3.03127337e+00,  7.72335005e+00,  1.66530895e+00, -3.22213006e+00,
        -6.63849711e-02,  3.34508634e+00,  4.43305492e+00,  5.31201982e+00,
        -2.64399827e-01, -2.35947204e+00,  9.64019585e+00,  4.01074648e+00,
        -5.51873207e+00,  4.37826967e+00, -1.13352823e+00,  1.94160938e+00,
         4.35695028e+00,  8.05677593e-01,  1.05962276e+01, -2.47067618e+00,
        -1.42366612e+00,  8.21589375e+00, -1.87384403e+00, -3.00028276e+00,
         4.61063004e+00,  5.33816528e+00,  9.87914026e-01, -6.44644880e+00,
         4.70458698e+00,  9.11405861e-01, -3.94645596e+00,  7.55444336e+00,
         1.08126080e+00,  4.18652296e+00, -1.62076116e+00,  6.57763863e+00,
         3.40370369e+00,  3.52328706e+00,  3.68109179e+00,  4.53997469e+00,
         1.15512311e+00,  2.99138665e+00,  4.48788404e+00,  1.06200743e+01,
        -2.05182195e+00,  8.77545261e+00, -3.15916538e+00, -1.57427716e+00,
         2.60978174e+00, -1.22366810e+00,  3.36520672e+00, -3.51834583e+00,
        -2.14334816e-01, -1.38953722e+00,  6.34737349e+00,  7.83959866e+00,
        -3.40451789e+00, -2.65765637e-01,  1.10510731e+01,  1.08215380e+01,
        -1.04952598e+00,  1.31454647e+00,  6.97008562e+00,  5.92310381e+00,
        -4.41084385e+00,  2.28733230e+00,  2.19364786e+00,  2.81976008e+00,
        -9.24093798e-02, -5.23354197e+00, -7.42490005e+00,  7.97478497e-01,
         2.56620359e+00,  3.90130568e+00,  3.78423738e+00, -3.58733177e+00,
        -8.68332744e-01,  2.45269513e+00,  6.18241739e+00,  2.67131591e+00,
        -3.64182591e-01, -9.12967861e-01,  3.19330502e+00,  3.44236636e+00,
         6.10960627e+00,  8.83858585e+00, -6.55251443e-01,  4.50519174e-01,
         5.59152126e+00, -6.26033306e-01,  5.44366837e+00,  2.00288272e+00,
         2.94050121e+00,  2.60796118e+00,  3.15805817e+00, -5.83688468e-02,
        -1.36998332e+00, -3.02748823e+00, -1.90837824e+00,  1.23842549e+00,
        -8.65440667e-02, -5.08403599e-01, -8.56506646e-01, -1.68571615e+00,
         2.03255010e+00,  5.68906021e+00,  3.03824162e+00,  1.05126333e+00,
         3.53914611e-02,  4.41267443e+00,  3.43715501e+00,  7.30474293e-01,
         2.09974742e+00,  3.31782818e+00,  2.00661078e-01,  2.02342600e-01,
         1.82752943e+00,  6.56389415e-01,  8.83247256e-01,  2.45531034e+00,
        -2.68853736e+00,  3.71515727e+00,  5.44404268e+00, -2.23881102e+00,
         4.11289644e+00,  6.85173321e+00, -5.50463557e-01,  8.65457916e+00,
        -2.34702802e+00,  2.33728230e-01, -9.80384946e-01, -1.91424644e+00,
        -2.43567944e+00,  7.62488186e-01, -2.86838078e+00, -2.11535358e+00,
         1.97137082e+00, -9.04729843e-01,  2.12446156e+01, -2.61763287e+00,
        -2.41028160e-01,  2.24689436e+00, -3.25479126e+00,  2.33114719e+00,
        -3.61737180e+00, -1.70654428e+00, -3.98723459e+00, -2.23293543e+00,
        -9.31767464e-01, -3.74582100e+00, -1.38928425e+00, -6.54406846e-01,
        -3.41431284e+00, -3.91356850e+00,  3.45268297e+00,  3.23755932e+00],
       device='cuda:0')/home/hongjixu/Verifier_Development/complete_verifier/auto_LiRPA/perturbations.py:254: UserWarning: The reduce argument of torch.scatter with Tensor src is deprecated and will be removed in a future PyTorch release. Use torch.scatter_reduce instead for more reduction options. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025845868/work/aten/src/ATen/native/TensorAdvancedIndexing.cpp:232.)
  self.x_L_sparse.scatter_(dim=-1, index=index, src=(x_L - lb).view(batch_size, -1), reduce='add')

Clean RHS: tensor([[6.43492985]], device='cuda:0')
Split layers:
  BoundConv(name=/input.24, inputs=[/110, /61, /62], perturbed=True): [(BoundRelu(name=/112, inputs=[/input.24], perturbed=True), 0)]
  BoundConv(name=/input.68, inputs=[/132, /77, /78], perturbed=True): [(BoundRelu(name=/134, inputs=[/input.68], perturbed=True), 0)]
  BoundConv(name=/input.36, inputs=[/116, /65], perturbed=True): [(BoundRelu(name=/118, inputs=[/input.36], perturbed=True), 0)]
  BoundConv(name=/input.100, inputs=[/148, /90], perturbed=True): [(BoundRelu(name=/150, inputs=[/input.100], perturbed=True), 0)]
  BoundConv(name=/input.48, inputs=[/122, /70, /71], perturbed=True): [(BoundRelu(name=/124, inputs=[/input.48], perturbed=True), 0)]
  BoundConv(name=/input.80, inputs=[/138, /82], perturbed=True): [(BoundRelu(name=/140, inputs=[/input.80], perturbed=True), 0)]
  BoundLinear(name=/input.112, inputs=[/155, /93, /94], perturbed=True): [(BoundRelu(name=/157, inputs=[/input.112], perturbed=True), 0)]
  BoundConv(name=/input.16, inputs=[/106, /58], perturbed=True): [(BoundRelu(name=/108, inputs=[/input.16], perturbed=True), 0)]
  BoundConv(name=/input.28, inputs=[/112, /63], perturbed=True): [(BoundRelu(name=/114, inputs=[/input.28], perturbed=True), 0)]
  BoundConv(name=/input.60, inputs=[/128, /74], perturbed=True): [(BoundRelu(name=/130, inputs=[/input.60], perturbed=True), 0)]
  BoundConv(name=/input.92, inputs=[/144, /86, /87], perturbed=True): [(BoundRelu(name=/146, inputs=[/input.92], perturbed=True), 0)]
  BoundConv(name=/input.12, inputs=[/104, /57], perturbed=True): [(BoundRelu(name=/106, inputs=[/input.12], perturbed=True), 0)]
  BoundConv(name=/input.40, inputs=[/118, /66, /67], perturbed=True): [(BoundRelu(name=/120, inputs=[/input.40], perturbed=True), 0)]
  BoundConv(name=/input.72, inputs=[/134, /79, /80], perturbed=True): [(BoundRelu(name=/136, inputs=[/input.72], perturbed=True), 0)]
  BoundConv(name=/input.4, inputs=[/100, /54, /55], perturbed=True): [(BoundRelu(name=/102, inputs=[/input.4], perturbed=True), 0)]
  BoundConv(name=/input.88, inputs=[/142, /84, /85], perturbed=True): [(BoundRelu(name=/144, inputs=[/input.88], perturbed=True), 0)]
  BoundConv(name=/input.104, inputs=[/150, /91], perturbed=True): [(BoundRelu(name=/152, inputs=[/input.104], perturbed=True), 0)]
  BoundConv(name=/input.52, inputs=[/124, /72], perturbed=True): [(BoundRelu(name=/126, inputs=[/input.52], perturbed=True), 0)]
  BoundConv(name=/input.84, inputs=[/140, /83], perturbed=True): [(BoundRelu(name=/142, inputs=[/input.84], perturbed=True), 0)]
  BoundLinear(name=/input.116, inputs=[/158, /95, /96], perturbed=True): [(BoundRelu(name=/160, inputs=[/input.116], perturbed=True), 0)]
  BoundConv(name=/input.8, inputs=[/102, /56], perturbed=True): [(BoundRelu(name=/104, inputs=[/input.8], perturbed=True), 0)]
  BoundConv(name=/input.20, inputs=[/108, /59, /60], perturbed=True): [(BoundRelu(name=/110, inputs=[/input.20], perturbed=True), 0)]
  BoundConv(name=/input.64, inputs=[/130, /75, /76], perturbed=True): [(BoundRelu(name=/132, inputs=[/input.64], perturbed=True), 0)]
  BoundConv(name=/input.32, inputs=[/114, /64], perturbed=True): [(BoundRelu(name=/116, inputs=[/input.32], perturbed=True), 0)]
  BoundConv(name=/input.96, inputs=[/146, /88, /89], perturbed=True): [(BoundRelu(name=/148, inputs=[/input.96], perturbed=True), 0)]
  BoundConv(name=/input, inputs=[/input.1, /52, /53], perturbed=True): [(BoundRelu(name=/100, inputs=[/input], perturbed=True), 0)]
  BoundConv(name=/input.44, inputs=[/120, /68, /69], perturbed=True): [(BoundRelu(name=/122, inputs=[/input.44], perturbed=True), 0)]
  BoundConv(name=/input.76, inputs=[/136, /81], perturbed=True): [(BoundRelu(name=/138, inputs=[/input.76], perturbed=True), 0)]
  BoundConv(name=/input.108, inputs=[/152, /92], perturbed=True): [(BoundRelu(name=/154, inputs=[/input.108], perturbed=True), 0)]
  BoundConv(name=/input.56, inputs=[/126, /73], perturbed=True): [(BoundRelu(name=/128, inputs=[/input.56], perturbed=True), 0)]
Nonlinear functions:
   BoundRelu(name=/100, inputs=[/input], perturbed=True)
   BoundRelu(name=/102, inputs=[/input.4], perturbed=True)
   BoundRelu(name=/104, inputs=[/input.8], perturbed=True)
   BoundRelu(name=/106, inputs=[/input.12], perturbed=True)
   BoundRelu(name=/108, inputs=[/input.16], perturbed=True)
   BoundRelu(name=/110, inputs=[/input.20], perturbed=True)
   BoundRelu(name=/112, inputs=[/input.24], perturbed=True)
   BoundRelu(name=/114, inputs=[/input.28], perturbed=True)
   BoundRelu(name=/116, inputs=[/input.32], perturbed=True)
   BoundRelu(name=/118, inputs=[/input.36], perturbed=True)
   BoundRelu(name=/120, inputs=[/input.40], perturbed=True)
   BoundRelu(name=/122, inputs=[/input.44], perturbed=True)
   BoundRelu(name=/124, inputs=[/input.48], perturbed=True)
   BoundRelu(name=/126, inputs=[/input.52], perturbed=True)
   BoundRelu(name=/128, inputs=[/input.56], perturbed=True)
   BoundRelu(name=/130, inputs=[/input.60], perturbed=True)
   BoundRelu(name=/132, inputs=[/input.64], perturbed=True)
   BoundRelu(name=/134, inputs=[/input.68], perturbed=True)
   BoundRelu(name=/136, inputs=[/input.72], perturbed=True)
   BoundRelu(name=/138, inputs=[/input.76], perturbed=True)
   BoundRelu(name=/140, inputs=[/input.80], perturbed=True)
   BoundRelu(name=/142, inputs=[/input.84], perturbed=True)
   BoundRelu(name=/144, inputs=[/input.88], perturbed=True)
   BoundRelu(name=/146, inputs=[/input.92], perturbed=True)
   BoundRelu(name=/148, inputs=[/input.96], perturbed=True)
   BoundRelu(name=/150, inputs=[/input.100], perturbed=True)
   BoundRelu(name=/152, inputs=[/input.104], perturbed=True)
   BoundRelu(name=/154, inputs=[/input.108], perturbed=True)
   BoundRelu(name=/157, inputs=[/input.112], perturbed=True)
   BoundRelu(name=/160, inputs=[/input.116], perturbed=True)
Using Linf sparse perturbation. Perturbed dimensions: 10.
Avg perturbation: 2.002716064453125e-05
initial forward+backward bounds: tensor([[6.43492985]], device='cuda:0')
Worst class: (+ rhs) 6.434929847717285
Verified by initial bound!
Result: safe in 11.4564 seconds
############# Summary #############
Final verified acc: 100.0% (total 1 examples)
Problem instances count: 1 , total verified (safe/unsat): 1 , total falsified (unsafe/sat): 0 , timeout: 0
mean time for ALL instances (total 1):11.456253406978869, max time: 11.45636796951294
mean time for verified SAFE instances(total 1): 11.45636796951294, max time: 11.45636796951294
safe (total 1), index: [0]
Result dict saved to /home/hongjixu/Verifier_Development/tests/gpu_tests/vnncomp23/vggnet16/master_outputs/6.pkl.
