/home/hongjixu/miniconda3/envs/alpha-beta-crown/lib/python3.11/site-packages/onnx2pytorch/convert/model.py:151: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  warnings.warn(
Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: matrix
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  sparse_alpha: false
  sparse_interm: false
  save_adv_example: false
  eval_adv_example: false
  show_adv_example: false
  precompile_jit: false
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2023_benchmarks/benchmarks/ml4acopf
  deterministic_opt: false
  graph_optimizer: 'Customized("custom_graph_optimizer", "default_optimizer")'
  buffer_has_batchdim: false
  save_output: true
  output_file: /home/hongjixu/Verifier_Development/tests/gpu_tests/vnncomp23/ml4acopf/master_outputs/0.pkl
  return_optimized_model: false
model:
  name: null
  path: null
  onnx_path: null
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  debug_onnx: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: default_onnx_and_vnnlib_loader
  onnx_optimization_flags: [remove_matmul_inplace]
  onnx_vnnlib_joint_optimization_flags: none
  check_optmized: false
  flatten_final_output: false
  optimize_graph: null
  with_jacobian: false
data:
  start: 0
  end: 1
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: null
  vnnlib_path_prefix: ''
  rhs_offset: null
solver:
  batch_size: 512
  auto_enlarge_batch_size: false
  min_batch_size_ratio: 0.0
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  optimize_disjuncts_separately: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
    relu_option: adaptive
  alpha-crown:
    alpha: true
    lr_alpha: 0.5
    iteration: 40
    share_alphas: false
    lr_decay: 0.99
    full_conv_alpha: true
    max_coeff_mul: .inf
    matmul_share_alphas: false
    disable_optimization: [sin, cos]
  invprop:
    apply_output_constraints_to: []
    tighten_input_bounds: false
    best_of_oc_and_no_oc: false
    directly_optimize: []
    oc_lr: 0.1
    share_gammas: false
  beta-crown:
    lr_alpha: 0.5
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 10
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
    reset_threshold: 1.0
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
    skip_unsafe: false
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 360
  timeout_scale: 1
  max_iterations: -1
  override_timeout: null
  get_upper_bound: false
  pruning_in_iteration: false
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_interm: ''
  interm_transfer: true
  recompute_interm: false
  sort_domain_interval: 1
  vanilla_crown: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
    _tmp_cuts: null
    fixed_cuts: false
    add_implied_cuts: false
    add_input_cuts: false
  branching:
    method: nonlinear
    candidates: 3
    reduceop: min
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    nonlinear_split:
      method: shortcut
      branching_point_method: uniform
      branching_point_node: ''
      branching_point_db: []
      num_branches: 2
      branching_point_refinement: false
      filter: true
      filter_beta: false
      filter_batch_size: 10000
      filter_iterations: 25
      use_min: false
      loose_tanh_threshold: null
      dynamic: false
      dynamic_bbps: false
      dynamic_beta_heuristic: false
      beta_heuristic: false
      dynamic_options: [uniform, three_left, three_right]
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
      split_partitions: 2
      sb_margin_weight: 1.0
      sb_primary_spec: null
      sb_primary_spec_iter: 1
      sb_sum: false
      bf_backup_thresh: -1
      bf_rhs_offset: 0
      bf_zero_crossing_score: false
      ibp_enhancement: false
      catch_assertion: false
      compare_with_old_bounds: false
      update_rhs_with_attack: false
      sb_coeff_thresh: 0.001
      sort_index: null
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 30.0
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 100
  pgd_batch_size: 100000000
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  adv_saver: default_adv_saver
  early_stop_condition: default_early_stop_condition
  adv_example_finalizer: default_adv_example_finalizer
  pgd_loss: default_pgd_loss
  cex_path: ./test_cex.txt
  attack_mode: PGD
  attack_tolerance: 0.0001
  attack_func: attack_with_general_specs
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 500000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
    max_num_domains: 10
debug:
  view_model: false
  lp_test: null
  rescale_vnnlib_ptb: null
  test_optimized_bounds: false
  test_optimized_bounds_after_n_iterations: 0
  print_verbose_decisions: false

Experiments at Wed Mar 27 05:25:37 2024 on huan-c4140-server
customized start/end sample from instance 0 to 1 in instances.csv
Internal results will be saved to out.txt.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx onnx/118_ieee_ml4acopf.onnx
Using vnnlib vnnlib/118_ieee_prop2.vnnlib
Precompiled vnnlib file found at ../../vnncomp2023_benchmarks/benchmarks/ml4acopf/vnnlib/118_ieee_prop2.vnnlib.compiled
Loading onnx ../../vnncomp2023_benchmarks/benchmarks/ml4acopf/onnx/118_ieee_ml4acopf.onnx wih quirks {}
Onnx optimization with flag: ['remove_matmul_inplace']
Found existed optimized onnx model at ../../vnncomp2023_benchmarks/benchmarks/ml4acopf/onnx/118_ieee_ml4acopf.onnx.optimized
Automatic inference of operator: cos
Automatic inference of operator: sin
Automatic inference of operator: neg

**************************
Model might not be converted correctly. Please check onnx conversion carefully.
Output by pytorch: [[ 0.          0.          0.         ...  0.00058532 -0.00012889
  -0.00023536]]
Output by onnx: [[ 0.          0.          0.         ...  0.00058722 -0.00012894
  -0.00023919]]
Max error: tensor(2.67028809e-05)
**************************

Attack parameters: initialization=uniform, steps=100, restarts=100, alpha=0.069255530834198, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  ...,
          6.71863556e-04, -2.11916864e-04,  4.19765711e-05]], device='cuda:0')
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:01<00:00,  1.88s/it]100%|██████████| 1/1 [00:01<00:00,  1.88s/it]
/home/hongjixu/miniconda3/envs/alpha-beta-crown/lib/python3.11/site-packages/onnx2pytorch/operations/slice.py:73: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert (steps == 1 or steps == -1) and axes == int(axes) and start == int(start) and end == int(end)
/home/hongjixu/miniconda3/envs/alpha-beta-crown/lib/python3.11/site-packages/onnx2pytorch/operations/slice.py:73: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert (steps == 1 or steps == -1) and axes == int(axes) and start == int(start) and end == int(end)
/home/hongjixu/miniconda3/envs/alpha-beta-crown/lib/python3.11/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/hongjixu/miniconda3/envs/alpha-beta-crown/lib/python3.11/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):
/home/hongjixu/miniconda3/envs/alpha-beta-crown/lib/python3.11/site-packages/onnx2pytorch/operations/gather.py:14: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if indices.numel() == 1 and indices == -1:
/home/hongjixu/miniconda3/envs/alpha-beta-crown/lib/python3.11/site-packages/onnx2pytorch/operations/constantofshape.py:16: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  return self.constant.expand(*shape).to(shape.device)
/home/hongjixu/miniconda3/envs/alpha-beta-crown/lib/python3.11/site-packages/onnx2pytorch/operations/constantofshape.py:16: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  return self.constant.expand(*shape).to(shape.device)
/home/hongjixu/miniconda3/envs/alpha-beta-crown/lib/python3.11/site-packages/onnx2pytorch/operations/expand.py:7: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if isinstance(shape, torch.Tensor) and (shape == 1).all():
/home/hongjixu/miniconda3/envs/alpha-beta-crown/lib/python3.11/site-packages/onnx2pytorch/operations/expand.py:9: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).
  torch.Size(shape), dtype=input.dtype, device=input.device)
/home/hongjixu/miniconda3/envs/alpha-beta-crown/lib/python3.11/site-packages/onnx2pytorch/operations/expand.py:9: TracerWarning: Using len to get tensor shape might cause the trace to be incorrect. Recommended usage would be tensor.shape[0]. Passing a tensor of different shape might lead to errors or silently give incorrect results.
  torch.Size(shape), dtype=input.dtype, device=input.device)
/home/hongjixu/Verifier_Development/complete_verifier/auto_LiRPA/operators/leaf.py:176: UserWarning: The "has_batchdim" option for BoundBuffers is deprecated. It may be removed from the next release.
  warnings.warn('The "has_batchdim" option for BoundBuffers is deprecated.'
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[ 0.00000000,  0.00000000,  0.00000000,  ...,  0.57179379,
           0.00200725, -0.01524086]]], device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[55.29486465]]], device='cuda:0')
number of violation:  0
Attack finished in 2.6428 seconds.
PGD attack failed
torch allclose failed: norm 9.395487722940743e-05
Model: BoundedModule(
  (/0): BoundInput(name=/0, inputs=[], perturbed=True)
  (/9): BoundBuffers(name=/9, inputs=[], perturbed=False)
  (/10): BoundBuffers(name=/10, inputs=[], perturbed=False)
  (/19): BoundParams(name=/19, inputs=[], perturbed=False)
  (/20): BoundParams(name=/20, inputs=[], perturbed=False)
  (/21): BoundParams(name=/21, inputs=[], perturbed=False)
  (/22): BoundParams(name=/22, inputs=[], perturbed=False)
  (/23): BoundParams(name=/23, inputs=[], perturbed=False)
  (/24): BoundParams(name=/24, inputs=[], perturbed=False)
  (/25): BoundParams(name=/25, inputs=[], perturbed=False)
  (/26): BoundParams(name=/26, inputs=[], perturbed=False)
  (/59): BoundBuffers(name=/59, inputs=[], perturbed=False)
  (/60): BoundBuffers(name=/60, inputs=[], perturbed=False)
  (/61): BoundBuffers(name=/61, inputs=[], perturbed=False)
  (/62): BoundBuffers(name=/62, inputs=[], perturbed=False)
  (/63): BoundBuffers(name=/63, inputs=[], perturbed=False)
  (/64): BoundBuffers(name=/64, inputs=[], perturbed=False)
  (/65): BoundBuffers(name=/65, inputs=[], perturbed=False)
  (/66): BoundBuffers(name=/66, inputs=[], perturbed=False)
  (/67): BoundBuffers(name=/67, inputs=[], perturbed=False)
  (/68): BoundBuffers(name=/68, inputs=[], perturbed=False)
  (/69): BoundBuffers(name=/69, inputs=[], perturbed=False)
  (/70): BoundBuffers(name=/70, inputs=[], perturbed=False)
  (/71): BoundBuffers(name=/71, inputs=[], perturbed=False)
  (/72): BoundBuffers(name=/72, inputs=[], perturbed=False)
  (/73): BoundBuffers(name=/73, inputs=[], perturbed=False)
  (/74): BoundBuffers(name=/74, inputs=[], perturbed=False)
  (/shape.1): BoundBuffers(name=/shape.1, inputs=[], perturbed=False)
  (/76): BoundBuffers(name=/76, inputs=[], perturbed=False)
  (/77): BoundBuffers(name=/77, inputs=[], perturbed=False)
  (/78): BoundBuffers(name=/78, inputs=[], perturbed=False)
  (/shape.5): BoundBuffers(name=/shape.5, inputs=[], perturbed=False)
  (/80): BoundBuffers(name=/80, inputs=[], perturbed=False)
  (/81): BoundBuffers(name=/81, inputs=[], perturbed=False)
  (/82): BoundBuffers(name=/82, inputs=[], perturbed=False)
  (/83): BoundBuffers(name=/83, inputs=[], perturbed=False)
  (/84): BoundBuffers(name=/84, inputs=[], perturbed=False)
  (/85): BoundBuffers(name=/85, inputs=[], perturbed=False)
  (/86): BoundParams(name=/86, inputs=[], perturbed=False)
  (/87): BoundParams(name=/87, inputs=[], perturbed=False)
  (/88): BoundParams(name=/88, inputs=[], perturbed=False)
  (/89): BoundParams(name=/89, inputs=[], perturbed=False)
  (/90): BoundParams(name=/90, inputs=[], perturbed=False)
  (/91): BoundParams(name=/91, inputs=[], perturbed=False)
  (/92): BoundParams(name=/92, inputs=[], perturbed=False)
  (/93): BoundParams(name=/93, inputs=[], perturbed=False)
  (/94): BoundBuffers(name=/94, inputs=[], perturbed=False)
  (/95): BoundBuffers(name=/95, inputs=[], perturbed=False)
  (/96): BoundBuffers(name=/96, inputs=[], perturbed=False)
  (/input): BoundLinear(name=/input, inputs=[/0, /19, /20], perturbed=True)
  (/98): BoundRelu(name=/98, inputs=[/input], perturbed=True)
  (/input.3): BoundLinear(name=/input.3, inputs=[/98, /21, /22], perturbed=True)
  (/100): BoundRelu(name=/100, inputs=[/input.3], perturbed=True)
  (/input.7): BoundLinear(name=/input.7, inputs=[/100, /23, /24], perturbed=True)
  (/102): BoundRelu(name=/102, inputs=[/input.7], perturbed=True)
  (/103): BoundLinear(name=/103, inputs=[/102, /25, /26], perturbed=True)
  (/104): BoundConstant(name=/104, value=1)
  (/105): BoundConstant(name=/105, value=0)
  (/106): BoundConstant(name=/106, value=226)
  (/107): BoundConstant(name=/107, value=0)
  (/108): BoundConstant(name=/108, value=226)
  (/109): BoundAdd(name=/109, inputs=[/107, /108], perturbed=False)
  (/110): BoundConstant(name=/110, value=tensor([0], device='cuda:0'))
  (/111): BoundUnsqueeze(name=/111, inputs=[/104, /110], perturbed=False)
  (/112): BoundConstant(name=/112, value=tensor([0], device='cuda:0'))
  (/113): BoundUnsqueeze(name=/113, inputs=[/105, /112], perturbed=False)
  (/114): BoundConstant(name=/114, value=tensor([0], device='cuda:0'))
  (/115): BoundUnsqueeze(name=/115, inputs=[/109, /114], perturbed=False)
  (/116): BoundSlice(name=/116, inputs=[/103, /113, /115, /111], perturbed=True)
  (/117): BoundSigmoid(name=/117, inputs=[/116], perturbed=True)
  (/118): BoundMul(name=/118, inputs=[/117, /9], perturbed=True)
  (/119): BoundAdd(name=/119, inputs=[/118, /10], perturbed=True)
  (/120): BoundConstant(name=/120, value=226)
  (/121): BoundConstant(name=/121, value=118)
  (/122): BoundAdd(name=/122, inputs=[/120, /121], perturbed=False)
  (/123): BoundConstant(name=/123, value=tensor([0], device='cuda:0'))
  (/124): BoundUnsqueeze(name=/124, inputs=[/104, /123], perturbed=False)
  (/125): BoundConstant(name=/125, value=tensor([0], device='cuda:0'))
  (/126): BoundUnsqueeze(name=/126, inputs=[/106, /125], perturbed=False)
  (/127): BoundConstant(name=/127, value=tensor([0], device='cuda:0'))
  (/128): BoundUnsqueeze(name=/128, inputs=[/122, /127], perturbed=False)
  (/129): BoundSlice(name=/129, inputs=[/103, /126, /128, /124], perturbed=True)
  (/130): BoundConcat(name=/130, inputs=[/119, /129], perturbed=True)
  (/131): BoundConstant(name=/131, value=99)
  (/132): BoundConstant(name=/132, value=0)
  (/133): BoundConstant(name=/133, value=99)
  (/134): BoundAdd(name=/134, inputs=[/132, /133], perturbed=False)
  (/135): BoundConstant(name=/135, value=tensor([0], device='cuda:0'))
  (/136): BoundUnsqueeze(name=/136, inputs=[/104, /135], perturbed=False)
  (/137): BoundConstant(name=/137, value=tensor([0], device='cuda:0'))
  (/138): BoundUnsqueeze(name=/138, inputs=[/105, /137], perturbed=False)
  (/139): BoundConstant(name=/139, value=tensor([0], device='cuda:0'))
  (/140): BoundUnsqueeze(name=/140, inputs=[/134, /139], perturbed=False)
  (/141): BoundSlice(name=/141, inputs=[/0, /138, /140, /136], perturbed=True)
  (/142): BoundConstant(name=/142, value=99)
  (/143): BoundAdd(name=/143, inputs=[/142, /142], perturbed=False)
  (/144): BoundConstant(name=/144, value=tensor([0], device='cuda:0'))
  (/145): BoundUnsqueeze(name=/145, inputs=[/104, /144], perturbed=False)
  (/146): BoundConstant(name=/146, value=tensor([0], device='cuda:0'))
  (/147): BoundUnsqueeze(name=/147, inputs=[/131, /146], perturbed=False)
  (/148): BoundConstant(name=/148, value=tensor([0], device='cuda:0'))
  (/149): BoundUnsqueeze(name=/149, inputs=[/143, /148], perturbed=False)
  (/150): BoundSlice(name=/150, inputs=[/0, /147, /149, /145], perturbed=True)
  (/151): BoundConstant(name=/151, value=54)
  (/152): BoundConstant(name=/152, value=0)
  (/153): BoundConstant(name=/153, value=54)
  (/154): BoundAdd(name=/154, inputs=[/152, /153], perturbed=False)
  (/155): BoundConstant(name=/155, value=tensor([0], device='cuda:0'))
  (/156): BoundUnsqueeze(name=/156, inputs=[/104, /155], perturbed=False)
  (/157): BoundConstant(name=/157, value=tensor([0], device='cuda:0'))
  (/158): BoundUnsqueeze(name=/158, inputs=[/105, /157], perturbed=False)
  (/159): BoundConstant(name=/159, value=tensor([0], device='cuda:0'))
  (/160): BoundUnsqueeze(name=/160, inputs=[/154, /159], perturbed=False)
  (/161): BoundSlice(name=/161, inputs=[/130, /158, /160, /156], perturbed=True)
  (/162): BoundConstant(name=/162, value=54)
  (/163): BoundAdd(name=/163, inputs=[/162, /162], perturbed=False)
  (/164): BoundConstant(name=/164, value=tensor([0], device='cuda:0'))
  (/165): BoundUnsqueeze(name=/165, inputs=[/104, /164], perturbed=False)
  (/166): BoundConstant(name=/166, value=tensor([0], device='cuda:0'))
  (/167): BoundUnsqueeze(name=/167, inputs=[/151, /166], perturbed=False)
  (/168): BoundConstant(name=/168, value=tensor([0], device='cuda:0'))
  (/169): BoundUnsqueeze(name=/169, inputs=[/163, /168], perturbed=False)
  (/170): BoundSlice(name=/170, inputs=[/130, /167, /169, /165], perturbed=True)
  (/171): BoundConstant(name=/171, value=108)
  (/172): BoundConstant(name=/172, value=108)
  (/173): BoundConstant(name=/173, value=118)
  (/174): BoundAdd(name=/174, inputs=[/172, /173], perturbed=False)
  (/175): BoundConstant(name=/175, value=tensor([0], device='cuda:0'))
  (/176): BoundUnsqueeze(name=/176, inputs=[/104, /175], perturbed=False)
  (/177): BoundConstant(name=/177, value=tensor([0], device='cuda:0'))
  (/178): BoundUnsqueeze(name=/178, inputs=[/171, /177], perturbed=False)
  (/179): BoundConstant(name=/179, value=tensor([0], device='cuda:0'))
  (/180): BoundUnsqueeze(name=/180, inputs=[/174, /179], perturbed=False)
  (/181): BoundSlice(name=/181, inputs=[/130, /178, /180, /176], perturbed=True)
  (/182): BoundConstant(name=/182, value=226)
  (/183): BoundConstant(name=/183, value=118)
  (/184): BoundAdd(name=/184, inputs=[/182, /183], perturbed=False)
  (/185): BoundConstant(name=/185, value=tensor([0], device='cuda:0'))
  (/186): BoundUnsqueeze(name=/186, inputs=[/104, /185], perturbed=False)
  (/187): BoundConstant(name=/187, value=tensor([0], device='cuda:0'))
  (/188): BoundUnsqueeze(name=/188, inputs=[/106, /187], perturbed=False)
  (/189): BoundConstant(name=/189, value=tensor([0], device='cuda:0'))
  (/190): BoundUnsqueeze(name=/190, inputs=[/184, /189], perturbed=False)
  (/191): BoundSlice(name=/191, inputs=[/130, /188, /190, /186], perturbed=True)
  (/192): BoundCast(name=/192, inputs=[/59], perturbed=False)
  (/193): BoundGather(name=/193, inputs=[/191, /192], perturbed=True)
  (/194): BoundCast(name=/194, inputs=[/60], perturbed=False)
  (/195): BoundGather(name=/195, inputs=[/191, /194], perturbed=True)
  (/196): BoundSub(name=/196, inputs=[/193, /195], perturbed=True)
  (/197): BoundCast(name=/197, inputs=[/192], perturbed=False)
  (/198): BoundGather(name=/198, inputs=[/181, /197], perturbed=True)
  (/199): BoundCast(name=/199, inputs=[/194], perturbed=False)
  (/200): BoundGather(name=/200, inputs=[/181, /199], perturbed=True)
  (/203): BoundCos(name=/203, inputs=[/196], perturbed=True)
  (/204): BoundSin(name=/204, inputs=[/196], perturbed=True)
  (/205): BoundMul(name=/205, inputs=[/198, /200], perturbed=True)
  (/206): BoundMul(name=/206, inputs=[/205, /203], perturbed=True)
  (/207): BoundMul(name=/207, inputs=[/205, /204], perturbed=True)
  (/208): BoundNeg(name=/208, inputs=[/207], perturbed=True)
  (/209): BoundMul(name=/209, inputs=[/63, /201/sqr], perturbed=True)
  (/210): BoundMul(name=/210, inputs=[/64, /206], perturbed=True)
  (/211): BoundAdd(name=/211, inputs=[/209, /210], perturbed=True)
  (/212): BoundMul(name=/212, inputs=[/65, /207], perturbed=True)
  (/213): BoundAdd(name=/213, inputs=[/211, /212], perturbed=True)
  (/214): BoundMul(name=/214, inputs=[/66, /201/sqr], perturbed=True)
  (/215): BoundMul(name=/215, inputs=[/67, /206], perturbed=True)
  (/216): BoundSub(name=/216, inputs=[/214, /215], perturbed=True)
  (/217): BoundMul(name=/217, inputs=[/68, /207], perturbed=True)
  (/218): BoundAdd(name=/218, inputs=[/216, /217], perturbed=True)
  (/219): BoundMul(name=/219, inputs=[/69, /202/sqr], perturbed=True)
  (/220): BoundAdd(name=/220, inputs=[/219, /210], perturbed=True)
  (/221): BoundMul(name=/221, inputs=[/70, /208], perturbed=True)
  (/222): BoundAdd(name=/222, inputs=[/220, /221], perturbed=True)
  (/223): BoundMul(name=/223, inputs=[/71, /202/sqr], perturbed=True)
  (/224): BoundSub(name=/224, inputs=[/223, /215], perturbed=True)
  (/225): BoundMul(name=/225, inputs=[/72, /208], perturbed=True)
  (/226): BoundAdd(name=/226, inputs=[/224, /225], perturbed=True)
  (/227): BoundConstant(name=/227, value=tensor([1], device='cuda:0'))
  (/228): BoundSplit(name=/228, inputs=[/shape.1, /227], perturbed=False)
  (/229): BoundConstant(name=/229, value=tensor([0], device='cuda:0'))
  (/230): BoundSqueeze(name=/230, inputs=[/228, /229], perturbed=False)
  (/231): BoundConstant(name=/231, value=tensor([0], device='cuda:0'))
  (/232): BoundUnsqueeze(name=/232, inputs=[/230, /231], perturbed=False)
  (/233): BoundConcat(name=/233, inputs=[/232], perturbed=False)
  (/234): BoundConstant(name=/234, value=tensor([-1], device='cuda:0'))
  (/235): BoundReshape(name=/235, inputs=[/233, /234], perturbed=False)
  (/236): BoundShape(name=/236, inputs=[/235], perturbed=False)
  (/237): BoundConstantOfShape(name=/237, inputs=[/236], perturbed=False)
  (/238): BoundConstant(name=/238, value=-1)
  (/239): BoundMul(name=/239, inputs=[/237, /238], perturbed=False)
  (/240): BoundEqual(name=/240, inputs=[/235, /239], perturbed=False)
  (/241): BoundWhere(name=/241, inputs=[/240, /237, /235], perturbed=False)
  (/242): BoundExpand(name=/242, inputs=[/76, /241], perturbed=False)
  (/243): BoundCast(name=/243, inputs=[/242], perturbed=False)
  (/244): BoundMul(name=/244, inputs=[/243, /77], perturbed=False)
  (/245): BoundEqual(name=/245, inputs=[/74, /244], perturbed=False)
  (/246): BoundCast(name=/246, inputs=[/243], perturbed=False)
  (/247): BoundCast(name=/247, inputs=[/74], perturbed=False)
  (/shape): BoundWhere(name=/shape, inputs=[/245, /246, /247], perturbed=False)
  (/249): BoundConstant(name=/249, inputs=[], perturbed=False)
  (/250): BoundSplit(name=/250, inputs=[/shape, /249], perturbed=False)
  (/251): BoundSplit(name=/251, inputs=[/shape, /249], perturbed=False)
  (/252): BoundConstant(name=/252, value=tensor([0], device='cuda:0'))
  (/253): BoundSqueeze(name=/253, inputs=[/250, /252], perturbed=False)
  (/254): BoundConstant(name=/254, value=tensor([0], device='cuda:0'))
  (/255): BoundSqueeze(name=/255, inputs=[/251, /254], perturbed=False)
  (/256): BoundConstant(name=/256, value=tensor([0], device='cuda:0'))
  (/257): BoundUnsqueeze(name=/257, inputs=[/253, /256], perturbed=False)
  (/258): BoundConstant(name=/258, value=tensor([0], device='cuda:0'))
  (/259): BoundUnsqueeze(name=/259, inputs=[/255, /258], perturbed=False)
  (/260): BoundConcat(name=/260, inputs=[/257, /259], perturbed=False)
  (/261): BoundConstantOfShape(name=/261, inputs=[/260], perturbed=False)
  (/262): BoundMul(name=/262, inputs=[/73, /261], perturbed=False)
  (/263): BoundConstant(name=/263, value=tensor([1], device='cuda:0'))
  (/264): BoundSplit(name=/264, inputs=[/shape.5, /263], perturbed=False)
  (/265): BoundConstant(name=/265, value=tensor([0], device='cuda:0'))
  (/266): BoundSqueeze(name=/266, inputs=[/264, /265], perturbed=False)
  (/267): BoundConstant(name=/267, value=tensor([0], device='cuda:0'))
  (/268): BoundUnsqueeze(name=/268, inputs=[/266, /267], perturbed=False)
  (/269): BoundConcat(name=/269, inputs=[/268], perturbed=False)
  (/270): BoundConstant(name=/270, value=tensor([-1], device='cuda:0'))
  (/271): BoundReshape(name=/271, inputs=[/269, /270], perturbed=False)
  (/272): BoundShape(name=/272, inputs=[/271], perturbed=False)
  (/273): BoundConstantOfShape(name=/273, inputs=[/272], perturbed=False)
  (/274): BoundConstant(name=/274, value=-1)
  (/275): BoundMul(name=/275, inputs=[/273, /274], perturbed=False)
  (/276): BoundEqual(name=/276, inputs=[/271, /275], perturbed=False)
  (/277): BoundWhere(name=/277, inputs=[/276, /273, /271], perturbed=False)
  (/278): BoundExpand(name=/278, inputs=[/80, /277], perturbed=False)
  (/279): BoundCast(name=/279, inputs=[/278], perturbed=False)
  (/280): BoundMul(name=/280, inputs=[/279, /81], perturbed=False)
  (/281): BoundEqual(name=/281, inputs=[/78, /280], perturbed=False)
  (/282): BoundCast(name=/282, inputs=[/279], perturbed=False)
  (/283): BoundCast(name=/283, inputs=[/78], perturbed=False)
  (/shape.4): BoundWhere(name=/shape.4, inputs=[/281, /282, /283], perturbed=False)
  (/285): BoundConstant(name=/285, inputs=[], perturbed=False)
  (/286): BoundSplit(name=/286, inputs=[/shape.4, /285], perturbed=False)
  (/287): BoundSplit(name=/287, inputs=[/shape.4, /285], perturbed=False)
  (/288): BoundConstant(name=/288, value=tensor([0], device='cuda:0'))
  (/289): BoundSqueeze(name=/289, inputs=[/286, /288], perturbed=False)
  (/290): BoundConstant(name=/290, value=tensor([0], device='cuda:0'))
  (/291): BoundSqueeze(name=/291, inputs=[/287, /290], perturbed=False)
  (/292): BoundConstant(name=/292, value=tensor([0], device='cuda:0'))
  (/293): BoundUnsqueeze(name=/293, inputs=[/289, /292], perturbed=False)
  (/294): BoundConstant(name=/294, value=tensor([0], device='cuda:0'))
  (/295): BoundUnsqueeze(name=/295, inputs=[/291, /294], perturbed=False)
  (/296): BoundConcat(name=/296, inputs=[/293, /295], perturbed=False)
  (/297): BoundConstantOfShape(name=/297, inputs=[/296], perturbed=False)
  (/298): BoundMul(name=/298, inputs=[/73, /297], perturbed=False)
  (/301): BoundAdd(name=/301, inputs=[/299/sqr, /300/sqr], perturbed=True)
  (/302): BoundSub(name=/302, inputs=[/301, /262], perturbed=True)
  (/305): BoundAdd(name=/305, inputs=[/303/sqr, /304/sqr], perturbed=True)
  (/306): BoundSub(name=/306, inputs=[/305, /298], perturbed=True)
  (/307): BoundTranspose(name=/307, inputs=[/86], perturbed=False)
  (/308): BoundMatMul(name=/308, inputs=[/141, /307], perturbed=True)
  (/309): BoundTranspose(name=/309, inputs=[/87], perturbed=False)
  (/310): BoundMatMul(name=/310, inputs=[/150, /309], perturbed=True)
  (/311): BoundTranspose(name=/311, inputs=[/88], perturbed=False)
  (/312): BoundMatMul(name=/312, inputs=[/161, /311], perturbed=True)
  (/313): BoundTranspose(name=/313, inputs=[/89], perturbed=False)
  (/314): BoundMatMul(name=/314, inputs=[/170, /313], perturbed=True)
  (/315): BoundTranspose(name=/315, inputs=[/90], perturbed=False)
  (/316): BoundMatMul(name=/316, inputs=[/213, /315], perturbed=True)
  (/317): BoundTranspose(name=/317, inputs=[/91], perturbed=False)
  (/318): BoundMatMul(name=/318, inputs=[/222, /317], perturbed=True)
  (/319): BoundTranspose(name=/319, inputs=[/92], perturbed=False)
  (/320): BoundMatMul(name=/320, inputs=[/218, /319], perturbed=True)
  (/321): BoundTranspose(name=/321, inputs=[/93], perturbed=False)
  (/322): BoundMatMul(name=/322, inputs=[/226, /321], perturbed=True)
  (/324): BoundSub(name=/324, inputs=[/312, /308], perturbed=True)
  (/325): BoundSub(name=/325, inputs=[/324, /318], perturbed=True)
  (/326): BoundSub(name=/326, inputs=[/325, /316], perturbed=True)
  (/327): BoundMul(name=/327, inputs=[/95, /323/sqr], perturbed=True)
  (/328): BoundSub(name=/328, inputs=[/326, /327], perturbed=True)
  (/329): BoundSub(name=/329, inputs=[/314, /310], perturbed=True)
  (/330): BoundSub(name=/330, inputs=[/329, /322], perturbed=True)
  (/331): BoundSub(name=/331, inputs=[/330, /320], perturbed=True)
  (/332): BoundMul(name=/332, inputs=[/96, /323/sqr], perturbed=True)
  (/333): BoundAdd(name=/333, inputs=[/331, /332], perturbed=True)
  (/334): BoundConcat(name=/334, inputs=[/130, /213, /222, /218, /226, /302, /306, /328, /333], perturbed=True)
  (/201/sqr): BoundSqr(name=/201/sqr, inputs=[/198], perturbed=True)
  (/202/sqr): BoundSqr(name=/202/sqr, inputs=[/200], perturbed=True)
  (/299/sqr): BoundSqr(name=/299/sqr, inputs=[/213], perturbed=True)
  (/300/sqr): BoundSqr(name=/300/sqr, inputs=[/218], perturbed=True)
  (/303/sqr): BoundSqr(name=/303/sqr, inputs=[/222], perturbed=True)
  (/304/sqr): BoundSqr(name=/304/sqr, inputs=[/226], perturbed=True)
  (/323/sqr): BoundSqr(name=/323/sqr, inputs=[/181], perturbed=True)
)
Original output: tensor([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  ...,
          6.71386719e-04, -2.11969018e-04,  3.83257866e-05]], device='cuda:0')
Split layers:
  BoundGather(name=/200, inputs=[/181, /199], perturbed=True): [(BoundMul(name=/205, inputs=[/198, /200], perturbed=True), 1), (BoundSqr(name=/202/sqr, inputs=[/200], perturbed=True), 0)]
  BoundLinear(name=/input.7, inputs=[/100, /23, /24], perturbed=True): [(BoundRelu(name=/102, inputs=[/input.7], perturbed=True), 0)]
  BoundGather(name=/198, inputs=[/181, /197], perturbed=True): [(BoundMul(name=/205, inputs=[/198, /200], perturbed=True), 0), (BoundSqr(name=/201/sqr, inputs=[/198], perturbed=True), 0)]
  BoundCos(name=/203, inputs=[/196], perturbed=True): [(BoundMul(name=/206, inputs=[/205, /203], perturbed=True), 1)]
  BoundSin(name=/204, inputs=[/196], perturbed=True): [(BoundMul(name=/207, inputs=[/205, /204], perturbed=True), 1)]
  BoundAdd(name=/222, inputs=[/220, /221], perturbed=True): [(BoundSqr(name=/303/sqr, inputs=[/222], perturbed=True), 0)]
  BoundLinear(name=/input.3, inputs=[/98, /21, /22], perturbed=True): [(BoundRelu(name=/100, inputs=[/input.3], perturbed=True), 0)]
  BoundMul(name=/205, inputs=[/198, /200], perturbed=True): [(BoundMul(name=/206, inputs=[/205, /203], perturbed=True), 0), (BoundMul(name=/207, inputs=[/205, /204], perturbed=True), 0)]
  BoundAdd(name=/226, inputs=[/224, /225], perturbed=True): [(BoundSqr(name=/304/sqr, inputs=[/226], perturbed=True), 0)]
  BoundLinear(name=/input, inputs=[/0, /19, /20], perturbed=True): [(BoundRelu(name=/98, inputs=[/input], perturbed=True), 0)]
  BoundSub(name=/196, inputs=[/193, /195], perturbed=True): [(BoundCos(name=/203, inputs=[/196], perturbed=True), 0), (BoundSin(name=/204, inputs=[/196], perturbed=True), 0)]
  BoundSlice(name=/116, inputs=[/103, /113, /115, /111], perturbed=True): [(BoundSigmoid(name=/117, inputs=[/116], perturbed=True), 0)]
  BoundAdd(name=/213, inputs=[/211, /212], perturbed=True): [(BoundSqr(name=/299/sqr, inputs=[/213], perturbed=True), 0)]
  BoundSlice(name=/181, inputs=[/130, /178, /180, /176], perturbed=True): [(BoundSqr(name=/323/sqr, inputs=[/181], perturbed=True), 0)]
  BoundAdd(name=/218, inputs=[/216, /217], perturbed=True): [(BoundSqr(name=/300/sqr, inputs=[/218], perturbed=True), 0)]
Nonlinear functions:
   BoundRelu(name=/98, inputs=[/input], perturbed=True)
   BoundRelu(name=/100, inputs=[/input.3], perturbed=True)
   BoundRelu(name=/102, inputs=[/input.7], perturbed=True)
   BoundSigmoid(name=/117, inputs=[/116], perturbed=True)
   BoundCos(name=/203, inputs=[/196], perturbed=True)
   BoundSin(name=/204, inputs=[/196], perturbed=True)
   BoundMul(name=/205, inputs=[/198, /200], perturbed=True)
   BoundMul(name=/206, inputs=[/205, /203], perturbed=True)
   BoundMul(name=/207, inputs=[/205, /204], perturbed=True)
   BoundSqr(name=/201/sqr, inputs=[/198], perturbed=True)
   BoundSqr(name=/202/sqr, inputs=[/200], perturbed=True)
   BoundSqr(name=/299/sqr, inputs=[/213], perturbed=True)
   BoundSqr(name=/300/sqr, inputs=[/218], perturbed=True)
   BoundSqr(name=/303/sqr, inputs=[/222], perturbed=True)
   BoundSqr(name=/304/sqr, inputs=[/226], perturbed=True)
   BoundSqr(name=/323/sqr, inputs=[/181], perturbed=True)
layer /98 start_node /input.3 using full alpha [2, 128, 1, 128] with unstable size None total_size 128 output_shape torch.Size([128])
layer /98 start_node /input.7 using full alpha [2, 256, 1, 128] with unstable size None total_size 256 output_shape torch.Size([256])
layer /98 start_node /116 using full alpha [2, 226, 1, 128] with unstable size None total_size 226 output_shape torch.Size([226])
layer /98 start_node /198 using full alpha [2, 186, 1, 128] with unstable size None total_size 186 output_shape torch.Size([186])
layer /98 start_node /200 using full alpha [2, 186, 1, 128] with unstable size None total_size 186 output_shape torch.Size([186])
layer /98 start_node /196 using full alpha [2, 186, 1, 128] with unstable size None total_size 186 output_shape torch.Size([186])
layer /98 start_node /205 using full alpha [2, 186, 1, 128] with unstable size None total_size 186 output_shape torch.Size([186])
layer /98 start_node /213 using full alpha [2, 186, 1, 128] with unstable size None total_size 186 output_shape torch.Size([186])
layer /98 start_node /218 using full alpha [2, 186, 1, 128] with unstable size None total_size 186 output_shape torch.Size([186])
layer /98 start_node /222 using full alpha [2, 186, 1, 128] with unstable size None total_size 186 output_shape torch.Size([186])
layer /98 start_node /226 using full alpha [2, 186, 1, 128] with unstable size None total_size 186 output_shape torch.Size([186])
layer /98 start_node /181 using full alpha [2, 118, 1, 128] with unstable size None total_size 118 output_shape torch.Size([118])
layer /98 start_node /334 using full alpha [2, 1, 1, 128] with unstable size None total_size 1 output_shape 1
layer /100 start_node /input.7 using full alpha [2, 256, 1, 128] with unstable size None total_size 256 output_shape torch.Size([256])
layer /100 start_node /116 using full alpha [2, 226, 1, 128] with unstable size None total_size 226 output_shape torch.Size([226])
layer /100 start_node /198 using full alpha [2, 186, 1, 128] with unstable size None total_size 186 output_shape torch.Size([186])
layer /100 start_node /200 using full alpha [2, 186, 1, 128] with unstable size None total_size 186 output_shape torch.Size([186])
layer /100 start_node /196 using full alpha [2, 186, 1, 128] with unstable size None total_size 186 output_shape torch.Size([186])
layer /100 start_node /205 using full alpha [2, 186, 1, 128] with unstable size None total_size 186 output_shape torch.Size([186])
layer /100 start_node /213 using full alpha [2, 186, 1, 128] with unstable size None total_size 186 output_shape torch.Size([186])
layer /100 start_node /218 using full alpha [2, 186, 1, 128] with unstable size None total_size 186 output_shape torch.Size([186])
layer /100 start_node /222 using full alpha [2, 186, 1, 128] with unstable size None total_size 186 output_shape torch.Size([186])
layer /100 start_node /226 using full alpha [2, 186, 1, 128] with unstable size None total_size 186 output_shape torch.Size([186])
layer /100 start_node /181 using full alpha [2, 118, 1, 128] with unstable size None total_size 118 output_shape torch.Size([118])
layer /100 start_node /334 using full alpha [2, 1, 1, 128] with unstable size None total_size 1 output_shape 1
layer /102 start_node /116 using full alpha [2, 226, 1, 256] with unstable size None total_size 226 output_shape torch.Size([226])
layer /102 start_node /198 using full alpha [2, 186, 1, 256] with unstable size None total_size 186 output_shape torch.Size([186])
layer /102 start_node /200 using full alpha [2, 186, 1, 256] with unstable size None total_size 186 output_shape torch.Size([186])
layer /102 start_node /196 using full alpha [2, 186, 1, 256] with unstable size None total_size 186 output_shape torch.Size([186])
layer /102 start_node /205 using full alpha [2, 186, 1, 256] with unstable size None total_size 186 output_shape torch.Size([186])
layer /102 start_node /213 using full alpha [2, 186, 1, 256] with unstable size None total_size 186 output_shape torch.Size([186])
layer /102 start_node /218 using full alpha [2, 186, 1, 256] with unstable size None total_size 186 output_shape torch.Size([186])
layer /102 start_node /222 using full alpha [2, 186, 1, 256] with unstable size None total_size 186 output_shape torch.Size([186])
layer /102 start_node /226 using full alpha [2, 186, 1, 256] with unstable size None total_size 186 output_shape torch.Size([186])
layer /102 start_node /181 using full alpha [2, 118, 1, 256] with unstable size None total_size 118 output_shape torch.Size([118])
layer /102 start_node /334 using full alpha [2, 1, 1, 256] with unstable size None total_size 1 output_shape 1
Optimizable variables initialized.
initial CROWN bounds: tensor([[-214.38096619]], device='cuda:0') None
best_l after optimization: -13.642627716064453
alpha/beta optimization time: 24.75331163406372
initial alpha-crown bounds: tensor([[-13.64262772]], device='cuda:0')
Worst class: (+ rhs) -13.642627716064453
Missing A for BoundCos(name=/203, inputs=[/196], perturbed=True). Making an additional CROWN call.
Missing A for BoundSin(name=/204, inputs=[/196], perturbed=True). Making an additional CROWN call.
Total VNNLIB file length: 1, max property batch size: 1, total number of batches: 1
lA shape: [torch.Size([1, 1, 128]), torch.Size([1, 1, 128]), torch.Size([1, 1, 256]), torch.Size([1, 1, 226]), torch.Size([1, 1, 186]), torch.Size([1, 1, 186]), torch.Size([1, 1, 186]), torch.Size([1, 1, 186]), torch.Size([1, 1, 186]), torch.Size([1, 1, 186]), torch.Size([1, 1, 186]), torch.Size([1, 1, 186]), torch.Size([1, 1, 186]), torch.Size([1, 1, 186]), torch.Size([1, 1, 186]), torch.Size([1, 1, 118])]

Properties batch 0, size 1
Remaining timeout: 570.4598639011383
##### Instance 0 first 10 spec matrices: 
tensor([[[0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64)
thresholds: tensor([-0.07930000], device='cuda:0') ######
torch allclose failed: norm 0.000155449757585302
Model prediction is: tensor([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  ...,
         6.71386719e-04, -2.11969018e-04,  3.83257866e-05], device='cuda:0')
build_with_refined_bounds batch [1/1]
setting alpha for layer /98 start_node /334 with alignment adjustment
setting alpha for layer /100 start_node /334 with alignment adjustment
setting alpha for layer /102 start_node /334 with alignment adjustment
setting alpha for layer /117 start_node /334 with alignment adjustment
setting alpha for layer /201/sqr start_node /334 with alignment adjustment
setting alpha for layer /202/sqr start_node /334 with alignment adjustment
setting alpha for layer /299/sqr start_node /334 with alignment adjustment
setting alpha for layer /300/sqr start_node /334 with alignment adjustment
setting alpha for layer /303/sqr start_node /334 with alignment adjustment
setting alpha for layer /304/sqr start_node /334 with alignment adjustment
setting alpha for layer /323/sqr start_node /334 with alignment adjustment
setting alpha for layer /205 start_node /334 with alignment adjustment
setting alpha for layer /206 start_node /334 with alignment adjustment
setting alpha for layer /207 start_node /334 with alignment adjustment
all alpha initialized
true A is required, we do a full backward CROWN pass to obtain it
(alpha-)CROWN with fixed intermediate bounds: tensor([[-13.58024216]], device='cuda:0') tensor([[62.88489914]], device='cuda:0')
Intermediate layers: /200,/input.7,/198,/203,/204,/222,/input.3,/205,/226,/input,/196,/116,/213,/181,/218,/334
Keeping alphas for these layers: ['/334']
Keeping alphas for these layers: ['/334']
Node /98 input 0: size torch.Size([128]) unstable 64
Node /100 input 0: size torch.Size([128]) unstable 74
Node /102 input 0: size torch.Size([256]) unstable 197
Node /117 input 0: size torch.Size([226]) unstable 226
Node /203 input 0: size torch.Size([186]) unstable 186
Node /204 input 0: size torch.Size([186]) unstable 186
Node /205 input 0: size torch.Size([186]) unstable 186
Node /205 input 1: size torch.Size([186]) unstable 186
Node /206 input 0: size torch.Size([186]) unstable 186
Node /206 input 1: size torch.Size([186]) unstable 186
Node /207 input 0: size torch.Size([186]) unstable 186
Node /207 input 1: size torch.Size([186]) unstable 186
Node /201/sqr input 0: size torch.Size([186]) unstable 186
Node /202/sqr input 0: size torch.Size([186]) unstable 186
Node /299/sqr input 0: size torch.Size([186]) unstable 186
Node /300/sqr input 0: size torch.Size([186]) unstable 186
Node /303/sqr input 0: size torch.Size([186]) unstable 186
Node /304/sqr input 0: size torch.Size([186]) unstable 186
Node /323/sqr input 0: size torch.Size([118]) unstable 118
-----------------
# of unstable neurons: 3283
-----------------

BaB round 1
batch: 1
Start filtering...
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 16.49it/s]
kfsb scores (first 10): tensor([[ -1.80945015],
        [ -0.09614563],
        [-13.50094032]], device='cuda:0')
kfsb choice (first 10): tensor([1], device='cuda:0')
Filtering time: 0.0817265510559082
splitting decisions: 
split level 0: [/218, 101] 
Time: prepare 0.0013    bound 0.7647    transfer 0.0006    finalize 0.0017    func 0.7684    
Accumulated time: func 0.7684    prepare 0.0015    bound 0.7647    transfer 0.0006    finalize 0.0017    
Current worst splitting domains lb-rhs (depth):
-13.12927 (1), 
length of domains: 1
Time: pickout 0.0028    decision 0.2673    set_bounds 0.0023    solve 0.7685    add 0.0021    
Accumulated time: pickout 0.0028    decision 0.2673    set_bounds 0.0023    solve 0.7685    add 0.0021    
Sorting batched domains takes 0.0011513233184814453 seconds.
Current (lb-rhs): -13.129274368286133
1 domains visited
Cumulative time: 1.1946613788604736

BaB round 2
batch: 1
Start filtering...
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 18.87it/s]
kfsb scores (first 10): tensor([[  0.66829872],
        [-39.96570587],
        [ -3.56500053]], device='cuda:0')
kfsb choice (first 10): tensor([0], device='cuda:0')
Filtering time: 0.0573732852935791
splitting decisions: 
split level 0: [/213, 101] 
Time: prepare 0.0018    bound 0.7892    transfer 0.0006    finalize 0.0014    func 0.7930    
Accumulated time: func 1.5614    prepare 0.0035    bound 1.5539    transfer 0.0012    finalize 0.0031    
Current worst splitting domains lb-rhs (depth):
-7.37931 (2), 
length of domains: 1
Time: pickout 0.0024    decision 0.1832    set_bounds 0.0022    solve 0.7930    add 0.0019    
Accumulated time: pickout 0.0052    decision 0.4505    set_bounds 0.0045    solve 1.5615    add 0.0040    
Sorting batched domains takes 0.0011243820190429688 seconds.
Current (lb-rhs): -7.379310607910156
2 domains visited
Cumulative time: 2.178945779800415

BaB round 3
batch: 1
Start filtering...
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 18.06it/s]
kfsb scores (first 10): tensor([[-25.49604797],
        [  0.85904694],
        [ -0.12181473]], device='cuda:0')
kfsb choice (first 10): tensor([1], device='cuda:0')
Filtering time: 0.06013298034667969
splitting decisions: 
split level 0: [/213, 101] 
Time: prepare 0.0024    bound 0.7973    transfer 0.0006    finalize 0.0014    func 0.8017    
Accumulated time: func 2.3632    prepare 0.0060    bound 2.3513    transfer 0.0018    finalize 0.0045    
Current worst splitting domains lb-rhs (depth):
-5.27429 (3), 
length of domains: 1
Time: pickout 0.0024    decision 0.1859    set_bounds 0.0032    solve 0.8018    add 0.0019    
Accumulated time: pickout 0.0076    decision 0.6365    set_bounds 0.0077    solve 2.3633    add 0.0059    
Sorting batched domains takes 0.0011081695556640625 seconds.
Current (lb-rhs): -5.2742919921875
3 domains visited
Cumulative time: 3.1756038665771484

BaB round 4
batch: 1
Start filtering...
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 18.78it/s]
kfsb scores (first 10): tensor([[-24.83985901],
        [  0.92071533],
        [ -1.96983337]], device='cuda:0')
kfsb choice (first 10): tensor([1], device='cuda:0')
Filtering time: 0.05760812759399414
splitting decisions: 
split level 0: [/116, 173] 

all verified at 3th iter
Time: prepare 0.0020    bound 0.3070    transfer 0.0006    finalize 0.0014    func 0.3110    
Accumulated time: func 2.6742    prepare 0.0082    bound 2.6583    transfer 0.0023    finalize 0.0059    
length of domains: 0
Time: pickout 0.0024    decision 0.1837    set_bounds 0.0022    solve 0.3111    add 0.0001    
Accumulated time: pickout 0.0100    decision 0.8202    set_bounds 0.0099    solve 2.6744    add 0.0060    
No domains left, verification finished!
Current (lb-rhs): 1.0000000116860974e-07
3 domains visited
Cumulative time: 3.675304651260376

Result: safe in 33.8399 seconds
############# Summary #############
Final verified acc: 100.0% (total 1 examples)
Problem instances count: 1 , total verified (safe/unsat): 1 , total falsified (unsafe/sat): 0 , timeout: 0
mean time for ALL instances (total 1):33.83952037516673, max time: 33.83985877037048
mean time for verified SAFE instances(total 1): 33.83985877037048, max time: 33.83985877037048
safe (total 1), index: [0]
Result dict saved to /home/hongjixu/Verifier_Development/tests/gpu_tests/vnncomp23/ml4acopf/master_outputs/0.pkl.
