Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  sparse_alpha: true
  save_adv_example: false
  precompile_jit: false
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: cifar10_resnet_instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2021/benchmarks/cifar10_resnet
model:
  name: null
  path: null
  onnx_path: null
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: default_onnx_and_vnnlib_loader
  onnx_optimization_flags: none
data:
  start: 62
  end: 63
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: null
  vnnlib_path_prefix: ''
solver:
  batch_size: 2000
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
    full_conv_alpha: true
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.01
    lr_decay: 0.98
    optimizer: adam
    iteration: 50
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 360
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_intermediate_layers: ''
  interm_transfer: true
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
    _tmp_cuts: null
    fixed_cuts: false
    add_implied_cuts: false
    add_input_cuts: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    sb_coeff_thresh: 0.001
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sort_domain_interval: -1
    nonlinear_split:
      method: babsr_like
      branching_point_method: middle
      num_branches: 2
      branching_point_refinement: false
      naive_branching_score: false
      filter: false
      prioritize_mul: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 30.0
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  cex_path: ./test_cex.txt
  attack_mode: PGD
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 5000000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue Mar 28 14:28:57 2023 on zeratul
customized start/end sample from instance 62 to 63 in cifar10_resnet_instances.csv
Internal results will be saved to a-b-crown_[cifar10_resnet_instances]_start=62_end=63_iter=50_b=2000_timeout=360_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.01_PGD=skip_cplex_cuts=False_initial_max_domains=1.npz.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 62 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx onnx/resnet_4b.onnx
Using vnnlib vnnlib_properties_pgd_filtered/resnet4b_pgd_filtered/prop_14_eps_0.004.vnnlib
Precompiled vnnlib file found at ../../vnncomp2021/benchmarks/cifar10_resnet/vnnlib_properties_pgd_filtered/resnet4b_pgd_filtered/prop_14_eps_0.004.vnnlib.compiled
Loading onnx ../../vnncomp2021/benchmarks/cifar10_resnet/onnx/resnet_4b.onnx wih quirks {}
Model: BoundedModule(
  (/input.1): BoundInput(name=/input.1, inputs=[])
  (/27): BoundParams(name=/27, inputs=[])
  (/28): BoundParams(name=/28, inputs=[])
  (/29): BoundParams(name=/29, inputs=[])
  (/30): BoundParams(name=/30, inputs=[])
  (/31): BoundParams(name=/31, inputs=[])
  (/32): BoundParams(name=/32, inputs=[])
  (/33): BoundParams(name=/33, inputs=[])
  (/34): BoundParams(name=/34, inputs=[])
  (/35): BoundParams(name=/35, inputs=[])
  (/36): BoundParams(name=/36, inputs=[])
  (/37): BoundParams(name=/37, inputs=[])
  (/38): BoundParams(name=/38, inputs=[])
  (/39): BoundParams(name=/39, inputs=[])
  (/40): BoundParams(name=/40, inputs=[])
  (/41): BoundParams(name=/41, inputs=[])
  (/42): BoundParams(name=/42, inputs=[])
  (/43): BoundParams(name=/43, inputs=[])
  (/44): BoundParams(name=/44, inputs=[])
  (/45): BoundParams(name=/45, inputs=[])
  (/46): BoundParams(name=/46, inputs=[])
  (/47): BoundParams(name=/47, inputs=[])
  (/48): BoundParams(name=/48, inputs=[])
  (/49): BoundParams(name=/49, inputs=[])
  (/50): BoundParams(name=/50, inputs=[])
  (/51): BoundParams(name=/51, inputs=[])
  (/52): BoundParams(name=/52, inputs=[])
  (/input): BoundConv(name=/input, inputs=[/input.1, /27, /28])
  (/54): BoundRelu(name=/54, inputs=[/input])
  (/input.4): BoundConv(name=/input.4, inputs=[/54, /29, /30])
  (/56): BoundRelu(name=/56, inputs=[/input.4])
  (/57): BoundConv(name=/57, inputs=[/56, /31, /32])
  (/58): BoundConv(name=/58, inputs=[/54, /33, /34])
  (/59): BoundAdd(name=/59, inputs=[/57, /58])
  (/input.8): BoundRelu(name=/input.8, inputs=[/59])
  (/input.12): BoundConv(name=/input.12, inputs=[/input.8, /35, /36])
  (/62): BoundRelu(name=/62, inputs=[/input.12])
  (/63): BoundConv(name=/63, inputs=[/62, /37, /38])
  (/64): BoundAdd(name=/64, inputs=[/63, /input.8])
  (/input.16): BoundRelu(name=/input.16, inputs=[/64])
  (/input.20): BoundConv(name=/input.20, inputs=[/input.16, /39, /40])
  (/67): BoundRelu(name=/67, inputs=[/input.20])
  (/68): BoundConv(name=/68, inputs=[/67, /41, /42])
  (/69): BoundConv(name=/69, inputs=[/input.16, /43, /44])
  (/70): BoundAdd(name=/70, inputs=[/68, /69])
  (/input.24): BoundRelu(name=/input.24, inputs=[/70])
  (/input.28): BoundConv(name=/input.28, inputs=[/input.24, /45, /46])
  (/73): BoundRelu(name=/73, inputs=[/input.28])
  (/74): BoundConv(name=/74, inputs=[/73, /47, /48])
  (/75): BoundAdd(name=/75, inputs=[/74, /input.24])
  (/76): BoundRelu(name=/76, inputs=[/75])
  (/77): BoundFlatten(name=/77, inputs=[/76])
  (/input.32): BoundLinear(name=/input.32, inputs=[/77, /49, /50])
  (/79): BoundRelu(name=/79, inputs=[/input.32])
  (/80): BoundLinear(name=/80, inputs=[/79, /51, /52])
)
Model prediction is: tensor([[ 1.13689673, -1.69910777, -0.77371299,  0.36231494, -1.27489316,
         -0.52829957, -1.23019004, -0.75381345,  5.67982864, -0.81278360]],
       device='cuda:0')
layer /54 using sparse-features alpha with shape [445]; unstable size 445; total size 4096 (torch.Size([1, 16, 16, 16]))
layer /54 start_node /input.4 using sparse-spec alpha with unstable size 196 total_size 2048 output_shape (32, 8, 8)
layer /54 start_node /59 using sparse-spec alpha with unstable size 189 total_size 2048 output_shape (32, 8, 8)
layer /54 start_node /input.12 using sparse-spec alpha with unstable size 242 total_size 2048 output_shape (32, 8, 8)
layer /54 start_node /64 using sparse-spec alpha with unstable size 385 total_size 2048 output_shape (32, 8, 8)
layer /54 start_node /input.20 using sparse-spec alpha with unstable size 106 total_size 512 output_shape torch.Size([32, 4, 4])
layer /54 start_node /70 using sparse-spec alpha with unstable size 144 total_size 512 output_shape torch.Size([32, 4, 4])
layer /54 start_node /input.28 using sparse-spec alpha with unstable size 152 total_size 512 output_shape torch.Size([32, 4, 4])
layer /54 start_node /75 using sparse-spec alpha with unstable size 267 total_size 512 output_shape torch.Size([32, 4, 4])
layer /54 start_node /input.32 using sparse-spec alpha with unstable size 79 total_size 100 output_shape torch.Size([100])
layer /54 start_node /80 using full alpha with unstable size None total_size 9 output_shape 9
layer /56 using sparse-features alpha with shape [196]; unstable size 196; total size 2048 (torch.Size([1, 32, 8, 8]))
layer /56 start_node /59 using sparse-spec alpha with unstable size 189 total_size 2048 output_shape (32, 8, 8)
layer /56 start_node /input.12 using sparse-spec alpha with unstable size 242 total_size 2048 output_shape (32, 8, 8)
layer /56 start_node /64 using sparse-spec alpha with unstable size 385 total_size 2048 output_shape (32, 8, 8)
layer /56 start_node /input.20 using sparse-spec alpha with unstable size 106 total_size 512 output_shape torch.Size([32, 4, 4])
layer /56 start_node /70 using sparse-spec alpha with unstable size 144 total_size 512 output_shape torch.Size([32, 4, 4])
layer /56 start_node /input.28 using sparse-spec alpha with unstable size 152 total_size 512 output_shape torch.Size([32, 4, 4])
layer /56 start_node /75 using sparse-spec alpha with unstable size 267 total_size 512 output_shape torch.Size([32, 4, 4])
layer /56 start_node /input.32 using sparse-spec alpha with unstable size 79 total_size 100 output_shape torch.Size([100])
layer /56 start_node /80 using full alpha with unstable size None total_size 9 output_shape 9
layer /input.8 using sparse-features alpha with shape [189]; unstable size 189; total size 2048 (torch.Size([1, 32, 8, 8]))
layer /input.8 start_node /input.12 using sparse-spec alpha with unstable size 242 total_size 2048 output_shape (32, 8, 8)
layer /input.8 start_node /64 using sparse-spec alpha with unstable size 385 total_size 2048 output_shape (32, 8, 8)
layer /input.8 start_node /input.20 using sparse-spec alpha with unstable size 106 total_size 512 output_shape (32, 4, 4)
layer /input.8 start_node /70 using sparse-spec alpha with unstable size 144 total_size 512 output_shape torch.Size([32, 4, 4])
layer /input.8 start_node /input.28 using sparse-spec alpha with unstable size 152 total_size 512 output_shape torch.Size([32, 4, 4])
layer /input.8 start_node /75 using sparse-spec alpha with unstable size 267 total_size 512 output_shape torch.Size([32, 4, 4])
layer /input.8 start_node /input.32 using sparse-spec alpha with unstable size 79 total_size 100 output_shape torch.Size([100])
layer /input.8 start_node /80 using full alpha with unstable size None total_size 9 output_shape 9
layer /62 using sparse-features alpha with shape [242]; unstable size 242; total size 2048 (torch.Size([1, 32, 8, 8]))
layer /62 start_node /64 using sparse-spec alpha with unstable size 385 total_size 2048 output_shape (32, 8, 8)
layer /62 start_node /input.20 using sparse-spec alpha with unstable size 106 total_size 512 output_shape (32, 4, 4)
layer /62 start_node /70 using sparse-spec alpha with unstable size 144 total_size 512 output_shape torch.Size([32, 4, 4])
layer /62 start_node /input.28 using sparse-spec alpha with unstable size 152 total_size 512 output_shape torch.Size([32, 4, 4])
layer /62 start_node /75 using sparse-spec alpha with unstable size 267 total_size 512 output_shape torch.Size([32, 4, 4])
layer /62 start_node /input.32 using sparse-spec alpha with unstable size 79 total_size 100 output_shape torch.Size([100])
layer /62 start_node /80 using full alpha with unstable size None total_size 9 output_shape 9
layer /input.16 using sparse-features alpha with shape [385]; unstable size 385; total size 2048 (torch.Size([1, 32, 8, 8]))
layer /input.16 start_node /input.20 using sparse-spec alpha with unstable size 106 total_size 512 output_shape (32, 4, 4)
layer /input.16 start_node /70 using sparse-spec alpha with unstable size 144 total_size 512 output_shape (32, 4, 4)
layer /input.16 start_node /input.28 using sparse-spec alpha with unstable size 152 total_size 512 output_shape torch.Size([32, 4, 4])
layer /input.16 start_node /75 using sparse-spec alpha with unstable size 267 total_size 512 output_shape torch.Size([32, 4, 4])
layer /input.16 start_node /input.32 using sparse-spec alpha with unstable size 79 total_size 100 output_shape torch.Size([100])
layer /input.16 start_node /80 using full alpha with unstable size None total_size 9 output_shape 9
layer /67 using sparse-features alpha with shape [106]; unstable size 106; total size 512 (torch.Size([1, 32, 4, 4]))
layer /67 start_node /70 using sparse-spec alpha with unstable size 144 total_size 512 output_shape (32, 4, 4)
layer /67 start_node /input.28 using sparse-spec alpha with unstable size 152 total_size 512 output_shape torch.Size([32, 4, 4])
layer /67 start_node /75 using sparse-spec alpha with unstable size 267 total_size 512 output_shape torch.Size([32, 4, 4])
layer /67 start_node /input.32 using sparse-spec alpha with unstable size 79 total_size 100 output_shape torch.Size([100])
layer /67 start_node /80 using full alpha with unstable size None total_size 9 output_shape 9
layer /input.24 using sparse-features alpha with shape [144]; unstable size 144; total size 512 (torch.Size([1, 32, 4, 4]))
layer /input.24 start_node /input.28 using sparse-spec alpha with unstable size 152 total_size 512 output_shape (32, 4, 4)
layer /input.24 start_node /75 using sparse-spec alpha with unstable size 267 total_size 512 output_shape torch.Size([32, 4, 4])
layer /input.24 start_node /input.32 using sparse-spec alpha with unstable size 79 total_size 100 output_shape torch.Size([100])
layer /input.24 start_node /80 using full alpha with unstable size None total_size 9 output_shape 9
layer /73 using sparse-features alpha with shape [152]; unstable size 152; total size 512 (torch.Size([1, 32, 4, 4]))
layer /73 start_node /75 using sparse-spec alpha with unstable size 267 total_size 512 output_shape (32, 4, 4)
layer /73 start_node /input.32 using sparse-spec alpha with unstable size 79 total_size 100 output_shape torch.Size([100])
layer /73 start_node /80 using full alpha with unstable size None total_size 9 output_shape 9
layer /76 using sparse-features alpha with shape [267]; unstable size 267; total size 512 (torch.Size([1, 32, 4, 4]))
layer /76 start_node /input.32 using sparse-spec alpha with unstable size 79 total_size 100 output_shape torch.Size([100])
layer /76 start_node /80 using full alpha with unstable size None total_size 9 output_shape 9
layer /79 using sparse-features alpha with shape [79]; unstable size 79; total size 100 (torch.Size([1, 100]))
layer /79 start_node /80 using full alpha with unstable size None total_size 9 output_shape 9
Optimizable variables initialized.
initial CROWN bounds: tensor([[-2.10904336, -0.41920316, -3.07417870, -2.59466696, -2.29753733,
         -2.28992653, -1.32546806, -3.86168575, -2.47135258]], device='cuda:0') None
best_l after optimization: 0.46555542945861816
alpha/beta optimization time: 46.72104239463806
initial alpha-CROWN bounds: tensor([[-0.23666620,  1.51479352, -0.30380106, -0.43290615,  0.08095217,
          0.11561823,  1.05317736, -1.09978199, -0.22583044]], device='cuda:0')
Worst class: (+ rhs) -1.0997819900512695
Split layers:
  BoundConv(name=/input.12, inputs=[/input.8, /35, /36]): [(BoundRelu(name=/62, inputs=[/input.12]), 0)]
  BoundConv(name=/input.20, inputs=[/input.16, /39, /40]): [(BoundRelu(name=/67, inputs=[/input.20]), 0)]
  BoundConv(name=/input, inputs=[/input.1, /27, /28]): [(BoundRelu(name=/54, inputs=[/input]), 0)]
  BoundAdd(name=/59, inputs=[/57, /58]): [(BoundRelu(name=/input.8, inputs=[/59]), 0)]
  BoundAdd(name=/75, inputs=[/74, /input.24]): [(BoundRelu(name=/76, inputs=[/75]), 0)]
  BoundAdd(name=/70, inputs=[/68, /69]): [(BoundRelu(name=/input.24, inputs=[/70]), 0)]
  BoundConv(name=/input.4, inputs=[/54, /29, /30]): [(BoundRelu(name=/56, inputs=[/input.4]), 0)]
  BoundConv(name=/input.28, inputs=[/input.24, /45, /46]): [(BoundRelu(name=/73, inputs=[/input.28]), 0)]
  BoundLinear(name=/input.32, inputs=[/77, /49, /50]): [(BoundRelu(name=/79, inputs=[/input.32]), 0)]
  BoundAdd(name=/64, inputs=[/63, /input.8]): [(BoundRelu(name=/input.16, inputs=[/64]), 0)]
Total VNNLIB file length: 9, max property batch size: 1, total number of batches: 9
lA shape: [torch.Size([1, 9, 16, 16, 16]), torch.Size([1, 9, 32, 8, 8]), torch.Size([1, 9, 32, 8, 8]), torch.Size([1, 9, 32, 8, 8]), torch.Size([1, 9, 32, 8, 8]), torch.Size([1, 9, 32, 4, 4]), torch.Size([1, 9, 32, 4, 4]), torch.Size([1, 9, 32, 4, 4]), torch.Size([1, 9, 32, 4, 4]), torch.Size([1, 9, 100])]

Properties batch 0, size 1
Remaining timeout: 240.92360830307007
##### Instance 0 first 10 spec matrices: 
tensor([[[-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]]],
       dtype=torch.float64)
thresholds: [0.] ######
Remaining spec index [0] with bounds tensor([[-0.23666620]], device='cuda:0') need to verify.
Model: BoundedModule(
  (/input.1): BoundInput(name=/input.1, inputs=[])
  (/27): BoundParams(name=/27, inputs=[])
  (/28): BoundParams(name=/28, inputs=[])
  (/29): BoundParams(name=/29, inputs=[])
  (/30): BoundParams(name=/30, inputs=[])
  (/31): BoundParams(name=/31, inputs=[])
  (/32): BoundParams(name=/32, inputs=[])
  (/33): BoundParams(name=/33, inputs=[])
  (/34): BoundParams(name=/34, inputs=[])
  (/35): BoundParams(name=/35, inputs=[])
  (/36): BoundParams(name=/36, inputs=[])
  (/37): BoundParams(name=/37, inputs=[])
  (/38): BoundParams(name=/38, inputs=[])
  (/39): BoundParams(name=/39, inputs=[])
  (/40): BoundParams(name=/40, inputs=[])
  (/41): BoundParams(name=/41, inputs=[])
  (/42): BoundParams(name=/42, inputs=[])
  (/43): BoundParams(name=/43, inputs=[])
  (/44): BoundParams(name=/44, inputs=[])
  (/45): BoundParams(name=/45, inputs=[])
  (/46): BoundParams(name=/46, inputs=[])
  (/47): BoundParams(name=/47, inputs=[])
  (/48): BoundParams(name=/48, inputs=[])
  (/49): BoundParams(name=/49, inputs=[])
  (/50): BoundParams(name=/50, inputs=[])
  (/51): BoundParams(name=/51, inputs=[])
  (/52): BoundParams(name=/52, inputs=[])
  (/input): BoundConv(name=/input, inputs=[/input.1, /27, /28])
  (/54): BoundRelu(name=/54, inputs=[/input])
  (/input.4): BoundConv(name=/input.4, inputs=[/54, /29, /30])
  (/56): BoundRelu(name=/56, inputs=[/input.4])
  (/57): BoundConv(name=/57, inputs=[/56, /31, /32])
  (/58): BoundConv(name=/58, inputs=[/54, /33, /34])
  (/59): BoundAdd(name=/59, inputs=[/57, /58])
  (/input.8): BoundRelu(name=/input.8, inputs=[/59])
  (/input.12): BoundConv(name=/input.12, inputs=[/input.8, /35, /36])
  (/62): BoundRelu(name=/62, inputs=[/input.12])
  (/63): BoundConv(name=/63, inputs=[/62, /37, /38])
  (/64): BoundAdd(name=/64, inputs=[/63, /input.8])
  (/input.16): BoundRelu(name=/input.16, inputs=[/64])
  (/input.20): BoundConv(name=/input.20, inputs=[/input.16, /39, /40])
  (/67): BoundRelu(name=/67, inputs=[/input.20])
  (/68): BoundConv(name=/68, inputs=[/67, /41, /42])
  (/69): BoundConv(name=/69, inputs=[/input.16, /43, /44])
  (/70): BoundAdd(name=/70, inputs=[/68, /69])
  (/input.24): BoundRelu(name=/input.24, inputs=[/70])
  (/input.28): BoundConv(name=/input.28, inputs=[/input.24, /45, /46])
  (/73): BoundRelu(name=/73, inputs=[/input.28])
  (/74): BoundConv(name=/74, inputs=[/73, /47, /48])
  (/75): BoundAdd(name=/75, inputs=[/74, /input.24])
  (/76): BoundRelu(name=/76, inputs=[/75])
  (/77): BoundFlatten(name=/77, inputs=[/76])
  (/input.32): BoundLinear(name=/input.32, inputs=[/77, /49, /50])
  (/79): BoundRelu(name=/79, inputs=[/input.32])
  (/80): BoundLinear(name=/80, inputs=[/79, /51, /52])
)
Model prediction is: tensor([ 1.13689673, -1.69910777, -0.77371299,  0.36231494, -1.27489316,
        -0.52829957, -1.23019004, -0.75381345,  5.67982864, -0.81278360],
       device='cuda:0')
build_with_refined_bounds batch [0/1]
setting alpha for layer /54 start_node /80 with alignment adjustment
setting alpha for layer /56 start_node /80 with alignment adjustment
setting alpha for layer /input.8 start_node /80 with alignment adjustment
setting alpha for layer /62 start_node /80 with alignment adjustment
setting alpha for layer /input.16 start_node /80 with alignment adjustment
setting alpha for layer /67 start_node /80 with alignment adjustment
setting alpha for layer /input.24 start_node /80 with alignment adjustment
setting alpha for layer /73 start_node /80 with alignment adjustment
setting alpha for layer /76 start_node /80 with alignment adjustment
setting alpha for layer /79 start_node /80 with alignment adjustment
all slope initialized
directly get lb and ub from refined bounds
lA shapes: [torch.Size([1, 1, 16, 16, 16]), torch.Size([1, 1, 32, 8, 8]), torch.Size([1, 1, 32, 8, 8]), torch.Size([1, 1, 32, 8, 8]), torch.Size([1, 1, 32, 8, 8]), torch.Size([1, 1, 32, 4, 4]), torch.Size([1, 1, 32, 4, 4]), torch.Size([1, 1, 32, 4, 4]), torch.Size([1, 1, 32, 4, 4]), torch.Size([1, 1, 100])]
c shape: torch.Size([1, 1, 10])
alpha-CROWN with fixed intermediate bounds: tensor([[-0.23666620]], device='cuda:0') tensor([[inf]], device='cuda:0')
Intermediate layers: /input.12,/input.20,/input,/59,/75,/70,/input.4,/input.28,/input.32,/64,/80
Split layers:
  BoundLinear(name=/input.32, inputs=[/77, /49, /50]): [(BoundRelu(name=/79, inputs=[/input.32]), 0)]
  BoundConv(name=/input, inputs=[/input.1, /27, /28]): [(BoundRelu(name=/54, inputs=[/input]), 0)]
  BoundAdd(name=/75, inputs=[/74, /input.24]): [(BoundRelu(name=/76, inputs=[/75]), 0)]
  BoundConv(name=/input.4, inputs=[/54, /29, /30]): [(BoundRelu(name=/56, inputs=[/input.4]), 0)]
  BoundAdd(name=/70, inputs=[/68, /69]): [(BoundRelu(name=/input.24, inputs=[/70]), 0)]
  BoundConv(name=/input.12, inputs=[/input.8, /35, /36]): [(BoundRelu(name=/62, inputs=[/input.12]), 0)]
  BoundConv(name=/input.28, inputs=[/input.24, /45, /46]): [(BoundRelu(name=/73, inputs=[/input.28]), 0)]
  BoundAdd(name=/59, inputs=[/57, /58]): [(BoundRelu(name=/input.8, inputs=[/59]), 0)]
  BoundAdd(name=/64, inputs=[/63, /input.8]): [(BoundRelu(name=/input.16, inputs=[/64]), 0)]
  BoundConv(name=/input.20, inputs=[/input.16, /39, /40]): [(BoundRelu(name=/67, inputs=[/input.20]), 0)]
Keeping slopes for these layers: ['/80']
Keeping slopes for these layers: ['/80']
Node /54 input 0: size torch.Size([16, 16, 16]) unstable 445
Node /56 input 0: size torch.Size([32, 8, 8]) unstable 194
Node /input.8 input 0: size torch.Size([32, 8, 8]) unstable 187
Node /62 input 0: size torch.Size([32, 8, 8]) unstable 239
Node /input.16 input 0: size torch.Size([32, 8, 8]) unstable 367
Node /67 input 0: size torch.Size([32, 4, 4]) unstable 101
Node /input.24 input 0: size torch.Size([32, 4, 4]) unstable 132
Node /73 input 0: size torch.Size([32, 4, 4]) unstable 143
Node /76 input 0: size torch.Size([32, 4, 4]) unstable 237
Node /79 input 0: size torch.Size([100]) unstable 72
-----------------
# of unstable neurons: 2117
-----------------

BaB round 1
batch: 1
Average branched neurons at iteration 1:  1.0000
splitting decisions: 
split level 0: [/input.32, 36] 
split level 1: [/input.32, 8] 
split level 2: [/input.32, 51] 
split level 3: [/input.32, 38] 
split level 4: [/input.32, 82] 
split level 5: [/input.32, 89] 
split level 6: [/input.32, 81] 

all verified at 0th iter
pruning_in_iteration open status: False
ratio of positive domain = 128 / 128 = 1.0
pruning-in-iteration extra time: 0.00014162063598632812
Time: prepare 0.0228    beta_bound 0.0691    bound 0.0692    transfer 0.0034    finalize 0.0293    func 0.1248    
Accumulated time: func 0.1248    prepare 0.0244    bound 0.0692    beta_bound 0.0691    transfer 0.0034    finalize 0.0293    
batch bounding time:  0.12501096725463867
length of domains: 0
Time: pickout 0.0044    decision 0.5728    set_bounds 0.0070    solve 0.1250    add 0.0003    
Accumulated time: pickout 0.0044    decision 0.5728    set_bounds 0.0070    solve 0.1250    add 0.0003    
No domains left, verification finished!
Current (lb-rhs): 1.0000000116860974e-07
0 domains visited
Cumulative time: 1.0032916069030762


Properties batch 1, size 1
Remaining timeout: 239.33383202552795
##### Instance 0 first 10 spec matrices: 
tensor([[[ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]]],
       dtype=torch.float64)
thresholds: [0.] ######
Initial alpha-CROWN verified for spec index [0] with bound 1.5147935152053833.

Properties batch 2, size 1
Remaining timeout: 239.2606589794159
##### Instance 0 first 10 spec matrices: 
tensor([[[ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]]],
       dtype=torch.float64)
thresholds: [0.] ######
Remaining spec index [0] with bounds tensor([[-0.30380106]], device='cuda:0') need to verify.
Model: BoundedModule(
  (/input.1): BoundInput(name=/input.1, inputs=[])
  (/27): BoundParams(name=/27, inputs=[])
  (/28): BoundParams(name=/28, inputs=[])
  (/29): BoundParams(name=/29, inputs=[])
  (/30): BoundParams(name=/30, inputs=[])
  (/31): BoundParams(name=/31, inputs=[])
  (/32): BoundParams(name=/32, inputs=[])
  (/33): BoundParams(name=/33, inputs=[])
  (/34): BoundParams(name=/34, inputs=[])
  (/35): BoundParams(name=/35, inputs=[])
  (/36): BoundParams(name=/36, inputs=[])
  (/37): BoundParams(name=/37, inputs=[])
  (/38): BoundParams(name=/38, inputs=[])
  (/39): BoundParams(name=/39, inputs=[])
  (/40): BoundParams(name=/40, inputs=[])
  (/41): BoundParams(name=/41, inputs=[])
  (/42): BoundParams(name=/42, inputs=[])
  (/43): BoundParams(name=/43, inputs=[])
  (/44): BoundParams(name=/44, inputs=[])
  (/45): BoundParams(name=/45, inputs=[])
  (/46): BoundParams(name=/46, inputs=[])
  (/47): BoundParams(name=/47, inputs=[])
  (/48): BoundParams(name=/48, inputs=[])
  (/49): BoundParams(name=/49, inputs=[])
  (/50): BoundParams(name=/50, inputs=[])
  (/51): BoundParams(name=/51, inputs=[])
  (/52): BoundParams(name=/52, inputs=[])
  (/input): BoundConv(name=/input, inputs=[/input.1, /27, /28])
  (/54): BoundRelu(name=/54, inputs=[/input])
  (/input.4): BoundConv(name=/input.4, inputs=[/54, /29, /30])
  (/56): BoundRelu(name=/56, inputs=[/input.4])
  (/57): BoundConv(name=/57, inputs=[/56, /31, /32])
  (/58): BoundConv(name=/58, inputs=[/54, /33, /34])
  (/59): BoundAdd(name=/59, inputs=[/57, /58])
  (/input.8): BoundRelu(name=/input.8, inputs=[/59])
  (/input.12): BoundConv(name=/input.12, inputs=[/input.8, /35, /36])
  (/62): BoundRelu(name=/62, inputs=[/input.12])
  (/63): BoundConv(name=/63, inputs=[/62, /37, /38])
  (/64): BoundAdd(name=/64, inputs=[/63, /input.8])
  (/input.16): BoundRelu(name=/input.16, inputs=[/64])
  (/input.20): BoundConv(name=/input.20, inputs=[/input.16, /39, /40])
  (/67): BoundRelu(name=/67, inputs=[/input.20])
  (/68): BoundConv(name=/68, inputs=[/67, /41, /42])
  (/69): BoundConv(name=/69, inputs=[/input.16, /43, /44])
  (/70): BoundAdd(name=/70, inputs=[/68, /69])
  (/input.24): BoundRelu(name=/input.24, inputs=[/70])
  (/input.28): BoundConv(name=/input.28, inputs=[/input.24, /45, /46])
  (/73): BoundRelu(name=/73, inputs=[/input.28])
  (/74): BoundConv(name=/74, inputs=[/73, /47, /48])
  (/75): BoundAdd(name=/75, inputs=[/74, /input.24])
  (/76): BoundRelu(name=/76, inputs=[/75])
  (/77): BoundFlatten(name=/77, inputs=[/76])
  (/input.32): BoundLinear(name=/input.32, inputs=[/77, /49, /50])
  (/79): BoundRelu(name=/79, inputs=[/input.32])
  (/80): BoundLinear(name=/80, inputs=[/79, /51, /52])
)
Model prediction is: tensor([ 1.13689673, -1.69910777, -0.77371299,  0.36231494, -1.27489316,
        -0.52829957, -1.23019004, -0.75381345,  5.67982864, -0.81278360],
       device='cuda:0')
build_with_refined_bounds batch [0/1]
setting alpha for layer /54 start_node /80 with alignment adjustment
setting alpha for layer /56 start_node /80 with alignment adjustment
setting alpha for layer /input.8 start_node /80 with alignment adjustment
setting alpha for layer /62 start_node /80 with alignment adjustment
setting alpha for layer /input.16 start_node /80 with alignment adjustment
setting alpha for layer /67 start_node /80 with alignment adjustment
setting alpha for layer /input.24 start_node /80 with alignment adjustment
setting alpha for layer /73 start_node /80 with alignment adjustment
setting alpha for layer /76 start_node /80 with alignment adjustment
setting alpha for layer /79 start_node /80 with alignment adjustment
all slope initialized
directly get lb and ub from refined bounds
lA shapes: [torch.Size([1, 1, 16, 16, 16]), torch.Size([1, 1, 32, 8, 8]), torch.Size([1, 1, 32, 8, 8]), torch.Size([1, 1, 32, 8, 8]), torch.Size([1, 1, 32, 8, 8]), torch.Size([1, 1, 32, 4, 4]), torch.Size([1, 1, 32, 4, 4]), torch.Size([1, 1, 32, 4, 4]), torch.Size([1, 1, 32, 4, 4]), torch.Size([1, 1, 100])]
c shape: torch.Size([1, 1, 10])
alpha-CROWN with fixed intermediate bounds: tensor([[-0.30380106]], device='cuda:0') tensor([[inf]], device='cuda:0')
Intermediate layers: /input.12,/input.20,/input,/59,/75,/70,/input.4,/input.28,/input.32,/64,/80
Split layers:
  BoundConv(name=/input.12, inputs=[/input.8, /35, /36]): [(BoundRelu(name=/62, inputs=[/input.12]), 0)]
  BoundConv(name=/input, inputs=[/input.1, /27, /28]): [(BoundRelu(name=/54, inputs=[/input]), 0)]
  BoundConv(name=/input.4, inputs=[/54, /29, /30]): [(BoundRelu(name=/56, inputs=[/input.4]), 0)]
  BoundConv(name=/input.20, inputs=[/input.16, /39, /40]): [(BoundRelu(name=/67, inputs=[/input.20]), 0)]
  BoundLinear(name=/input.32, inputs=[/77, /49, /50]): [(BoundRelu(name=/79, inputs=[/input.32]), 0)]
  BoundAdd(name=/59, inputs=[/57, /58]): [(BoundRelu(name=/input.8, inputs=[/59]), 0)]
  BoundAdd(name=/70, inputs=[/68, /69]): [(BoundRelu(name=/input.24, inputs=[/70]), 0)]
  BoundAdd(name=/75, inputs=[/74, /input.24]): [(BoundRelu(name=/76, inputs=[/75]), 0)]
  BoundAdd(name=/64, inputs=[/63, /input.8]): [(BoundRelu(name=/input.16, inputs=[/64]), 0)]
  BoundConv(name=/input.28, inputs=[/input.24, /45, /46]): [(BoundRelu(name=/73, inputs=[/input.28]), 0)]
Keeping slopes for these layers: ['/80']
Keeping slopes for these layers: ['/80']
Node /54 input 0: size torch.Size([16, 16, 16]) unstable 445
Node /56 input 0: size torch.Size([32, 8, 8]) unstable 194
Node /input.8 input 0: size torch.Size([32, 8, 8]) unstable 187
Node /62 input 0: size torch.Size([32, 8, 8]) unstable 239
Node /input.16 input 0: size torch.Size([32, 8, 8]) unstable 367
Node /67 input 0: size torch.Size([32, 4, 4]) unstable 101
Node /input.24 input 0: size torch.Size([32, 4, 4]) unstable 132
Node /73 input 0: size torch.Size([32, 4, 4]) unstable 143
Node /76 input 0: size torch.Size([32, 4, 4]) unstable 237
Node /79 input 0: size torch.Size([100]) unstable 72
-----------------
# of unstable neurons: 2117
-----------------

BaB round 1
batch: 1
Average branched neurons at iteration 1:  1.0000
splitting decisions: 
split level 0: [/input.32, 76] 
split level 1: [/input.32, 14] 
split level 2: [/input.32, 96] 
split level 3: [/input.32, 74] 
split level 4: [/input.32, 31] 
split level 5: [/input.32, 82] 
split level 6: [/input.32, 51] 

all verified at 0th iter
pruning_in_iteration open status: False
ratio of positive domain = 128 / 128 = 1.0
pruning-in-iteration extra time: 9.202957153320312e-05
Time: prepare 0.0206    beta_bound 0.0216    bound 0.0225    transfer 0.0026    finalize 0.0162    func 0.0620    
Accumulated time: func 0.0620    prepare 0.0221    bound 0.0225    beta_bound 0.0216    transfer 0.0026    finalize 0.0162    
batch bounding time:  0.06208181381225586
length of domains: 0
Time: pickout 0.0024    decision 0.1283    set_bounds 0.0041    solve 0.0621    add 0.0002    
Accumulated time: pickout 0.0024    decision 0.1283    set_bounds 0.0041    solve 0.0621    add 0.0002    
No domains left, verification finished!
Current (lb-rhs): 1.0000000116860974e-07
0 domains visited
Cumulative time: 0.2200639247894287


Properties batch 3, size 1
Remaining timeout: 238.67695808410645
##### Instance 0 first 10 spec matrices: 
tensor([[[ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  1.,  0.]]],
       dtype=torch.float64)
thresholds: [0.] ######
Remaining spec index [0] with bounds tensor([[-0.43290615]], device='cuda:0') need to verify.
Model: BoundedModule(
  (/input.1): BoundInput(name=/input.1, inputs=[])
  (/27): BoundParams(name=/27, inputs=[])
  (/28): BoundParams(name=/28, inputs=[])
  (/29): BoundParams(name=/29, inputs=[])
  (/30): BoundParams(name=/30, inputs=[])
  (/31): BoundParams(name=/31, inputs=[])
  (/32): BoundParams(name=/32, inputs=[])
  (/33): BoundParams(name=/33, inputs=[])
  (/34): BoundParams(name=/34, inputs=[])
  (/35): BoundParams(name=/35, inputs=[])
  (/36): BoundParams(name=/36, inputs=[])
  (/37): BoundParams(name=/37, inputs=[])
  (/38): BoundParams(name=/38, inputs=[])
  (/39): BoundParams(name=/39, inputs=[])
  (/40): BoundParams(name=/40, inputs=[])
  (/41): BoundParams(name=/41, inputs=[])
  (/42): BoundParams(name=/42, inputs=[])
  (/43): BoundParams(name=/43, inputs=[])
  (/44): BoundParams(name=/44, inputs=[])
  (/45): BoundParams(name=/45, inputs=[])
  (/46): BoundParams(name=/46, inputs=[])
  (/47): BoundParams(name=/47, inputs=[])
  (/48): BoundParams(name=/48, inputs=[])
  (/49): BoundParams(name=/49, inputs=[])
  (/50): BoundParams(name=/50, inputs=[])
  (/51): BoundParams(name=/51, inputs=[])
  (/52): BoundParams(name=/52, inputs=[])
  (/input): BoundConv(name=/input, inputs=[/input.1, /27, /28])
  (/54): BoundRelu(name=/54, inputs=[/input])
  (/input.4): BoundConv(name=/input.4, inputs=[/54, /29, /30])
  (/56): BoundRelu(name=/56, inputs=[/input.4])
  (/57): BoundConv(name=/57, inputs=[/56, /31, /32])
  (/58): BoundConv(name=/58, inputs=[/54, /33, /34])
  (/59): BoundAdd(name=/59, inputs=[/57, /58])
  (/input.8): BoundRelu(name=/input.8, inputs=[/59])
  (/input.12): BoundConv(name=/input.12, inputs=[/input.8, /35, /36])
  (/62): BoundRelu(name=/62, inputs=[/input.12])
  (/63): BoundConv(name=/63, inputs=[/62, /37, /38])
  (/64): BoundAdd(name=/64, inputs=[/63, /input.8])
  (/input.16): BoundRelu(name=/input.16, inputs=[/64])
  (/input.20): BoundConv(name=/input.20, inputs=[/input.16, /39, /40])
  (/67): BoundRelu(name=/67, inputs=[/input.20])
  (/68): BoundConv(name=/68, inputs=[/67, /41, /42])
  (/69): BoundConv(name=/69, inputs=[/input.16, /43, /44])
  (/70): BoundAdd(name=/70, inputs=[/68, /69])
  (/input.24): BoundRelu(name=/input.24, inputs=[/70])
  (/input.28): BoundConv(name=/input.28, inputs=[/input.24, /45, /46])
  (/73): BoundRelu(name=/73, inputs=[/input.28])
  (/74): BoundConv(name=/74, inputs=[/73, /47, /48])
  (/75): BoundAdd(name=/75, inputs=[/74, /input.24])
  (/76): BoundRelu(name=/76, inputs=[/75])
  (/77): BoundFlatten(name=/77, inputs=[/76])
  (/input.32): BoundLinear(name=/input.32, inputs=[/77, /49, /50])
  (/79): BoundRelu(name=/79, inputs=[/input.32])
  (/80): BoundLinear(name=/80, inputs=[/79, /51, /52])
)
Model prediction is: tensor([ 1.13689673, -1.69910777, -0.77371299,  0.36231494, -1.27489316,
        -0.52829957, -1.23019004, -0.75381345,  5.67982864, -0.81278360],
       device='cuda:0')
build_with_refined_bounds batch [0/1]
setting alpha for layer /54 start_node /80 with alignment adjustment
setting alpha for layer /56 start_node /80 with alignment adjustment
setting alpha for layer /input.8 start_node /80 with alignment adjustment
setting alpha for layer /62 start_node /80 with alignment adjustment
setting alpha for layer /input.16 start_node /80 with alignment adjustment
setting alpha for layer /67 start_node /80 with alignment adjustment
setting alpha for layer /input.24 start_node /80 with alignment adjustment
setting alpha for layer /73 start_node /80 with alignment adjustment
setting alpha for layer /76 start_node /80 with alignment adjustment
setting alpha for layer /79 start_node /80 with alignment adjustment
all slope initialized
directly get lb and ub from refined bounds
lA shapes: [torch.Size([1, 1, 16, 16, 16]), torch.Size([1, 1, 32, 8, 8]), torch.Size([1, 1, 32, 8, 8]), torch.Size([1, 1, 32, 8, 8]), torch.Size([1, 1, 32, 8, 8]), torch.Size([1, 1, 32, 4, 4]), torch.Size([1, 1, 32, 4, 4]), torch.Size([1, 1, 32, 4, 4]), torch.Size([1, 1, 32, 4, 4]), torch.Size([1, 1, 100])]
c shape: torch.Size([1, 1, 10])
alpha-CROWN with fixed intermediate bounds: tensor([[-0.43290615]], device='cuda:0') tensor([[inf]], device='cuda:0')
Intermediate layers: /input.12,/input.20,/input,/59,/75,/70,/input.4,/input.28,/input.32,/64,/80
Split layers:
  BoundConv(name=/input, inputs=[/input.1, /27, /28]): [(BoundRelu(name=/54, inputs=[/input]), 0)]
  BoundAdd(name=/70, inputs=[/68, /69]): [(BoundRelu(name=/input.24, inputs=[/70]), 0)]
  BoundAdd(name=/64, inputs=[/63, /input.8]): [(BoundRelu(name=/input.16, inputs=[/64]), 0)]
  BoundConv(name=/input.4, inputs=[/54, /29, /30]): [(BoundRelu(name=/56, inputs=[/input.4]), 0)]
  BoundConv(name=/input.28, inputs=[/input.24, /45, /46]): [(BoundRelu(name=/73, inputs=[/input.28]), 0)]
  BoundConv(name=/input.12, inputs=[/input.8, /35, /36]): [(BoundRelu(name=/62, inputs=[/input.12]), 0)]
  BoundAdd(name=/75, inputs=[/74, /input.24]): [(BoundRelu(name=/76, inputs=[/75]), 0)]
  BoundConv(name=/input.20, inputs=[/input.16, /39, /40]): [(BoundRelu(name=/67, inputs=[/input.20]), 0)]
  BoundLinear(name=/input.32, inputs=[/77, /49, /50]): [(BoundRelu(name=/79, inputs=[/input.32]), 0)]
  BoundAdd(name=/59, inputs=[/57, /58]): [(BoundRelu(name=/input.8, inputs=[/59]), 0)]
Keeping slopes for these layers: ['/80']
Keeping slopes for these layers: ['/80']
Node /54 input 0: size torch.Size([16, 16, 16]) unstable 445
Node /56 input 0: size torch.Size([32, 8, 8]) unstable 194
Node /input.8 input 0: size torch.Size([32, 8, 8]) unstable 187
Node /62 input 0: size torch.Size([32, 8, 8]) unstable 239
Node /input.16 input 0: size torch.Size([32, 8, 8]) unstable 367
Node /67 input 0: size torch.Size([32, 4, 4]) unstable 101
Node /input.24 input 0: size torch.Size([32, 4, 4]) unstable 132
Node /73 input 0: size torch.Size([32, 4, 4]) unstable 143
Node /76 input 0: size torch.Size([32, 4, 4]) unstable 237
Node /79 input 0: size torch.Size([100]) unstable 72
-----------------
# of unstable neurons: 2117
-----------------

BaB round 1
batch: 1
Average branched neurons at iteration 1:  1.0000
splitting decisions: 
split level 0: [/input.32, 74] 
split level 1: [/input.32, 47] 
split level 2: [/input.32, 51] 
split level 3: [/input.32, 59] 
split level 4: [/input.32, 20] 
split level 5: [/input.32, 96] 
split level 6: [/input.32, 38] 

all verified at 0th iter
pruning_in_iteration open status: False
ratio of positive domain = 128 / 128 = 1.0
pruning-in-iteration extra time: 0.0001087188720703125
Time: prepare 0.0204    beta_bound 0.0734    bound 0.0742    transfer 0.0028    finalize 0.0230    func 0.1206    
Accumulated time: func 0.1206    prepare 0.0217    bound 0.0742    beta_bound 0.0734    transfer 0.0028    finalize 0.0230    
batch bounding time:  0.12085556983947754
length of domains: 0
Time: pickout 0.0018    decision 0.1109    set_bounds 0.0041    solve 0.1209    add 0.0002    
Accumulated time: pickout 0.0018    decision 0.1109    set_bounds 0.0041    solve 0.1209    add 0.0002    
No domains left, verification finished!
Current (lb-rhs): 1.0000000116860974e-07
0 domains visited
Cumulative time: 0.25447964668273926


Properties batch 4, size 1
Remaining timeout: 238.07009530067444
##### Instance 0 first 10 spec matrices: 
tensor([[[ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  1.,  0.]]],
       dtype=torch.float64)
thresholds: [0.] ######
Initial alpha-CROWN verified for spec index [0] with bound 0.08095216751098633.

Properties batch 5, size 1
Remaining timeout: 237.94927954673767
##### Instance 0 first 10 spec matrices: 
tensor([[[ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  1.,  0.]]],
       dtype=torch.float64)
thresholds: [0.] ######
Initial alpha-CROWN verified for spec index [0] with bound 0.11561822891235352.

Properties batch 6, size 1
Remaining timeout: 237.8556637763977
##### Instance 0 first 10 spec matrices: 
tensor([[[ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  1.,  0.]]],
       dtype=torch.float64)
thresholds: [0.] ######
Initial alpha-CROWN verified for spec index [0] with bound 1.0531773567199707.

Properties batch 7, size 1
Remaining timeout: 237.78481912612915
##### Instance 0 first 10 spec matrices: 
tensor([[[ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  1.,  0.]]],
       dtype=torch.float64)
thresholds: [0.] ######
Remaining spec index [0] with bounds tensor([[-1.09978199]], device='cuda:0') need to verify.
Model: BoundedModule(
  (/input.1): BoundInput(name=/input.1, inputs=[])
  (/27): BoundParams(name=/27, inputs=[])
  (/28): BoundParams(name=/28, inputs=[])
  (/29): BoundParams(name=/29, inputs=[])
  (/30): BoundParams(name=/30, inputs=[])
  (/31): BoundParams(name=/31, inputs=[])
  (/32): BoundParams(name=/32, inputs=[])
  (/33): BoundParams(name=/33, inputs=[])
  (/34): BoundParams(name=/34, inputs=[])
  (/35): BoundParams(name=/35, inputs=[])
  (/36): BoundParams(name=/36, inputs=[])
  (/37): BoundParams(name=/37, inputs=[])
  (/38): BoundParams(name=/38, inputs=[])
  (/39): BoundParams(name=/39, inputs=[])
  (/40): BoundParams(name=/40, inputs=[])
  (/41): BoundParams(name=/41, inputs=[])
  (/42): BoundParams(name=/42, inputs=[])
  (/43): BoundParams(name=/43, inputs=[])
  (/44): BoundParams(name=/44, inputs=[])
  (/45): BoundParams(name=/45, inputs=[])
  (/46): BoundParams(name=/46, inputs=[])
  (/47): BoundParams(name=/47, inputs=[])
  (/48): BoundParams(name=/48, inputs=[])
  (/49): BoundParams(name=/49, inputs=[])
  (/50): BoundParams(name=/50, inputs=[])
  (/51): BoundParams(name=/51, inputs=[])
  (/52): BoundParams(name=/52, inputs=[])
  (/input): BoundConv(name=/input, inputs=[/input.1, /27, /28])
  (/54): BoundRelu(name=/54, inputs=[/input])
  (/input.4): BoundConv(name=/input.4, inputs=[/54, /29, /30])
  (/56): BoundRelu(name=/56, inputs=[/input.4])
  (/57): BoundConv(name=/57, inputs=[/56, /31, /32])
  (/58): BoundConv(name=/58, inputs=[/54, /33, /34])
  (/59): BoundAdd(name=/59, inputs=[/57, /58])
  (/input.8): BoundRelu(name=/input.8, inputs=[/59])
  (/input.12): BoundConv(name=/input.12, inputs=[/input.8, /35, /36])
  (/62): BoundRelu(name=/62, inputs=[/input.12])
  (/63): BoundConv(name=/63, inputs=[/62, /37, /38])
  (/64): BoundAdd(name=/64, inputs=[/63, /input.8])
  (/input.16): BoundRelu(name=/input.16, inputs=[/64])
  (/input.20): BoundConv(name=/input.20, inputs=[/input.16, /39, /40])
  (/67): BoundRelu(name=/67, inputs=[/input.20])
  (/68): BoundConv(name=/68, inputs=[/67, /41, /42])
  (/69): BoundConv(name=/69, inputs=[/input.16, /43, /44])
  (/70): BoundAdd(name=/70, inputs=[/68, /69])
  (/input.24): BoundRelu(name=/input.24, inputs=[/70])
  (/input.28): BoundConv(name=/input.28, inputs=[/input.24, /45, /46])
  (/73): BoundRelu(name=/73, inputs=[/input.28])
  (/74): BoundConv(name=/74, inputs=[/73, /47, /48])
  (/75): BoundAdd(name=/75, inputs=[/74, /input.24])
  (/76): BoundRelu(name=/76, inputs=[/75])
  (/77): BoundFlatten(name=/77, inputs=[/76])
  (/input.32): BoundLinear(name=/input.32, inputs=[/77, /49, /50])
  (/79): BoundRelu(name=/79, inputs=[/input.32])
  (/80): BoundLinear(name=/80, inputs=[/79, /51, /52])
)
Model prediction is: tensor([ 1.13689673, -1.69910777, -0.77371299,  0.36231494, -1.27489316,
        -0.52829957, -1.23019004, -0.75381345,  5.67982864, -0.81278360],
       device='cuda:0')
build_with_refined_bounds batch [0/1]
setting alpha for layer /54 start_node /80 with alignment adjustment
setting alpha for layer /56 start_node /80 with alignment adjustment
setting alpha for layer /input.8 start_node /80 with alignment adjustment
setting alpha for layer /62 start_node /80 with alignment adjustment
setting alpha for layer /input.16 start_node /80 with alignment adjustment
setting alpha for layer /67 start_node /80 with alignment adjustment
setting alpha for layer /input.24 start_node /80 with alignment adjustment
setting alpha for layer /73 start_node /80 with alignment adjustment
setting alpha for layer /76 start_node /80 with alignment adjustment
setting alpha for layer /79 start_node /80 with alignment adjustment
all slope initialized
directly get lb and ub from refined bounds
lA shapes: [torch.Size([1, 1, 16, 16, 16]), torch.Size([1, 1, 32, 8, 8]), torch.Size([1, 1, 32, 8, 8]), torch.Size([1, 1, 32, 8, 8]), torch.Size([1, 1, 32, 8, 8]), torch.Size([1, 1, 32, 4, 4]), torch.Size([1, 1, 32, 4, 4]), torch.Size([1, 1, 32, 4, 4]), torch.Size([1, 1, 32, 4, 4]), torch.Size([1, 1, 100])]
c shape: torch.Size([1, 1, 10])
alpha-CROWN with fixed intermediate bounds: tensor([[-1.09978199]], device='cuda:0') tensor([[inf]], device='cuda:0')
Intermediate layers: /input.12,/input.20,/input,/59,/75,/70,/input.4,/input.28,/input.32,/64,/80
Split layers:
  BoundConv(name=/input, inputs=[/input.1, /27, /28]): [(BoundRelu(name=/54, inputs=[/input]), 0)]
  BoundLinear(name=/input.32, inputs=[/77, /49, /50]): [(BoundRelu(name=/79, inputs=[/input.32]), 0)]
  BoundConv(name=/input.4, inputs=[/54, /29, /30]): [(BoundRelu(name=/56, inputs=[/input.4]), 0)]
  BoundAdd(name=/59, inputs=[/57, /58]): [(BoundRelu(name=/input.8, inputs=[/59]), 0)]
  BoundConv(name=/input.12, inputs=[/input.8, /35, /36]): [(BoundRelu(name=/62, inputs=[/input.12]), 0)]
  BoundConv(name=/input.20, inputs=[/input.16, /39, /40]): [(BoundRelu(name=/67, inputs=[/input.20]), 0)]
  BoundAdd(name=/70, inputs=[/68, /69]): [(BoundRelu(name=/input.24, inputs=[/70]), 0)]
  BoundAdd(name=/64, inputs=[/63, /input.8]): [(BoundRelu(name=/input.16, inputs=[/64]), 0)]
  BoundConv(name=/input.28, inputs=[/input.24, /45, /46]): [(BoundRelu(name=/73, inputs=[/input.28]), 0)]
  BoundAdd(name=/75, inputs=[/74, /input.24]): [(BoundRelu(name=/76, inputs=[/75]), 0)]
Keeping slopes for these layers: ['/80']
Keeping slopes for these layers: ['/80']
Node /54 input 0: size torch.Size([16, 16, 16]) unstable 445
Node /56 input 0: size torch.Size([32, 8, 8]) unstable 194
Node /input.8 input 0: size torch.Size([32, 8, 8]) unstable 187
Node /62 input 0: size torch.Size([32, 8, 8]) unstable 239
Node /input.16 input 0: size torch.Size([32, 8, 8]) unstable 367
Node /67 input 0: size torch.Size([32, 4, 4]) unstable 101
Node /input.24 input 0: size torch.Size([32, 4, 4]) unstable 132
Node /73 input 0: size torch.Size([32, 4, 4]) unstable 143
Node /76 input 0: size torch.Size([32, 4, 4]) unstable 237
Node /79 input 0: size torch.Size([100]) unstable 72
-----------------
# of unstable neurons: 2117
-----------------

BaB round 1
batch: 1
Average branched neurons at iteration 1:  1.0000
splitting decisions: 
split level 0: [/input.32, 26] 
split level 1: [/input.32, 31] 
split level 2: [/input.32, 76] 
split level 3: [/input.32, 66] 
split level 4: [/input.32, 74] 
split level 5: [/input.32, 97] 
split level 6: [/input.32, 88] 

all verified at 0th iter
pruning_in_iteration open status: False
ratio of positive domain = 128 / 128 = 1.0
pruning-in-iteration extra time: 0.0002079010009765625
Time: prepare 0.0335    beta_bound 0.0958    bound 0.0974    transfer 0.0049    finalize 0.0274    func 0.1633    
Accumulated time: func 0.1633    prepare 0.0353    bound 0.0974    beta_bound 0.0958    transfer 0.0049    finalize 0.0274    
batch bounding time:  0.16357898712158203
length of domains: 0
Time: pickout 0.0035    decision 0.1806    set_bounds 0.0050    solve 0.1636    add 0.0003    
Accumulated time: pickout 0.0035    decision 0.1806    set_bounds 0.0050    solve 0.1636    add 0.0003    
No domains left, verification finished!
Current (lb-rhs): 1.0000000116860974e-07
0 domains visited
Cumulative time: 0.3797626495361328


Properties batch 8, size 1
Remaining timeout: 236.8393223285675
##### Instance 0 first 10 spec matrices: 
tensor([[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1., -1.]]],
       dtype=torch.float64)
thresholds: [0.] ######
Remaining spec index [0] with bounds tensor([[-0.22583044]], device='cuda:0') need to verify.
Model: BoundedModule(
  (/input.1): BoundInput(name=/input.1, inputs=[])
  (/27): BoundParams(name=/27, inputs=[])
  (/28): BoundParams(name=/28, inputs=[])
  (/29): BoundParams(name=/29, inputs=[])
  (/30): BoundParams(name=/30, inputs=[])
  (/31): BoundParams(name=/31, inputs=[])
  (/32): BoundParams(name=/32, inputs=[])
  (/33): BoundParams(name=/33, inputs=[])
  (/34): BoundParams(name=/34, inputs=[])
  (/35): BoundParams(name=/35, inputs=[])
  (/36): BoundParams(name=/36, inputs=[])
  (/37): BoundParams(name=/37, inputs=[])
  (/38): BoundParams(name=/38, inputs=[])
  (/39): BoundParams(name=/39, inputs=[])
  (/40): BoundParams(name=/40, inputs=[])
  (/41): BoundParams(name=/41, inputs=[])
  (/42): BoundParams(name=/42, inputs=[])
  (/43): BoundParams(name=/43, inputs=[])
  (/44): BoundParams(name=/44, inputs=[])
  (/45): BoundParams(name=/45, inputs=[])
  (/46): BoundParams(name=/46, inputs=[])
  (/47): BoundParams(name=/47, inputs=[])
  (/48): BoundParams(name=/48, inputs=[])
  (/49): BoundParams(name=/49, inputs=[])
  (/50): BoundParams(name=/50, inputs=[])
  (/51): BoundParams(name=/51, inputs=[])
  (/52): BoundParams(name=/52, inputs=[])
  (/input): BoundConv(name=/input, inputs=[/input.1, /27, /28])
  (/54): BoundRelu(name=/54, inputs=[/input])
  (/input.4): BoundConv(name=/input.4, inputs=[/54, /29, /30])
  (/56): BoundRelu(name=/56, inputs=[/input.4])
  (/57): BoundConv(name=/57, inputs=[/56, /31, /32])
  (/58): BoundConv(name=/58, inputs=[/54, /33, /34])
  (/59): BoundAdd(name=/59, inputs=[/57, /58])
  (/input.8): BoundRelu(name=/input.8, inputs=[/59])
  (/input.12): BoundConv(name=/input.12, inputs=[/input.8, /35, /36])
  (/62): BoundRelu(name=/62, inputs=[/input.12])
  (/63): BoundConv(name=/63, inputs=[/62, /37, /38])
  (/64): BoundAdd(name=/64, inputs=[/63, /input.8])
  (/input.16): BoundRelu(name=/input.16, inputs=[/64])
  (/input.20): BoundConv(name=/input.20, inputs=[/input.16, /39, /40])
  (/67): BoundRelu(name=/67, inputs=[/input.20])
  (/68): BoundConv(name=/68, inputs=[/67, /41, /42])
  (/69): BoundConv(name=/69, inputs=[/input.16, /43, /44])
  (/70): BoundAdd(name=/70, inputs=[/68, /69])
  (/input.24): BoundRelu(name=/input.24, inputs=[/70])
  (/input.28): BoundConv(name=/input.28, inputs=[/input.24, /45, /46])
  (/73): BoundRelu(name=/73, inputs=[/input.28])
  (/74): BoundConv(name=/74, inputs=[/73, /47, /48])
  (/75): BoundAdd(name=/75, inputs=[/74, /input.24])
  (/76): BoundRelu(name=/76, inputs=[/75])
  (/77): BoundFlatten(name=/77, inputs=[/76])
  (/input.32): BoundLinear(name=/input.32, inputs=[/77, /49, /50])
  (/79): BoundRelu(name=/79, inputs=[/input.32])
  (/80): BoundLinear(name=/80, inputs=[/79, /51, /52])
)/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)
  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  "Using experimental implementation that allows 'batch_size > 1'."
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):

Model prediction is: tensor([ 1.13689673, -1.69910777, -0.77371299,  0.36231494, -1.27489316,
        -0.52829957, -1.23019004, -0.75381345,  5.67982864, -0.81278360],
       device='cuda:0')
build_with_refined_bounds batch [0/1]
setting alpha for layer /54 start_node /80 with alignment adjustment
setting alpha for layer /56 start_node /80 with alignment adjustment
setting alpha for layer /input.8 start_node /80 with alignment adjustment
setting alpha for layer /62 start_node /80 with alignment adjustment
setting alpha for layer /input.16 start_node /80 with alignment adjustment
setting alpha for layer /67 start_node /80 with alignment adjustment
setting alpha for layer /input.24 start_node /80 with alignment adjustment
setting alpha for layer /73 start_node /80 with alignment adjustment
setting alpha for layer /76 start_node /80 with alignment adjustment
setting alpha for layer /79 start_node /80 with alignment adjustment
all slope initialized
directly get lb and ub from refined bounds
lA shapes: [torch.Size([1, 1, 16, 16, 16]), torch.Size([1, 1, 32, 8, 8]), torch.Size([1, 1, 32, 8, 8]), torch.Size([1, 1, 32, 8, 8]), torch.Size([1, 1, 32, 8, 8]), torch.Size([1, 1, 32, 4, 4]), torch.Size([1, 1, 32, 4, 4]), torch.Size([1, 1, 32, 4, 4]), torch.Size([1, 1, 32, 4, 4]), torch.Size([1, 1, 100])]
c shape: torch.Size([1, 1, 10])
alpha-CROWN with fixed intermediate bounds: tensor([[-0.22583044]], device='cuda:0') tensor([[inf]], device='cuda:0')
Intermediate layers: /input.12,/input.20,/input,/59,/75,/70,/input.4,/input.28,/input.32,/64,/80
Split layers:
  BoundConv(name=/input.12, inputs=[/input.8, /35, /36]): [(BoundRelu(name=/62, inputs=[/input.12]), 0)]
  BoundAdd(name=/70, inputs=[/68, /69]): [(BoundRelu(name=/input.24, inputs=[/70]), 0)]
  BoundAdd(name=/59, inputs=[/57, /58]): [(BoundRelu(name=/input.8, inputs=[/59]), 0)]
  BoundLinear(name=/input.32, inputs=[/77, /49, /50]): [(BoundRelu(name=/79, inputs=[/input.32]), 0)]
  BoundAdd(name=/64, inputs=[/63, /input.8]): [(BoundRelu(name=/input.16, inputs=[/64]), 0)]
  BoundAdd(name=/75, inputs=[/74, /input.24]): [(BoundRelu(name=/76, inputs=[/75]), 0)]
  BoundConv(name=/input.4, inputs=[/54, /29, /30]): [(BoundRelu(name=/56, inputs=[/input.4]), 0)]
  BoundConv(name=/input.28, inputs=[/input.24, /45, /46]): [(BoundRelu(name=/73, inputs=[/input.28]), 0)]
  BoundConv(name=/input.20, inputs=[/input.16, /39, /40]): [(BoundRelu(name=/67, inputs=[/input.20]), 0)]
  BoundConv(name=/input, inputs=[/input.1, /27, /28]): [(BoundRelu(name=/54, inputs=[/input]), 0)]
Keeping slopes for these layers: ['/80']
Keeping slopes for these layers: ['/80']
Node /54 input 0: size torch.Size([16, 16, 16]) unstable 445
Node /56 input 0: size torch.Size([32, 8, 8]) unstable 194
Node /input.8 input 0: size torch.Size([32, 8, 8]) unstable 187
Node /62 input 0: size torch.Size([32, 8, 8]) unstable 239
Node /input.16 input 0: size torch.Size([32, 8, 8]) unstable 367
Node /67 input 0: size torch.Size([32, 4, 4]) unstable 101
Node /input.24 input 0: size torch.Size([32, 4, 4]) unstable 132
Node /73 input 0: size torch.Size([32, 4, 4]) unstable 143
Node /76 input 0: size torch.Size([32, 4, 4]) unstable 237
Node /79 input 0: size torch.Size([100]) unstable 72
-----------------
# of unstable neurons: 2117
-----------------

BaB round 1
batch: 1
Average branched neurons at iteration 1:  1.0000
splitting decisions: 
split level 0: [/input.32, 76] 
split level 1: [/input.32, 48] 
split level 2: [/input.32, 85] 
split level 3: [/input.32, 75] 
split level 4: [/input.32, 22] 
split level 5: [/input.32, 69] 
split level 6: [/input.32, 38] 

all verified at 0th iter
pruning_in_iteration open status: False
ratio of positive domain = 128 / 128 = 1.0
pruning-in-iteration extra time: 0.00017976760864257812
Time: prepare 0.0244    beta_bound 0.0885    bound 0.0894    transfer 0.0031    finalize 0.0232    func 0.1403    
Accumulated time: func 0.1403    prepare 0.0256    bound 0.0894    beta_bound 0.0885    transfer 0.0031    finalize 0.0232    
batch bounding time:  0.14053797721862793
length of domains: 0
Time: pickout 0.0018    decision 0.1082    set_bounds 0.0044    solve 0.1406    add 0.0002    
Accumulated time: pickout 0.0018    decision 0.1082    set_bounds 0.0044    solve 0.1406    add 0.0002    
No domains left, verification finished!
Current (lb-rhs): 1.0000000116860974e-07
0 domains visited
Cumulative time: 0.2717738151550293

Result: safe in 63.8161 seconds
############# Summary #############
Final verified acc: 100.0% (total 1 examples)
Problem instances count: 1 , total verified (safe/unsat): 1 , total falsified (unsafe/sat): 0 , timeout: 0
mean time for ALL instances (total 1):63.81548533071187, max time: 63.816123485565186
mean time for verified SAFE instances(total 1): 63.816123485565186, max time: 63.816123485565186
safe (total 1), index: [0]
