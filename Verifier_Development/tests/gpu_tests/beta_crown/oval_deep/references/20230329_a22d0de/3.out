Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  sparse_alpha: true
  save_adv_example: false
  precompile_jit: false
  complete_verifier: bab
  enable_incomplete_verification: false
  csv_name: null
  results_file: out.txt
  root_path: ''
model:
  name: cifar_model_deep
  path: cifar_deep.pth
  onnx_path: null
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: default_onnx_and_vnnlib_loader
  onnx_optimization_flags: none
data:
  start: 91
  end: 92
  select_instance: null
  num_outputs: 10
  mean: [0.485, 0.456, 0.406]
  std: [0.225, 0.225, 0.225]
  pkl_path: deep_100.pkl
  dataset: CIFAR
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: specify-target
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: null
  vnnlib_path_prefix: ''
solver:
  batch_size: 1024
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
    full_conv_alpha: true
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 36
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_intermediate_layers: ''
  interm_transfer: true
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
    _tmp_cuts: null
    fixed_cuts: false
    add_implied_cuts: false
    add_input_cuts: false
  branching:
    method: fsb
    candidates: 1
    reduceop: min
    sb_coeff_thresh: 0.001
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sort_domain_interval: -1
    nonlinear_split:
      method: babsr_like
      branching_point_method: middle
      num_branches: 2
      branching_point_refinement: false
      naive_branching_score: false
      filter: false
      prioritize_mul: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 30.0
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  pgd_steps: 100
  pgd_restarts: 30
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  cex_path: ./test_cex.txt
  attack_mode: PGD
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 5000000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
debug:
  lp_test: null

Experiments at Wed Mar 29 13:59:28 2023 on zeratul
Sequential(
  (0): Conv2d(3, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(8, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (7): ReLU()
  (8): Flatten()
  (9): Linear(in_features=512, out_features=100, bias=True)
  (10): ReLU()
  (11): Linear(in_features=100, out_features=10, bias=True)
)
Files already downloaded and verified
Overwrite epsilon that saved in .pkl file, they should be after normalized!
Internal results will be saved to Verified_ret_[cifar_model_deep]_start=91_end=92_iter=20_b=1024_timeout=36_branching=fsb-min-1_lra-init=0.1_lra=0.01_lrb=0.05_PGD=skip_cplex_cuts=False.npy.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 91 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Total VNNLIB file length: 1, max property batch size: 1, total number of batches: 1

Properties batch 0, size 1
Remaining timeout: 32.689340591430664
##### Instance 0 first 10 spec matrices: 
tensor([[[-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]]])
thresholds: [0] ######
Model: BoundedModule(
  (/input.1): BoundInput(name=/input.1, inputs=[])
  (/1): BoundParams(name=/1, inputs=[])
  (/2): BoundParams(name=/2, inputs=[])
  (/3): BoundParams(name=/3, inputs=[])
  (/4): BoundParams(name=/4, inputs=[])
  (/5): BoundParams(name=/5, inputs=[])
  (/6): BoundParams(name=/6, inputs=[])
  (/7): BoundParams(name=/7, inputs=[])
  (/8): BoundParams(name=/8, inputs=[])
  (/9): BoundParams(name=/9, inputs=[])
  (/10): BoundParams(name=/10, inputs=[])
  (/11): BoundParams(name=/11, inputs=[])
  (/12): BoundParams(name=/12, inputs=[])
  (/input): BoundConv(name=/input, inputs=[/input.1, /1, /2])
  (/input.4): BoundRelu(name=/input.4, inputs=[/input])
  (/input.8): BoundConv(name=/input.8, inputs=[/input.4, /3, /4])
  (/input.12): BoundRelu(name=/input.12, inputs=[/input.8])
  (/input.16): BoundConv(name=/input.16, inputs=[/input.12, /5, /6])
  (/input.20): BoundRelu(name=/input.20, inputs=[/input.16])
  (/input.24): BoundConv(name=/input.24, inputs=[/input.20, /7, /8])
  (/20): BoundRelu(name=/20, inputs=[/input.24])
  (/21): BoundShape(name=/21, inputs=[/20])
  (/22): BoundConstant(name=/22, inputs=[])
  (/23): BoundGather(name=/23, inputs=[/21, /22])
  (/24): BoundConstant(name=/24, inputs=[])
  (/25): BoundUnsqueeze(name=/25, inputs=[/23])
  (/26): BoundUnsqueeze(name=/26, inputs=[/24])
  (/27): BoundConcat(name=/27, inputs=[/25, /26])
  (/28): BoundReshape(name=/28, inputs=[/20, /27])
  (/input.28): BoundLinear(name=/input.28, inputs=[/28, /9, /10])
  (/30): BoundRelu(name=/30, inputs=[/input.28])
  (/31): BoundLinear(name=/31, inputs=[/30, /11, /12])
)
Model prediction is: tensor([ 3.31787443,  1.66825652,  0.17516437, -2.21493006, -0.52868778,
        -2.70783496, -2.71228242, -2.56523848,  4.70507812,  0.86265033],
       device='cuda:0')
layer /input.4 using sparse-features alpha with shape [232]; unstable size 232; total size 2048 (torch.Size([1, 8, 16, 16]))
layer /input.4 start_node /input.8 using sparse-spec alpha with unstable size 338 total_size 2048 output_shape (8, 16, 16)
layer /input.4 start_node /input.16 using sparse-spec alpha with unstable size 360 total_size 2048 output_shape (8, 16, 16)
layer /input.4 start_node /input.24 using sparse-spec alpha with unstable size 110 total_size 512 output_shape (8, 8, 8)
layer /input.4 start_node /input.28 using sparse-spec alpha with unstable size 40 total_size 100 output_shape torch.Size([100])
layer /input.4 start_node /31 using full alpha with unstable size None total_size 1 output_shape 1
layer /input.12 using sparse-features alpha with shape [338]; unstable size 338; total size 2048 (torch.Size([1, 8, 16, 16]))
layer /input.12 start_node /input.16 using sparse-spec alpha with unstable size 360 total_size 2048 output_shape (8, 16, 16)
layer /input.12 start_node /input.24 using sparse-spec alpha with unstable size 110 total_size 512 output_shape (8, 8, 8)
layer /input.12 start_node /input.28 using sparse-spec alpha with unstable size 40 total_size 100 output_shape torch.Size([100])
layer /input.12 start_node /31 using full alpha with unstable size None total_size 1 output_shape 1
layer /input.20 using sparse-features alpha with shape [360]; unstable size 360; total size 2048 (torch.Size([1, 8, 16, 16]))
layer /input.20 start_node /input.24 using sparse-spec alpha with unstable size 110 total_size 512 output_shape (8, 8, 8)
layer /input.20 start_node /input.28 using sparse-spec alpha with unstable size 40 total_size 100 output_shape torch.Size([100])
layer /input.20 start_node /31 using full alpha with unstable size None total_size 1 output_shape 1
layer /20 using sparse-features alpha with shape [110]; unstable size 110; total size 512 (torch.Size([1, 8, 8, 8]))
layer /20 start_node /input.28 using sparse-spec alpha with unstable size 40 total_size 100 output_shape torch.Size([100])
layer /20 start_node /31 using full alpha with unstable size None total_size 1 output_shape 1
layer /30 using sparse-features alpha with shape [40]; unstable size 40; total size 100 (torch.Size([1, 100]))
layer /30 start_node /31 using full alpha with unstable size None total_size 1 output_shape 1
Optimizable variables initialized.
initial CROWN bounds: tensor([[-0.76750565]], device='cuda:0') None
best_l after optimization: -0.5188992023468018
alpha/beta optimization time: 8.800289392471313
initial alpha-CROWN bounds: tensor([[-0.51889920]], device='cuda:0')
Worst class: (+ rhs) -0.5188992023468018
Split layers:
  BoundConv(name=/input, inputs=[/input.1, /1, /2]): [(BoundRelu(name=/input.4, inputs=[/input]), 0)]
  BoundConv(name=/input.8, inputs=[/input.4, /3, /4]): [(BoundRelu(name=/input.12, inputs=[/input.8]), 0)]
  BoundConv(name=/input.16, inputs=[/input.12, /5, /6]): [(BoundRelu(name=/input.20, inputs=[/input.16]), 0)]
  BoundConv(name=/input.24, inputs=[/input.20, /7, /8]): [(BoundRelu(name=/20, inputs=[/input.24]), 0)]
  BoundLinear(name=/input.28, inputs=[/28, /9, /10]): [(BoundRelu(name=/30, inputs=[/input.28]), 0)]
Keeping slopes for these layers: ['/31']
Node /input.4 input 0: size torch.Size([8, 16, 16]) unstable 232
Node /input.12 input 0: size torch.Size([8, 16, 16]) unstable 332
Node /input.20 input 0: size torch.Size([8, 16, 16]) unstable 329
Node /20 input 0: size torch.Size([8, 8, 8]) unstable 97
Node /30 input 0: size torch.Size([100]) unstable 40
-----------------
# of unstable neurons: 1030
-----------------

BaB round 1
batch: 1
Average branched neurons at iteration 1:  1.0000
splitting decisions: 
split level 0: [/input.28, 49] 
split level 1: [/input.28, 36] 
split level 2: [/input.28, 17] 
split level 3: [/input.28, 90] 
split level 4: [/input.28, 68] 
split level 5: [/input.28, 35] 
best_l after optimization: 37.99729919433594
beta sum per layer: [0.0, 0.0, 0.0, 0.0, 0.3923712372779846]
alpha/beta optimization time: 0.6669423580169678
pruning_in_iteration open status: True
ratio of positive domain = 62 / 64 = 0.96875
pruning-in-iteration extra time: 0.012977361679077148
Time: prepare 0.0041    beta_bound 0.6675    bound 0.6675    transfer 0.0013    finalize 0.0049    func 0.6779    
Accumulated time: func 0.6779    prepare 0.0068    bound 0.6675    beta_bound 0.6675    transfer 0.0013    finalize 0.0049    
batch bounding time:  0.6779539585113525
Current worst splitting domains lb-rhs (depth):
-0.12723 (6), -0.00165 (6), 
length of domains: 2
Time: pickout 0.0009    decision 0.1645    set_bounds 0.0014    solve 0.6780    add 0.0011    
Accumulated time: pickout 0.0009    decision 0.1645    set_bounds 0.0014    solve 0.6780    add 0.0011    
Current (lb-rhs): -0.12722504138946533
2 domains visited
Cumulative time: 11.019980192184448

BaB round 2
batch: 2
Average branched neurons at iteration 2:  1.0000
splitting decisions: 
split level 0: [/input.28, 75] [/input.28, 45] 
split level 1: [/input.28, 45] [/input.28, 75] 
split level 2: [/input.28, 77] [/input.28, 77] 
split level 3: [/input.28, 46] [/input.28, 46] 
split level 4: [/input.28, 69] [/input.28, 69] 

all verified at 0th iter
best_l after optimization: 17.417800903320312
beta sum per layer: [0.0, 0.0, 0.0, 0.0, 12.555879592895508]
alpha/beta optimization time: 0.008176803588867188
pruning_in_iteration open status: False
ratio of positive domain = 64 / 64 = 1.0
pruning-in-iteration extra time: 7.128715515136719e-05
Time: prepare 0.0052    beta_bound 0.0085    bound 0.0085    transfer 0.0006    finalize 0.0037    func 0.0181    
Accumulated time: func 0.6960    prepare 0.0142    bound 0.6760    beta_bound 0.6759    transfer 0.0019    finalize 0.0086    
batch bounding time:  0.018165111541748047
length of domains: 0
Time: pickout 0.0010    decision 0.1426    set_bounds 0.0014    solve 0.0182    add 0.0001    
Accumulated time: pickout 0.0019    decision 0.3071    set_bounds 0.0029    solve 0.6961    add 0.0012    
No domains left, verification finished!
Current (lb-rhs): 1.0000000116860974e-07
2 domains visited
Cumulative time: 11.183642625808716

Result: safe in 15.5451 seconds
############# Summary #############
Final verified acc: 100.0% (total 1 examples)
Problem instances count: 1 , total verified (safe/unsat): 1 , total falsified (unsafe/sat): 0 , timeout: 0
mean time for ALL instances (total 1):15.544955014545923, max time: 15.54511046409607
mean time for verified SAFE instances(total 1): 15.54511046409607, max time: 15.54511046409607
safe (total 1), index: [0]
