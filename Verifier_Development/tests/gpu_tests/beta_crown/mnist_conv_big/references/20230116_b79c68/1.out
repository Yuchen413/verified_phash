Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  sparse_alpha: true
  save_adv_example: false
  precompile_jit: false
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: null
  results_file: out.txt
  root_path: ''
model:
  name: mnist_conv_big
  path: mnist_conv_big_diffai.pth
  onnx_path: null
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: default_onnx_and_vnnlib_loader
  onnx_optimization_flags: none
data:
  start: 232
  end: 233
  select_instance: null
  num_outputs: 10
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: MNIST_ERAN
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: 0.3
  vnnlib_path: null
  vnnlib_path_prefix: ''
solver:
  batch_size: 256
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: false
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.1
    iteration: 100
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
    full_conv_alpha: true
  beta-crown:
    lr_alpha: 0.01
    lr_beta: 0.05
    lr_decay: 0.98
    optimizer: adam
    iteration: 20
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
bab:
  initial_max_domains: 1
  max_domains: .inf
  decision_thresh: 0
  timeout: 180
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_intermediate_layers: ''
  interm_transfer: true
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 100
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
    _tmp_cuts: null
    fixed_cuts: false
    add_implied_cuts: false
    add_input_cuts: false
  branching:
    method: kfsb
    candidates: 3
    reduceop: max
    sb_coeff_thresh: 0.001
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sort_domain_interval: -1
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 30.0
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: before
  pgd_steps: 100
  pgd_restarts: 100
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  cex_path: ./test_cex.txt
  attack_mode: PGD
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 5000000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
debug:
  lp_test: null

Experiments at Mon Jan 16 02:17:02 2023 on diablo.cs.ucla.edu
Sequential(
  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU()
  (2): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (3): ReLU()
  (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (5): ReLU()
  (6): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
  (7): ReLU()
  (8): Flatten()
  (9): Linear(in_features=3136, out_features=512, bias=True)
  (10): ReLU()
  (11): Linear(in_features=512, out_features=512, bias=True)
  (12): ReLU()
  (13): Linear(in_features=512, out_features=10, bias=True)
)
############################
Sampled data loaded. Data already preprocessed!
Shape: torch.Size([1000, 1, 28, 28]) torch.Size([1000]) torch.Size([1000])
X range: tensor(2.82148671) tensor(-0.42421296) tensor(-0.02737886)
Note runnerup label is empty here!
############################
Internal results will be saved to Verified_ret_[mnist_conv_big]_start=232_end=233_iter=20_b=256_timeout=180_branching=kfsb-max-3_lra-init=0.1_lra=0.01_lrb=0.05_PGD=before_cplex_cuts=False.npy.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 232 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Attack parameters: initialization=uniform, steps=100, restarts=100, alpha=0.24342750012874603, initialization=uniform, GAMA=False
Model output of first 5 examples:
 tensor([[-1.50842750, -2.78271246, -3.05500746, -2.76670456, -2.05510044,
          3.06344867,  2.96421409, -5.58440161,  4.34885550, -0.61086601]],
       device='cuda:0')
Adv example prediction (first 2 examples and 2 restarts):
 tensor([[[-1.31334746, -2.79717565, -3.17141461, -2.98147917, -2.12214541,
           3.11691117,  4.09380627, -5.83988905,  4.26125431, -0.49536744],
         [-1.31334746, -2.79717565, -3.17141461, -2.98147917, -2.12214541,
           3.11691117,  4.09380627, -5.83988905,  4.26125431, -0.49536744]]],
       device='cuda:0')
PGD attack margin (first 2 examles and 10 specs):
 tensor([[[ 5.57460165,  7.05842972,  7.43266869,  7.24273348,  6.38339996,
           1.14434314,  0.16744804, 10.10114288,  4.75662184]]],
       device='cuda:0')
number of violation:  0
Attack finished in 2.6378 seconds.
PGD attack failed
Model prediction is: tensor([[-1.50842750, -2.78271246, -3.05500746, -2.76670456, -2.05510044,
          3.06344867,  2.96421409, -5.58440161,  4.34885550, -0.61086601]],
       device='cuda:0')
layer /input.4 using sparse-features alpha with shape [593]; unstable size 593; total size 25088 (torch.Size([1, 32, 28, 28]))
layer /input.4 start_node /input.8 using sparse-spec alpha with unstable size 48 total_size 6272 output_shape (32, 14, 14)
layer /input.4 start_node /input.16 using sparse-spec alpha with unstable size 34 total_size 12544 output_shape (64, 14, 14)
layer /input.4 start_node /input.24 using sparse-spec alpha with unstable size 22 total_size 3136 output_shape (64, 7, 7)
layer /input.4 start_node /input.28 using sparse-spec alpha with unstable size 4 total_size 512 output_shape torch.Size([512])
layer /input.4 start_node /input.32 using sparse-spec alpha with unstable size 11 total_size 512 output_shape torch.Size([512])
layer /input.4 start_node /35 using full alpha with unstable size None total_size 9 output_shape 9
layer /input.12 using sparse-features alpha with shape [48]; unstable size 48; total size 6272 (torch.Size([1, 32, 14, 14]))
layer /input.12 start_node /input.16 using sparse-spec alpha with unstable size 34 total_size 12544 output_shape (64, 14, 14)
layer /input.12 start_node /input.24 using sparse-spec alpha with unstable size 22 total_size 3136 output_shape (64, 7, 7)
layer /input.12 start_node /input.28 using sparse-spec alpha with unstable size 4 total_size 512 output_shape torch.Size([512])
layer /input.12 start_node /input.32 using sparse-spec alpha with unstable size 11 total_size 512 output_shape torch.Size([512])
layer /input.12 start_node /35 using full alpha with unstable size None total_size 9 output_shape 9
layer /input.20 using sparse-features alpha with shape [34]; unstable size 34; total size 12544 (torch.Size([1, 64, 14, 14]))
layer /input.20 start_node /input.24 using sparse-spec alpha with unstable size 22 total_size 3136 output_shape (64, 7, 7)
layer /input.20 start_node /input.28 using sparse-spec alpha with unstable size 4 total_size 512 output_shape torch.Size([512])
layer /input.20 start_node /input.32 using sparse-spec alpha with unstable size 11 total_size 512 output_shape torch.Size([512])
layer /input.20 start_node /35 using full alpha with unstable size None total_size 9 output_shape 9
layer /22 using sparse-features alpha with shape [22]; unstable size 22; total size 3136 (torch.Size([1, 64, 7, 7]))
layer /22 start_node /input.28 using sparse-spec alpha with unstable size 4 total_size 512 output_shape torch.Size([512])
layer /22 start_node /input.32 using sparse-spec alpha with unstable size 11 total_size 512 output_shape torch.Size([512])
layer /22 start_node /35 using full alpha with unstable size None total_size 9 output_shape 9
layer /32 using sparse-features alpha with shape [4]; unstable size 4; total size 512 (torch.Size([1, 512]))
layer /32 start_node /input.32 using sparse-spec alpha with unstable size 11 total_size 512 output_shape torch.Size([512])
layer /32 start_node /35 using full alpha with unstable size None total_size 9 output_shape 9
layer /34 using sparse-features alpha with shape [11]; unstable size 11; total size 512 (torch.Size([1, 512]))
layer /34 start_node /35 using full alpha with unstable size None total_size 9 output_shape 9
Optimizable variables initialized.
initial CROWN bounds: tensor([[ 4.66079330,  5.06178761,  5.61804724,  4.95026398,  3.18083572,
         -0.66849524, -1.44434476,  7.45653391,  2.78505516]], device='cuda:0') None
best_l after optimization: 42.06480026245117 with beta sum per layer: []
alpha/beta optimization time: 12.073049783706665
initial alpha-CROWN bounds: tensor([[ 5.19139147,  6.41232729,  6.47227573,  5.69581747,  5.27674150,
          0.19790834, -0.10901147,  8.75562286,  4.17172813]], device='cuda:0')
Worst class: (+ rhs) -0.10901147127151489
Total VNNLIB file length: 9, max property batch size: 1, total number of batches: 9
lA shape: [torch.Size([1, 9, 32, 28, 28]), torch.Size([1, 9, 32, 14, 14]), torch.Size([1, 9, 64, 14, 14]), torch.Size([1, 9, 64, 7, 7]), torch.Size([1, 9, 512]), torch.Size([1, 9, 512])]

Properties batch 0, size 1
Remaining timeout: 161.38175129890442
##### Instance 0 first 10 spec matrices: [[[-1.  0.  0.  0.  0.  0.  0.  0.  1.  0.]]]
thresholds: [0] ######
Initial alpha-CROWN verified for spec index [0] with bound 5.191391468048096.

Properties batch 1, size 1
Remaining timeout: 161.2900354862213
##### Instance 0 first 10 spec matrices: [[[ 0. -1.  0.  0.  0.  0.  0.  0.  1.  0.]]]
thresholds: [0] ######
Initial alpha-CROWN verified for spec index [0] with bound 6.412327289581299.

Properties batch 2, size 1
Remaining timeout: 161.2502043247223
##### Instance 0 first 10 spec matrices: [[[ 0.  0. -1.  0.  0.  0.  0.  0.  1.  0.]]]
thresholds: [0] ######
Initial alpha-CROWN verified for spec index [0] with bound 6.472275733947754.

Properties batch 3, size 1
Remaining timeout: 161.21063327789307
##### Instance 0 first 10 spec matrices: [[[ 0.  0.  0. -1.  0.  0.  0.  0.  1.  0.]]]
thresholds: [0] ######
Initial alpha-CROWN verified for spec index [0] with bound 5.695817470550537.

Properties batch 4, size 1
Remaining timeout: 161.1710708141327
##### Instance 0 first 10 spec matrices: [[[ 0.  0.  0.  0. -1.  0.  0.  0.  1.  0.]]]
thresholds: [0] ######
Initial alpha-CROWN verified for spec index [0] with bound 5.2767415046691895.

Properties batch 5, size 1
Remaining timeout: 161.13146209716797
##### Instance 0 first 10 spec matrices: [[[ 0.  0.  0.  0.  0. -1.  0.  0.  1.  0.]]]
thresholds: [0] ######
Initial alpha-CROWN verified for spec index [0] with bound 0.19790834188461304.

Properties batch 6, size 1
Remaining timeout: 161.09184885025024
##### Instance 0 first 10 spec matrices: [[[ 0.  0.  0.  0.  0.  0. -1.  0.  1.  0.]]]
thresholds: [0] ######
Remaining spec index [0] with bounds tensor([[-0.10901147]], device='cuda:0') need to verify.
Model prediction is: tensor([-1.50842750, -2.78271246, -3.05500746, -2.76670456, -2.05510044,
         3.06344867,  2.96421409, -5.58440161,  4.34885550, -0.61086601],
       device='cuda:0')
build_the_model_with_refined_bounds batch [0/1]
setting alpha for layer /input.4 start_node /35 with alignment adjustment
setting alpha for layer /input.12 start_node /35 with alignment adjustment
setting alpha for layer /input.20 start_node /35 with alignment adjustment
setting alpha for layer /22 start_node /35 with alignment adjustment
setting alpha for layer /32 start_node /35 with alignment adjustment
setting alpha for layer /34 start_node /35 with alignment adjustment
all slope initialized
directly get lb and ub from refined bounds
lA shapes: [torch.Size([1, 1, 32, 28, 28]), torch.Size([1, 1, 32, 14, 14]), torch.Size([1, 1, 64, 14, 14]), torch.Size([1, 1, 64, 7, 7]), torch.Size([1, 1, 512]), torch.Size([1, 1, 512])]
c shape: torch.Size([1, 1, 10])
alpha-CROWN with fixed intermediate bounds: tensor([[-0.10901147]], device='cuda:0') tensor([[inf]], device='cuda:0')
Keeping slopes for these layers: ['/35']
Keeping slopes for these layers: ['/35']
layer 0 name BoundConv(name="/input") size torch.Size([25088]) unstable 593
layer 1 name BoundConv(name="/input.8") size torch.Size([6272]) unstable 46
layer 2 name BoundConv(name="/input.16") size torch.Size([12544]) unstable 31
layer 3 name BoundConv(name="/input.24") size torch.Size([3136]) unstable 21
layer 4 name BoundLinear(name="/input.28") size torch.Size([512]) unstable 3
layer 5 name BoundLinear(name="/input.32") size torch.Size([512]) unstable 8
-----------------
# of unstable neurons: 702
-----------------

batch:  torch.Size([1, 32, 28, 28]) pre split depth:  4
post split depth:  4
splitting decisions: 
split level 0: [2, 4571] 
split level 1: [2, 4586] 
split level 2: [3, 1530] 
split level 3: [3, 2444] 
pruning_in_iteration open status: True
ratio of positive domain = 15 / 16 = 0.9375
pruning-in-iteration extra time: 0.014606952667236328
Time: prepare 0.0042    beta_bound 0.7716    bound 0.7717    transfer 0.0012    finalize 0.0035    func 0.7806    
Accumulated time: func 0.7806    prepare 0.0084    bound 0.7717    beta_bound 0.7716    transfer 0.0012    finalize 0.0035    
batch bounding time:  0.7807211875915527
Current worst splitting domains lb-rhs (depth):
-0.06018 (4), 
length of domains: 1
Time: pickout 0.0015    decision 0.4365    solve 0.7835    add 0.0029    
Accumulated time: pickout 0.0015    decision 0.4365    solve 0.7835    add 0.0029    
Current (lb-rhs): -0.06018102169036865
1 domains visited
Cumulative time: 1.5891404151916504

batch:  torch.Size([1, 32, 28, 28]) pre split depth:  4
post split depth:  4
splitting decisions: 
split level 0: [3, 2097] 
split level 1: [2, 4622] 
split level 2: [3, 2069] 
split level 3: [2, 4545] 
pruning_in_iteration open status: True
ratio of positive domain = 15 / 16 = 0.9375
pruning-in-iteration extra time: 0.014693021774291992
Time: prepare 0.0043    beta_bound 0.3729    bound 0.3729    transfer 0.0012    finalize 0.0034    func 0.3819    
Accumulated time: func 1.1626    prepare 0.0166    bound 1.1446    beta_bound 1.1445    transfer 0.0024    finalize 0.0069    
batch bounding time:  0.38196802139282227
Current worst splitting domains lb-rhs (depth):
-0.00015 (8), 
length of domains: 1
Time: pickout 0.0014    decision 0.0402    solve 0.3848    add 0.0025    
Accumulated time: pickout 0.0029    decision 0.4767    solve 1.1683    add 0.0054    
Current (lb-rhs): -0.00015020370483398438
2 domains visited
Cumulative time: 2.0182042121887207

batch:  torch.Size([1, 32, 28, 28]) pre split depth:  4
post split depth:  4
splitting decisions: 
split level 0: [2, 4558] 
split level 1: [2, 4557] 
split level 2: [2, 4670] 
split level 3: [3, 2066] 

all verified at 3th iter
pruning_in_iteration open status: True/home/zhouxingshi/gputest/CROWN-GENERAL/complete_verifier/data_utils.py:232: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  eps_temp = torch.tensor(eps_temp / std).reshape(1, -1, 1, 1)

ratio of positive domain = 16 / 16 = 1.0
pruning-in-iteration extra time: 0.002200603485107422
Time: prepare 0.0043    beta_bound 0.0664    bound 0.0665    transfer 0.0012    finalize 0.0034    func 0.0755    
Accumulated time: func 1.2380    prepare 0.0250    bound 1.2111    beta_bound 1.2109    transfer 0.0036    finalize 0.0103    
batch bounding time:  0.07554078102111816
length of domains: 0
Time: pickout 0.0013    decision 0.0403    solve 0.0783    add 0.0018    
Accumulated time: pickout 0.0042    decision 0.5170    solve 1.2466    add 0.0072    
No domains left, verification finished!
Current (lb-rhs): 1.0000000116860974e-07
2 domains visited
Cumulative time: 2.1402416229248047


Properties batch 7, size 1
Remaining timeout: 158.79850792884827
##### Instance 0 first 10 spec matrices: [[[ 0.  0.  0.  0.  0.  0.  0. -1.  1.  0.]]]
thresholds: [0] ######
Initial alpha-CROWN verified for spec index [0] with bound 8.755622863769531.

Properties batch 8, size 1
Remaining timeout: 158.75226426124573
##### Instance 0 first 10 spec matrices: [[[ 0.  0.  0.  0.  0.  0.  0.  0.  1. -1.]]]
thresholds: [0] ######
Initial alpha-CROWN verified for spec index [0] with bound 4.171728134155273.
Result: safe in 21.2877 seconds
############# Summary #############
Final verified acc: 100.0% (total 1 examples)
Problem instances count: 1 , total verified (safe/unsat): 1 , total falsified (unsafe/sat): 0 , timeout: 0
mean time for ALL instances (total 1):21.287460121919775, max time: 21.287672996520996
mean time for verified SAFE instances(total 1): 21.287672996520996, max time: 21.287672996520996
safe (total 1), index: [0]
