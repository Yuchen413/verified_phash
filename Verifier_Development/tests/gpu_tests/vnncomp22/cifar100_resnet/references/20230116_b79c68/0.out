Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  sparse_alpha: true
  save_adv_example: false
  precompile_jit: false
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2022_benchmarks/benchmarks/cifar100_tinyimagenet_resnet
model:
  name: null
  path: null
  onnx_path: null
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: default_onnx_and_vnnlib_loader
  onnx_optimization_flags: merge_bn
data:
  start: 0
  end: 1
  select_instance: null
  num_outputs: 100
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  vnnlib_path: null
  vnnlib_path_prefix: ''
solver:
  batch_size: 256
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: true
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.25
    iteration: 20
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
    full_conv_alpha: false
  beta-crown:
    lr_alpha: 0.05
    lr_beta: 0.1
    lr_decay: 0.98
    optimizer: adam
    iteration: 5
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
bab:
  initial_max_domains: 100
  max_domains: .inf
  decision_thresh: 0
  timeout: 360
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_intermediate_layers: ''
  interm_transfer: false
  cut:
    enabled: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 100
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
    _tmp_cuts: null
    fixed_cuts: false
    add_implied_cuts: false
    add_input_cuts: false
  branching:
    method: kfsb
    candidates: 7
    reduceop: max
    sb_coeff_thresh: 0.001
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sort_domain_interval: -1
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 30.0
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  pgd_steps: 100
  pgd_restarts: 10
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  cex_path: ./test_cex.txt
  attack_mode: PGD
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 5000000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
debug:
  lp_test: null

Experiments at Sun Jan 15 22:18:57 2023 on diablo.cs.ucla.edu
customized start/end sample from instance 0 to 1 in instances.csv
Internal results will be saved to a-b-crown_[instances]_start=0_end=1_iter=5_b=256_timeout=360_branching=kfsb-max-7_lra-init=0.25_lra=0.05_lrb=0.1_PGD=skip_cplex_cuts=False_initial_max_domains=100.npz.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx onnx/CIFAR100_resnet_small.onnx
Using vnnlib vnnlib/CIFAR100_resnet_small_prop_idx_7129_sidx_1634_eps_0.0039.vnnlib
Precompiled vnnlib file found at ../../vnncomp2022_benchmarks/benchmarks/cifar100_tinyimagenet_resnet/vnnlib/CIFAR100_resnet_small_prop_idx_7129_sidx_1634_eps_0.0039.vnnlib.compiled
Loading onnx ../../vnncomp2022_benchmarks/benchmarks/cifar100_tinyimagenet_resnet/onnx/CIFAR100_resnet_small.onnx wih quirks {}
Onnx optimization with flag: merge_bn
Found existed optimized onnx model at ../../vnncomp2022_benchmarks/benchmarks/cifar100_tinyimagenet_resnet/onnx/CIFAR100_resnet_small.onnx.optimized
Model prediction is: tensor([[ -6.16110611,  -5.35189247,  -6.63838196,  -1.86059761,   0.11116584,
         -10.11872673,  -4.05360031,  -1.74366450,  -3.32689142,  -8.15904236,
          -7.46693563,  -5.78805780,  -3.15143609,  -5.00590134,  -4.14910078,
          -2.56400585,  -7.67670918,  -7.34021759,  -4.19427729,  -2.98574638,
         -11.50354290,  -2.86428237,  -6.95179081,  -8.57429600,  -5.86174917,
          -6.12972975,  -1.81921124,  -1.88009501,  -7.23338795,  -2.77960277,
          -6.66013479,  -2.95222259,  -4.44099236,  -2.23306108,  -2.14823103,
          -6.19033241,  -7.01506472,  -3.64295626,  -1.63159943,  -6.60959435,
          -6.24223185,  -5.34258413,  -2.82549000,  -4.65815115,  -1.93024802,
          -1.66022003,  -5.19752359,  -4.90962315,  -3.16080785,  -6.14222050,
          -1.68901002,  -1.35682666,  -4.53342772,  -9.38375664,  -6.84528923,
          -0.98658538,  -2.42015982,  -6.15781927,  -4.54610157,  -3.36491632,
          -7.45315218,  -9.82804394,  -6.81166935,  -2.71696711,  -0.80461359,
          -3.63948226,  -0.40597302,  -4.75543308,  -6.19850063,  -6.96731520,
          -5.63448668,  -6.89007616,  -1.89141941,  -5.16311264,   2.23245382,
          -3.20890164,  -7.58390331,  -2.06751800,  -2.76550269,  -1.95667255,
          -2.20863008,  -3.25515842,  -5.95652390,  -4.48778105,  -7.88440990,
          -3.25094366,  -6.59201813,  -7.73082256,  -5.21276379,  -2.16033602,
          -1.06771100,  -5.50464869,  -5.21620941,  -3.12952518,  -9.58456707,
          -7.41099882,  -4.63919449,  -2.05928230,  -6.47336006,  -2.76289630]],
       device='cuda:0')
layer /54 using sparse-features alpha with shape [553]; unstable size 553; total size 14400 (torch.Size([1, 64, 15, 15]))
layer /54 start_node /input.4 using sparse-spec alpha with unstable size 82 total_size 128 output_shape 128
layer /54 start_node /59 using sparse-spec alpha with unstable size 106 total_size 128 output_shape 128
layer /54 start_node /input.12 using sparse-spec alpha with unstable size 15 total_size 128 output_shape 128
layer /54 start_node /64 using sparse-spec alpha with unstable size 91 total_size 128 output_shape 128
layer /54 start_node /input.20 using sparse-spec alpha with unstable size 108 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /54 start_node /70 using sparse-spec alpha with unstable size 316 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /54 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /54 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /54 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /56 using sparse-features alpha with shape [217]; unstable size 217; total size 8192 (torch.Size([1, 128, 8, 8]))
layer /56 start_node /59 using sparse-spec alpha with unstable size 106 total_size 128 output_shape 128
layer /56 start_node /input.12 using sparse-spec alpha with unstable size 15 total_size 128 output_shape 128
layer /56 start_node /64 using sparse-spec alpha with unstable size 91 total_size 128 output_shape 128
layer /56 start_node /input.20 using sparse-spec alpha with unstable size 108 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /56 start_node /70 using sparse-spec alpha with unstable size 316 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /56 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /56 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /56 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /input.8 using sparse-features alpha with shape [408]; unstable size 408; total size 8192 (torch.Size([1, 128, 8, 8]))
layer /input.8 start_node /input.12 using sparse-spec alpha with unstable size 15 total_size 128 output_shape 128
layer /input.8 start_node /64 using sparse-spec alpha with unstable size 91 total_size 128 output_shape 128
layer /input.8 start_node /input.20 using sparse-spec alpha with unstable size 59 total_size 128 output_shape 128
layer /input.8 start_node /70 using sparse-spec alpha with unstable size 316 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /input.8 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /input.8 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /input.8 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /62 using sparse-features alpha with shape [43]; unstable size 43; total size 8192 (torch.Size([1, 128, 8, 8]))
layer /62 start_node /64 using sparse-spec alpha with unstable size 91 total_size 128 output_shape 128
layer /62 start_node /input.20 using sparse-spec alpha with unstable size 59 total_size 128 output_shape 128
layer /62 start_node /70 using sparse-spec alpha with unstable size 316 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /62 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /62 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /62 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /input.16 using sparse-features alpha with shape [337]; unstable size 337; total size 8192 (torch.Size([1, 128, 8, 8]))
layer /input.16 start_node /input.20 using sparse-spec alpha with unstable size 59 total_size 128 output_shape 128
layer /input.16 start_node /70 using sparse-spec alpha with unstable size 100 total_size 128 output_shape 128
layer /input.16 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /input.16 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /input.16 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /67 using sparse-features alpha with shape [108]; unstable size 108; total size 2048 (torch.Size([1, 128, 4, 4]))
layer /67 start_node /70 using sparse-spec alpha with unstable size 100 total_size 128 output_shape 128
layer /67 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /67 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /67 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /input.24 using sparse-features alpha with shape [316]; unstable size 316; total size 2048 (torch.Size([1, 128, 4, 4]))
layer /input.24 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /input.24 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /input.24 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /73 using sparse-features alpha with shape [0]; unstable size 0; total size 2048 (torch.Size([1, 128, 4, 4]))
layer /73 start_node /75 using sparse-spec alpha with unstable size 53 total_size 128 output_shape 128
layer /73 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /73 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /76 using sparse-features alpha with shape [150]; unstable size 150; total size 2048 (torch.Size([1, 128, 4, 4]))
layer /76 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /76 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /79 using sparse-features alpha with shape [12]; unstable size 12; total size 100 (torch.Size([1, 100]))
layer /79 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
Optimizable variables initialized.
initial CROWN bounds: tensor([[ 4.58201599,  4.65631151,  5.54419088,  1.16658807, -0.02561784,
          8.95760250,  2.92083073,  1.14079475,  1.54260063,  6.60651731,
          6.72118139,  4.72295618,  1.85433555,  3.96015263,  3.29507637,
          1.82076073,  6.14002419,  5.73220110,  3.15422964,  1.95755625,
          9.82365036,  1.88867426,  5.52393532,  7.77056170,  5.11357450,
          5.20151854,  1.33262062,  1.49766874,  6.21567822,  1.55252922,
          5.87450647,  1.85210514,  3.75290680,  0.78319740,  1.26455259,
          4.88834381,  6.21213198,  2.83590031,  1.20468974,  4.86897707,
          4.78672695,  3.89892673,  1.78502107,  3.59130001,  1.30915201,
          1.02204800,  4.03141689,  2.62421227,  1.27290916,  5.27491760,
          2.30410433,  0.47220731,  2.56467295,  7.35462570,  5.69668484,
          0.80267686,  0.71510339,  4.70078897,  3.13846493,  1.79706717,
          5.98687553,  8.38723373,  5.69914627,  2.59605503,  0.47852325,
          3.19327497, -0.67651439,  4.54048920,  4.93768406,  5.61079216,
          3.82027340,  6.05506659,  1.46648479,  4.81224155,  2.09049416,
          6.37115574,  1.13275516,  1.83720064,  0.85678601,  1.74134696,
          2.26106882,  4.88197708,  3.27520084,  6.57559586,  2.21175957,
          4.97303963,  6.46450615,  4.21741009,  0.68550920,  0.35515904,
          4.71084118,  4.08793449,  2.73747659,  7.69276810,  6.60700655,
          2.63158464,  1.51131105,  5.10305119,  2.18639469]], device='cuda:0') None
prune_after_crown optimization in use: original label size = 99 pruned label size = 2
best_l after optimization: 0.4482872784137726 with beta sum per layer: []
alpha/beta optimization time: 11.494834184646606
initial alpha-CROWN bounds: tensor([[        inf,         inf,         inf,         inf,  0.44896773,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf, -0.00068045,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf]], device='cuda:0')
Worst class: (+ rhs) -0.0006804466247558594
Total VNNLIB file length: 99, max property batch size: 100, total number of batches: 1
lA shape: [torch.Size([1, 99, 64, 15, 15]), torch.Size([1, 99, 128, 8, 8]), torch.Size([1, 99, 128, 8, 8]), torch.Size([1, 99, 128, 8, 8]), torch.Size([1, 99, 128, 8, 8]), torch.Size([1, 99, 128, 4, 4]), torch.Size([1, 99, 128, 4, 4]), torch.Size([1, 99, 128, 4, 4]), torch.Size([1, 99, 128, 4, 4]), torch.Size([1, 99, 100])]

Properties batch 0, size 99
Remaining timeout: 220.77476620674133
##### Instance 0 first 10 spec matrices: [[[-1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]

 [[ 0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]

 [[ 0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]

 [[ 0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]

 [[ 0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]]
thresholds: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ######
Initial alpha-CROWN verified for spec index [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 67 68 69 70 71 72
 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96
 97 98] with bound tensor([       inf,        inf,        inf,        inf, 0.44896773,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf], device='cuda:0').
Remaining spec index [66] with bounds tensor([[-0.00068045]], device='cuda:0') need to verify.
Model prediction is: tensor([ -6.16110611,  -5.35189247,  -6.63838196,  -1.86059761,   0.11116584,
        -10.11872673,  -4.05360031,  -1.74366450,  -3.32689142,  -8.15904236,
         -7.46693563,  -5.78805780,  -3.15143609,  -5.00590134,  -4.14910078,
         -2.56400585,  -7.67670918,  -7.34021759,  -4.19427729,  -2.98574638,
        -11.50354290,  -2.86428237,  -6.95179081,  -8.57429600,  -5.86174917,
         -6.12972975,  -1.81921124,  -1.88009501,  -7.23338795,  -2.77960277,
         -6.66013479,  -2.95222259,  -4.44099236,  -2.23306108,  -2.14823103,
         -6.19033241,  -7.01506472,  -3.64295626,  -1.63159943,  -6.60959435,
         -6.24223185,  -5.34258413,  -2.82549000,  -4.65815115,  -1.93024802,
         -1.66022003,  -5.19752359,  -4.90962315,  -3.16080785,  -6.14222050,
         -1.68901002,  -1.35682666,  -4.53342772,  -9.38375664,  -6.84528923,
         -0.98658538,  -2.42015982,  -6.15781927,  -4.54610157,  -3.36491632,
         -7.45315218,  -9.82804394,  -6.81166935,  -2.71696711,  -0.80461359,
         -3.63948226,  -0.40597302,  -4.75543308,  -6.19850063,  -6.96731520,
         -5.63448668,  -6.89007616,  -1.89141941,  -5.16311264,   2.23245382,
         -3.20890164,  -7.58390331,  -2.06751800,  -2.76550269,  -1.95667255,
         -2.20863008,  -3.25515842,  -5.95652390,  -4.48778105,  -7.88440990,
         -3.25094366,  -6.59201813,  -7.73082256,  -5.21276379,  -2.16033602,
         -1.06771100,  -5.50464869,  -5.21620941,  -3.12952518,  -9.58456707,
         -7.41099882,  -4.63919449,  -2.05928230,  -6.47336006,  -2.76289630],
       device='cuda:0')/home/zhouxingshi/onnx2pytorch/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  "Using experimental implementation that allows 'batch_size > 1'."
/home/zhouxingshi/onnx2pytorch/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/zhouxingshi/onnx2pytorch/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):

build_the_model_with_refined_bounds batch [0/1]
setting alpha for layer /54 start_node /80 with alignment adjustment
setting alpha for layer /56 start_node /80 with alignment adjustment
setting alpha for layer /input.8 start_node /80 with alignment adjustment
setting alpha for layer /62 start_node /80 with alignment adjustment
setting alpha for layer /input.16 start_node /80 with alignment adjustment
setting alpha for layer /67 start_node /80 with alignment adjustment
setting alpha for layer /input.24 start_node /80 with alignment adjustment
setting alpha for layer /73 start_node /80 with alignment adjustment
setting alpha for layer /76 start_node /80 with alignment adjustment
setting alpha for layer /79 start_node /80 with alignment adjustment
all slope initialized
directly get lb and ub from refined bounds
lA shapes: [torch.Size([1, 1, 64, 15, 15]), torch.Size([1, 1, 128, 8, 8]), torch.Size([1, 1, 128, 8, 8]), torch.Size([1, 1, 128, 8, 8]), torch.Size([1, 1, 128, 8, 8]), torch.Size([1, 1, 128, 4, 4]), torch.Size([1, 1, 128, 4, 4]), torch.Size([1, 1, 128, 4, 4]), torch.Size([1, 1, 128, 4, 4]), torch.Size([1, 1, 100])]
c shape: torch.Size([1, 1, 100])
alpha-CROWN with fixed intermediate bounds: tensor([[-0.00068045]], device='cuda:0') tensor([[inf]], device='cuda:0')
Keeping slopes for these layers: ['/80']
Keeping slopes for these layers: ['/80']
layer 0 name BoundConv(name="/input") size torch.Size([14400]) unstable 553
layer 1 name BoundConv(name="/input.4") size torch.Size([8192]) unstable 212
layer 2 name BoundAdd(name="/59") size torch.Size([8192]) unstable 396
layer 3 name BoundConv(name="/input.12") size torch.Size([8192]) unstable 41
layer 4 name BoundAdd(name="/64") size torch.Size([8192]) unstable 325
layer 5 name BoundConv(name="/input.20") size torch.Size([2048]) unstable 101
layer 6 name BoundAdd(name="/70") size torch.Size([2048]) unstable 300
layer 7 name BoundConv(name="/input.28") size torch.Size([2048]) unstable 0
layer 8 name BoundAdd(name="/75") size torch.Size([2048]) unstable 143
layer 9 name BoundLinear(name="/input.32") size torch.Size([100]) unstable 9
-----------------
# of unstable neurons: 2080
-----------------

batch:  torch.Size([1, 64, 15, 15]) pre split depth:  4
post split depth:  4
splitting decisions: 
split level 0: [9, 71] 
split level 1: [9, 49] 
split level 2: [6, 1466] 
split level 3: [9, 43] 

all verified at 0th iter
pruning_in_iteration open status: False
ratio of positive domain = 16 / 16 = 1.0
pruning-in-iteration extra time: 0.0001087188720703125
Time: prepare 0.0074    beta_bound 0.0216    bound 0.0216    transfer 0.0012    finalize 0.0034    func 0.0337    
Accumulated time: func 0.0337    prepare 0.0169    bound 0.0216    beta_bound 0.0216    transfer 0.0012    finalize 0.0034    
batch bounding time:  0.033721208572387695
length of domains: 0
Time: pickout 0.0025    decision 0.5220    solve 0.0380    add 0.0021    
Accumulated time: pickout 0.0025    decision 0.5220    solve 0.0380    add 0.0021    
No domains left, verification finished!
Current (lb-rhs): 1.0000000116860974e-07
0 domains visited
Cumulative time: 0.9768390655517578

Result: safe in 20.7776 seconds
############# Summary #############
Final verified acc: 100.0% (total 1 examples)
Problem instances count: 1 , total verified (safe/unsat): 1 , total falsified (unsafe/sat): 0 , timeout: 0
mean time for ALL instances (total 1):20.77740610418908, max time: 20.777613878250122
mean time for verified SAFE instances(total 1): 20.777613878250122, max time: 20.777613878250122
safe (total 1), index: [0]
