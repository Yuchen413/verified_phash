Configurations:

general:
  device: cuda
  seed: 100
  conv_mode: patches
  deterministic: false
  double_fp: false
  loss_reduction_func: sum
  sparse_alpha: true
  save_adv_example: false
  precompile_jit: false
  complete_verifier: bab
  enable_incomplete_verification: true
  csv_name: instances.csv
  results_file: out.txt
  root_path: ../../vnncomp2022_benchmarks/benchmarks/cifar100_tinyimagenet_resnet
model:
  name: null
  path: null
  onnx_path: null
  onnx_path_prefix: ''
  cache_onnx_conversion: false
  onnx_quirks: null
  input_shape: null
  onnx_loader: default_onnx_and_vnnlib_loader
  onnx_optimization_flags: merge_bn
data:
  start: 0
  end: 1
  select_instance: null
  num_outputs: 100
  mean: 0.0
  std: 1.0
  pkl_path: null
  dataset: null
  data_filter_path: null
  data_idx_file: null
specification:
  type: lp
  robustness_type: verified-acc
  norm: .inf
  epsilon: null
  epsilon_min: 0.0
  vnnlib_path: null
  vnnlib_path_prefix: ''
solver:
  batch_size: 256
  min_batch_size_ratio: 0.1
  use_float64_in_last_iteration: false
  early_stop_patience: 10
  start_save_best: 0.5
  bound_prop_method: alpha-crown
  init_bound_prop_method: same
  prune_after_crown: true
  crown:
    batch_size: 1000000000
    max_crown_size: 1000000000
  alpha-crown:
    alpha: true
    lr_alpha: 0.25
    iteration: 20
    share_slopes: false
    no_joint_opt: false
    lr_decay: 0.98
    full_conv_alpha: false
  beta-crown:
    lr_alpha: 0.05
    lr_beta: 0.1
    lr_decay: 0.98
    optimizer: adam
    iteration: 5
    beta: true
    beta_warmup: true
    enable_opt_interm_bounds: false
    all_node_split_LP: false
  forward:
    refine: false
    dynamic: false
    max_dim: 10000
  intermediate_refinement:
    enabled: false
    batch_size: 10
    opt_coeffs: false
    opt_bias: false
    lr: 0.05
    layers: [-1]
    max_domains: 1000
  multi_class:
    label_batch_size: 32
    skip_with_refined_bound: true
  mip:
    parallel_solvers: null
    solver_threads: 1
    refine_neuron_timeout: 15
    refine_neuron_time_percentage: 0.8
    early_stop: true
    adv_warmup: true
    mip_solver: gurobi
bab:
  initial_max_domains: 100
  max_domains: .inf
  decision_thresh: 0
  timeout: 360
  timeout_scale: 1
  override_timeout: null
  get_upper_bound: false
  dfs_percent: 0.0
  pruning_in_iteration: true
  pruning_in_iteration_ratio: 0.2
  sort_targets: false
  batched_domain_list: true
  optimized_intermediate_layers: ''
  interm_transfer: false
  cut:
    enabled: false
    implication: false
    bab_cut: false
    lp_cut: false
    method: null
    lr: 0.01
    lr_decay: 1.0
    iteration: 100
    bab_iteration: -1
    early_stop_patience: -1
    lr_beta: 0.02
    number_cuts: 50
    topk_cuts_in_filter: 1000
    batch_size_primal: 100
    max_num: 1000000000
    patches_cut: false
    cplex_cuts: false
    cplex_cuts_wait: 0
    cplex_cuts_revpickup: true
    cut_reference_bounds: true
    fix_intermediate_bounds: false
    _tmp_cuts: null
    fixed_cuts: false
    add_implied_cuts: false
    add_input_cuts: false
  branching:
    method: kfsb
    candidates: 7
    reduceop: max
    sb_coeff_thresh: 0.001
    enable_intermediate_bound_opt: false
    branching_input_and_activation: false
    branching_input_and_activation_order: [input, relu]
    branching_input_iterations: 30
    branching_relu_iterations: 50
    sort_domain_interval: -1
    nonlinear_split:
      method: babsr_like
      branching_point_method: middle
      num_branches: 2
      branching_point_refinement: false
      naive_branching_score: false
      filter: false
      prioritize_mul: false
    input_split:
      enable: false
      enhanced_bound_prop_method: alpha-crown
      enhanced_branching_method: naive
      enhanced_bound_patience: 100000000.0
      attack_patience: 100000000.0
      adv_check: 0
  attack:
    enabled: false
    beam_candidates: 8
    beam_depth: 7
    max_dive_fix_ratio: 0.8
    min_local_free_ratio: 0.2
    mip_start_iteration: 5
    mip_timeout: 30.0
    adv_pool_threshold: null
    refined_mip_attacker: false
    refined_batch_size: null
attack:
  pgd_order: skip
  pgd_steps: 100
  pgd_restarts: 10
  pgd_early_stop: true
  pgd_lr_decay: 0.99
  pgd_alpha: auto
  pgd_loss_mode: null
  enable_mip_attack: false
  cex_path: ./test_cex.txt
  attack_mode: PGD
  gama_lambda: 10.0
  gama_decay: 0.9
  check_clean: false
  input_split:
    pgd_steps: 100
    pgd_restarts: 30
    pgd_alpha: auto
  input_split_enhanced:
    pgd_steps: 200
    pgd_restarts: 5000000
    pgd_alpha: auto
  input_split_check_adv:
    pgd_steps: 5
    pgd_restarts: 5
    pgd_alpha: auto
debug:
  lp_test: null

Experiments at Tue Mar 28 13:31:09 2023 on zeratul
customized start/end sample from instance 0 to 1 in instances.csv
Internal results will be saved to a-b-crown_[instances]_start=0_end=1_iter=5_b=256_timeout=360_branching=kfsb-max-7_lra-init=0.25_lra=0.05_lrb=0.1_PGD=skip_cplex_cuts=False_initial_max_domains=100.npz.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Using onnx onnx/CIFAR100_resnet_small.onnx
Using vnnlib vnnlib/CIFAR100_resnet_small_prop_idx_7129_sidx_1634_eps_0.0039.vnnlib
Precompiled vnnlib file found at ../../vnncomp2022_benchmarks/benchmarks/cifar100_tinyimagenet_resnet/vnnlib/CIFAR100_resnet_small_prop_idx_7129_sidx_1634_eps_0.0039.vnnlib.compiled
Loading onnx ../../vnncomp2022_benchmarks/benchmarks/cifar100_tinyimagenet_resnet/onnx/CIFAR100_resnet_small.onnx wih quirks {}
Onnx optimization with flag: merge_bn
Found existed optimized onnx model at ../../vnncomp2022_benchmarks/benchmarks/cifar100_tinyimagenet_resnet/onnx/CIFAR100_resnet_small.onnx.optimized
Model: BoundedModule(
  (/input.1): BoundInput(name=/input.1, inputs=[])
  (/27): BoundParams(name=/27, inputs=[])
  (/28): BoundParams(name=/28, inputs=[])
  (/29): BoundParams(name=/29, inputs=[])
  (/30): BoundParams(name=/30, inputs=[])
  (/31): BoundParams(name=/31, inputs=[])
  (/32): BoundParams(name=/32, inputs=[])
  (/33): BoundParams(name=/33, inputs=[])
  (/34): BoundParams(name=/34, inputs=[])
  (/35): BoundParams(name=/35, inputs=[])
  (/36): BoundParams(name=/36, inputs=[])
  (/37): BoundParams(name=/37, inputs=[])
  (/38): BoundParams(name=/38, inputs=[])
  (/39): BoundParams(name=/39, inputs=[])
  (/40): BoundParams(name=/40, inputs=[])
  (/41): BoundParams(name=/41, inputs=[])
  (/42): BoundParams(name=/42, inputs=[])
  (/43): BoundParams(name=/43, inputs=[])
  (/44): BoundParams(name=/44, inputs=[])
  (/45): BoundParams(name=/45, inputs=[])
  (/46): BoundParams(name=/46, inputs=[])
  (/47): BoundParams(name=/47, inputs=[])
  (/48): BoundParams(name=/48, inputs=[])
  (/49): BoundParams(name=/49, inputs=[])
  (/50): BoundParams(name=/50, inputs=[])
  (/51): BoundParams(name=/51, inputs=[])
  (/52): BoundParams(name=/52, inputs=[])
  (/input): BoundConv(name=/input, inputs=[/input.1, /27, /28])
  (/54): BoundRelu(name=/54, inputs=[/input])
  (/input.4): BoundConv(name=/input.4, inputs=[/54, /29, /30])
  (/56): BoundRelu(name=/56, inputs=[/input.4])
  (/57): BoundConv(name=/57, inputs=[/56, /31, /32])
  (/58): BoundConv(name=/58, inputs=[/54, /33, /34])
  (/59): BoundAdd(name=/59, inputs=[/57, /58])
  (/input.8): BoundRelu(name=/input.8, inputs=[/59])
  (/input.12): BoundConv(name=/input.12, inputs=[/input.8, /35, /36])
  (/62): BoundRelu(name=/62, inputs=[/input.12])
  (/63): BoundConv(name=/63, inputs=[/62, /37, /38])
  (/64): BoundAdd(name=/64, inputs=[/63, /input.8])
  (/input.16): BoundRelu(name=/input.16, inputs=[/64])
  (/input.20): BoundConv(name=/input.20, inputs=[/input.16, /39, /40])
  (/67): BoundRelu(name=/67, inputs=[/input.20])
  (/68): BoundConv(name=/68, inputs=[/67, /41, /42])
  (/69): BoundConv(name=/69, inputs=[/input.16, /43, /44])
  (/70): BoundAdd(name=/70, inputs=[/68, /69])
  (/input.24): BoundRelu(name=/input.24, inputs=[/70])
  (/input.28): BoundConv(name=/input.28, inputs=[/input.24, /45, /46])
  (/73): BoundRelu(name=/73, inputs=[/input.28])
  (/74): BoundConv(name=/74, inputs=[/73, /47, /48])
  (/75): BoundAdd(name=/75, inputs=[/74, /input.24])
  (/76): BoundRelu(name=/76, inputs=[/75])
  (/77): BoundFlatten(name=/77, inputs=[/76])
  (/input.32): BoundLinear(name=/input.32, inputs=[/77, /49, /50])
  (/79): BoundRelu(name=/79, inputs=[/input.32])
  (/80): BoundLinear(name=/80, inputs=[/79, /51, /52])
)
Model prediction is: tensor([[ -6.16110611,  -5.35189104,  -6.63838196,  -1.86059761,   0.11116534,
         -10.11872673,  -4.05360079,  -1.74366474,  -3.32689190,  -8.15904140,
          -7.46693563,  -5.78805733,  -3.15143585,  -5.00590038,  -4.14910078,
          -2.56400585,  -7.67670774,  -7.34021807,  -4.19427729,  -2.98574591,
         -11.50354290,  -2.86428237,  -6.95179081,  -8.57429600,  -5.86174965,
          -6.12973022,  -1.81921148,  -1.88009489,  -7.23338842,  -2.77960229,
          -6.66013479,  -2.95222306,  -4.44099236,  -2.23306108,  -2.14823055,
          -6.19033194,  -7.01506519,  -3.64295554,  -1.63159895,  -6.60959387,
          -6.24223137,  -5.34258509,  -2.82548904,  -4.65815115,  -1.93024790,
          -1.66022027,  -5.19752359,  -4.90962362,  -3.16080809,  -6.14222050,
          -1.68901014,  -1.35682642,  -4.53342819,  -9.38375664,  -6.84528923,
          -0.98658550,  -2.42015982,  -6.15781975,  -4.54610014,  -3.36491656,
          -7.45315218,  -9.82804394,  -6.81166983,  -2.71696687,  -0.80461359,
          -3.63948178,  -0.40597218,  -4.75543308,  -6.19850063,  -6.96731472,
          -5.63448715,  -6.89007521,  -1.89141941,  -5.16311169,   2.23245358,
          -3.20890164,  -7.58390236,  -2.06751895,  -2.76550293,  -1.95667255,
          -2.20863032,  -3.25515842,  -5.95652390,  -4.48778105,  -7.88440895,
          -3.25094366,  -6.59201813,  -7.73082161,  -5.21276331,  -2.16033602,
          -1.06771088,  -5.50464773,  -5.21620893,  -3.12952518,  -9.58456707,
          -7.41099882,  -4.63919449,  -2.05928183,  -6.47336006,  -2.76289630]],
       device='cuda:0')
layer /54 using sparse-features alpha with shape [553]; unstable size 553; total size 14400 (torch.Size([1, 64, 15, 15]))
layer /54 start_node /input.4 using sparse-spec alpha with unstable size 82 total_size 128 output_shape 128
layer /54 start_node /59 using sparse-spec alpha with unstable size 106 total_size 128 output_shape 128
layer /54 start_node /input.12 using sparse-spec alpha with unstable size 15 total_size 128 output_shape 128
layer /54 start_node /64 using sparse-spec alpha with unstable size 91 total_size 128 output_shape 128
layer /54 start_node /input.20 using sparse-spec alpha with unstable size 108 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /54 start_node /70 using sparse-spec alpha with unstable size 316 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /54 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /54 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /54 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /56 using sparse-features alpha with shape [217]; unstable size 217; total size 8192 (torch.Size([1, 128, 8, 8]))
layer /56 start_node /59 using sparse-spec alpha with unstable size 106 total_size 128 output_shape 128
layer /56 start_node /input.12 using sparse-spec alpha with unstable size 15 total_size 128 output_shape 128
layer /56 start_node /64 using sparse-spec alpha with unstable size 91 total_size 128 output_shape 128
layer /56 start_node /input.20 using sparse-spec alpha with unstable size 108 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /56 start_node /70 using sparse-spec alpha with unstable size 316 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /56 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /56 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /56 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /input.8 using sparse-features alpha with shape [408]; unstable size 408; total size 8192 (torch.Size([1, 128, 8, 8]))
layer /input.8 start_node /input.12 using sparse-spec alpha with unstable size 15 total_size 128 output_shape 128
layer /input.8 start_node /64 using sparse-spec alpha with unstable size 91 total_size 128 output_shape 128
layer /input.8 start_node /input.20 using sparse-spec alpha with unstable size 59 total_size 128 output_shape 128
layer /input.8 start_node /70 using sparse-spec alpha with unstable size 316 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /input.8 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /input.8 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /input.8 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /62 using sparse-features alpha with shape [43]; unstable size 43; total size 8192 (torch.Size([1, 128, 8, 8]))
layer /62 start_node /64 using sparse-spec alpha with unstable size 91 total_size 128 output_shape 128
layer /62 start_node /input.20 using sparse-spec alpha with unstable size 59 total_size 128 output_shape 128
layer /62 start_node /70 using sparse-spec alpha with unstable size 316 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /62 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /62 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /62 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /input.16 using sparse-features alpha with shape [337]; unstable size 337; total size 8192 (torch.Size([1, 128, 8, 8]))
layer /input.16 start_node /input.20 using sparse-spec alpha with unstable size 59 total_size 128 output_shape 128
layer /input.16 start_node /70 using sparse-spec alpha with unstable size 100 total_size 128 output_shape 128
layer /input.16 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /input.16 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /input.16 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /67 using sparse-features alpha with shape [108]; unstable size 108; total size 2048 (torch.Size([1, 128, 4, 4]))
layer /67 start_node /70 using sparse-spec alpha with unstable size 100 total_size 128 output_shape 128
layer /67 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /67 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /67 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /input.24 using sparse-features alpha with shape [316]; unstable size 316; total size 2048 (torch.Size([1, 128, 4, 4]))
layer /input.24 start_node /75 using sparse-spec alpha with unstable size 150 total_size 2048 output_shape torch.Size([128, 4, 4])
layer /input.24 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /input.24 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /73 using sparse-features alpha with shape [0]; unstable size 0; total size 2048 (torch.Size([1, 128, 4, 4]))
layer /73 start_node /75 using sparse-spec alpha with unstable size 53 total_size 128 output_shape 128
layer /73 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /73 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /76 using sparse-features alpha with shape [150]; unstable size 150; total size 2048 (torch.Size([1, 128, 4, 4]))
layer /76 start_node /input.32 using sparse-spec alpha with unstable size 12 total_size 100 output_shape torch.Size([100])
layer /76 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
layer /79 using sparse-features alpha with shape [12]; unstable size 12; total size 100 (torch.Size([1, 100]))
layer /79 start_node /80 using full alpha with unstable size None total_size 99 output_shape 99
Optimizable variables initialized.
initial CROWN bounds: tensor([[ 4.58202457,  4.65631151,  5.54419041,  1.16659021, -0.02561867,
          8.95760536,  2.92083454,  1.14079428,  1.54260015,  6.60651398,
          6.72118425,  4.72295666,  1.85433364,  3.96015263,  3.29508209,
          1.82076550,  6.14002657,  5.73220062,  3.15423131,  1.95755768,
          9.82364750,  1.88867426,  5.52393818,  7.77056313,  5.11357021,
          5.20151758,  1.33262157,  1.49767137,  6.21567631,  1.55253124,
          5.87451077,  1.85210514,  3.75290871,  0.78319740,  1.26455438,
          4.88833809,  6.21212864,  2.83590317,  1.20469427,  4.86897898,
          4.78672981,  3.89892721,  1.78502560,  3.59129667,  1.30915773,
          1.02204370,  4.03141689,  2.62421036,  1.27291203,  5.27491522,
          2.30410457,  0.47220802,  2.56467819,  7.35463715,  5.69668484,
          0.80267704,  0.71510983,  4.70079470,  3.13847065,  1.79707098,
          5.98688221,  8.38723660,  5.69915295,  2.59605694,  0.47852039,
          3.19327545, -0.67651701,  4.54048538,  4.93768501,  5.61079407,
          3.82027912,  6.05507326,  1.46647847,  4.81224012,  2.09049630,
          6.37115431,  1.13275075,  1.83719862,  0.85678840,  1.74134517,
          2.26107264,  4.88197613,  3.27520275,  6.57559776,  2.21176195,
          4.97304344,  6.46449947,  4.21741199,  0.68551159,  0.35515475,
          4.71083832,  4.08793545,  2.73747730,  7.69276333,  6.60700607,
          2.63158703,  1.51131368,  5.10305023,  2.18639517]], device='cuda:0') None
prune_after_crown optimization in use: original label size = 99 pruned label size = 2
best_l after optimization: 0.448288232088089
alpha/beta optimization time: 13.415611267089844
initial alpha-CROWN bounds: tensor([[        inf,         inf,         inf,         inf,  0.44896749,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf, -0.00067925,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf,         inf,
                 inf,         inf,         inf,         inf]], device='cuda:0')
Worst class: (+ rhs) -0.0006792545318603516
Split layers:
  BoundLinear(name=/input.32, inputs=[/77, /49, /50]): [(BoundRelu(name=/79, inputs=[/input.32]), 0)]
  BoundAdd(name=/75, inputs=[/74, /input.24]): [(BoundRelu(name=/76, inputs=[/75]), 0)]
  BoundConv(name=/input.4, inputs=[/54, /29, /30]): [(BoundRelu(name=/56, inputs=[/input.4]), 0)]
  BoundAdd(name=/64, inputs=[/63, /input.8]): [(BoundRelu(name=/input.16, inputs=[/64]), 0)]
  BoundConv(name=/input.20, inputs=[/input.16, /39, /40]): [(BoundRelu(name=/67, inputs=[/input.20]), 0)]
  BoundAdd(name=/70, inputs=[/68, /69]): [(BoundRelu(name=/input.24, inputs=[/70]), 0)]
  BoundConv(name=/input, inputs=[/input.1, /27, /28]): [(BoundRelu(name=/54, inputs=[/input]), 0)]
  BoundConv(name=/input.28, inputs=[/input.24, /45, /46]): [(BoundRelu(name=/73, inputs=[/input.28]), 0)]
  BoundConv(name=/input.12, inputs=[/input.8, /35, /36]): [(BoundRelu(name=/62, inputs=[/input.12]), 0)]
  BoundAdd(name=/59, inputs=[/57, /58]): [(BoundRelu(name=/input.8, inputs=[/59]), 0)]
Total VNNLIB file length: 99, max property batch size: 100, total number of batches: 1
lA shape: [torch.Size([1, 99, 64, 15, 15]), torch.Size([1, 99, 128, 8, 8]), torch.Size([1, 99, 128, 8, 8]), torch.Size([1, 99, 128, 8, 8]), torch.Size([1, 99, 128, 8, 8]), torch.Size([1, 99, 128, 4, 4]), torch.Size([1, 99, 128, 4, 4]), torch.Size([1, 99, 128, 4, 4]), torch.Size([1, 99, 128, 4, 4]), torch.Size([1, 99, 100])]

Properties batch 0, size 99
Remaining timeout: 216.50986123085022
##### Instance 0 first 10 spec matrices: 
tensor([[[-1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.]],

        [[ 0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.]],

        [[ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.]],

        [[ 0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.]],

        [[ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.]],

        [[ 0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.]],

        [[ 0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.]],

        [[ 0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.]],

        [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.]],

        [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
           0.,  0.]]], dtype=torch.float64)
thresholds: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] ######
Initial alpha-CROWN verified for spec index [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 67 68 69 70 71 72
 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96
 97 98] with bound tensor([       inf,        inf,        inf,        inf, 0.44896749,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf,        inf,        inf,        inf,        inf,
               inf,        inf], device='cuda:0').
Remaining spec index [66] with bounds tensor([[-0.00067925]], device='cuda:0') need to verify.
Model: BoundedModule(
  (/input.1): BoundInput(name=/input.1, inputs=[])
  (/27): BoundParams(name=/27, inputs=[])
  (/28): BoundParams(name=/28, inputs=[])
  (/29): BoundParams(name=/29, inputs=[])
  (/30): BoundParams(name=/30, inputs=[])
  (/31): BoundParams(name=/31, inputs=[])
  (/32): BoundParams(name=/32, inputs=[])
  (/33): BoundParams(name=/33, inputs=[])
  (/34): BoundParams(name=/34, inputs=[])
  (/35): BoundParams(name=/35, inputs=[])
  (/36): BoundParams(name=/36, inputs=[])
  (/37): BoundParams(name=/37, inputs=[])
  (/38): BoundParams(name=/38, inputs=[])
  (/39): BoundParams(name=/39, inputs=[])
  (/40): BoundParams(name=/40, inputs=[])
  (/41): BoundParams(name=/41, inputs=[])
  (/42): BoundParams(name=/42, inputs=[])
  (/43): BoundParams(name=/43, inputs=[])
  (/44): BoundParams(name=/44, inputs=[])
  (/45): BoundParams(name=/45, inputs=[])
  (/46): BoundParams(name=/46, inputs=[])
  (/47): BoundParams(name=/47, inputs=[])
  (/48): BoundParams(name=/48, inputs=[])
  (/49): BoundParams(name=/49, inputs=[])
  (/50): BoundParams(name=/50, inputs=[])
  (/51): BoundParams(name=/51, inputs=[])
  (/52): BoundParams(name=/52, inputs=[])
  (/input): BoundConv(name=/input, inputs=[/input.1, /27, /28])
  (/54): BoundRelu(name=/54, inputs=[/input])
  (/input.4): BoundConv(name=/input.4, inputs=[/54, /29, /30])
  (/56): BoundRelu(name=/56, inputs=[/input.4])
  (/57): BoundConv(name=/57, inputs=[/56, /31, /32])
  (/58): BoundConv(name=/58, inputs=[/54, /33, /34])
  (/59): BoundAdd(name=/59, inputs=[/57, /58])
  (/input.8): BoundRelu(name=/input.8, inputs=[/59])
  (/input.12): BoundConv(name=/input.12, inputs=[/input.8, /35, /36])
  (/62): BoundRelu(name=/62, inputs=[/input.12])
  (/63): BoundConv(name=/63, inputs=[/62, /37, /38])
  (/64): BoundAdd(name=/64, inputs=[/63, /input.8])
  (/input.16): BoundRelu(name=/input.16, inputs=[/64])
  (/input.20): BoundConv(name=/input.20, inputs=[/input.16, /39, /40])
  (/67): BoundRelu(name=/67, inputs=[/input.20])
  (/68): BoundConv(name=/68, inputs=[/67, /41, /42])
  (/69): BoundConv(name=/69, inputs=[/input.16, /43, /44])
  (/70): BoundAdd(name=/70, inputs=[/68, /69])
  (/input.24): BoundRelu(name=/input.24, inputs=[/70])
  (/input.28): BoundConv(name=/input.28, inputs=[/input.24, /45, /46])
  (/73): BoundRelu(name=/73, inputs=[/input.28])
  (/74): BoundConv(name=/74, inputs=[/73, /47, /48])
  (/75): BoundAdd(name=/75, inputs=[/74, /input.24])
  (/76): BoundRelu(name=/76, inputs=[/75])
  (/77): BoundFlatten(name=/77, inputs=[/76])
  (/input.32): BoundLinear(name=/input.32, inputs=[/77, /49, /50])
  (/79): BoundRelu(name=/79, inputs=[/input.32])
  (/80): BoundLinear(name=/80, inputs=[/79, /51, /52])
)
Model prediction is: tensor([ -6.16110611,  -5.35189104,  -6.63838196,  -1.86059761,   0.11116534,
        -10.11872673,  -4.05360079,  -1.74366474,  -3.32689190,  -8.15904140,
         -7.46693563,  -5.78805733,  -3.15143585,  -5.00590038,  -4.14910078,
         -2.56400585,  -7.67670774,  -7.34021807,  -4.19427729,  -2.98574591,
        -11.50354290,  -2.86428237,  -6.95179081,  -8.57429600,  -5.86174965,
         -6.12973022,  -1.81921148,  -1.88009489,  -7.23338842,  -2.77960229,
         -6.66013479,  -2.95222306,  -4.44099236,  -2.23306108,  -2.14823055,
         -6.19033194,  -7.01506519,  -3.64295554,  -1.63159895,  -6.60959387,
         -6.24223137,  -5.34258509,  -2.82548904,  -4.65815115,  -1.93024790,
         -1.66022027,  -5.19752359,  -4.90962362,  -3.16080809,  -6.14222050,
         -1.68901014,  -1.35682642,  -4.53342819,  -9.38375664,  -6.84528923,
         -0.98658550,  -2.42015982,  -6.15781975,  -4.54610014,  -3.36491656,
         -7.45315218,  -9.82804394,  -6.81166983,  -2.71696687,  -0.80461359,
         -3.63948178,  -0.40597218,  -4.75543308,  -6.19850063,  -6.96731472,
         -5.63448715,  -6.89007521,  -1.89141941,  -5.16311169,   2.23245358,
         -3.20890164,  -7.58390236,  -2.06751895,  -2.76550293,  -1.95667255,
         -2.20863032,  -3.25515842,  -5.95652390,  -4.48778105,  -7.88440895,
         -3.25094366,  -6.59201813,  -7.73082161,  -5.21276331,  -2.16033602,
         -1.06771088,  -5.50464773,  -5.21620893,  -3.12952518,  -9.58456707,
         -7.41099882,  -4.63919449,  -2.05928183,  -6.47336006,  -2.76289630],
       device='cuda:0')
build_with_refined_bounds batch [0/1]
setting alpha for layer /54 start_node /80 with alignment adjustment
setting alpha for layer /56 start_node /80 with alignment adjustment
setting alpha for layer /input.8 start_node /80 with alignment adjustment
setting alpha for layer /62 start_node /80 with alignment adjustment
setting alpha for layer /input.16 start_node /80 with alignment adjustment
setting alpha for layer /67 start_node /80 with alignment adjustment
setting alpha for layer /input.24 start_node /80 with alignment adjustment
setting alpha for layer /73 start_node /80 with alignment adjustment
setting alpha for layer /76 start_node /80 with alignment adjustment
setting alpha for layer /79 start_node /80 with alignment adjustment
all slope initialized
directly get lb and ub from refined bounds
lA shapes: [torch.Size([1, 1, 64, 15, 15]), torch.Size([1, 1, 128, 8, 8]), torch.Size([1, 1, 128, 8, 8]), torch.Size([1, 1, 128, 8, 8]), torch.Size([1, 1, 128, 8, 8]), torch.Size([1, 1, 128, 4, 4]), torch.Size([1, 1, 128, 4, 4]), torch.Size([1, 1, 128, 4, 4]), torch.Size([1, 1, 128, 4, 4]), torch.Size([1, 1, 100])]
c shape: torch.Size([1, 1, 100])
alpha-CROWN with fixed intermediate bounds: tensor([[-0.00067925]], device='cuda:0') tensor([[inf]], device='cuda:0')
Intermediate layers: /input.32,/75,/input.4,/64,/input.20,/70,/input,/input.28,/input.12,/59,/80
Split layers:
  BoundAdd(name=/59, inputs=[/57, /58]): [(BoundRelu(name=/input.8, inputs=[/59]), 0)]
  BoundConv(name=/input.4, inputs=[/54, /29, /30]): [(BoundRelu(name=/56, inputs=[/input.4]), 0)]
  BoundConv(name=/input.20, inputs=[/input.16, /39, /40]): [(BoundRelu(name=/67, inputs=[/input.20]), 0)]
  BoundConv(name=/input, inputs=[/input.1, /27, /28]): [(BoundRelu(name=/54, inputs=[/input]), 0)]
  BoundConv(name=/input.28, inputs=[/input.24, /45, /46]): [(BoundRelu(name=/73, inputs=[/input.28]), 0)]
  BoundAdd(name=/64, inputs=[/63, /input.8]): [(BoundRelu(name=/input.16, inputs=[/64]), 0)]
  BoundAdd(name=/70, inputs=[/68, /69]): [(BoundRelu(name=/input.24, inputs=[/70]), 0)]
  BoundAdd(name=/75, inputs=[/74, /input.24]): [(BoundRelu(name=/76, inputs=[/75]), 0)]/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.
  "Using experimental implementation that allows 'batch_size > 1'."
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/utils.py:21: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  return value.ndim == 0 or value.shape == torch.Size([1])
/home/zhouxingshi/miniconda3/envs/alpha-beta-crown/lib/python3.7/site-packages/onnx2pytorch/operations/add.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  elif all(x == 1 for x in input[0].shape):

  BoundConv(name=/input.12, inputs=[/input.8, /35, /36]): [(BoundRelu(name=/62, inputs=[/input.12]), 0)]
  BoundLinear(name=/input.32, inputs=[/77, /49, /50]): [(BoundRelu(name=/79, inputs=[/input.32]), 0)]
Keeping slopes for these layers: ['/80']
Keeping slopes for these layers: ['/80']
Node /54 input 0: size torch.Size([64, 15, 15]) unstable 553
Node /56 input 0: size torch.Size([128, 8, 8]) unstable 212
Node /input.8 input 0: size torch.Size([128, 8, 8]) unstable 396
Node /62 input 0: size torch.Size([128, 8, 8]) unstable 41
Node /input.16 input 0: size torch.Size([128, 8, 8]) unstable 325
Node /67 input 0: size torch.Size([128, 4, 4]) unstable 101
Node /input.24 input 0: size torch.Size([128, 4, 4]) unstable 300
Node /73 input 0: size torch.Size([128, 4, 4]) unstable 0
Node /76 input 0: size torch.Size([128, 4, 4]) unstable 143
Node /79 input 0: size torch.Size([100]) unstable 9
-----------------
# of unstable neurons: 2080
-----------------

BaB round 1
batch: 1
Average branched neurons at iteration 1:  1.0000
splitting decisions: 
split level 0: [/input.32, 71] 
split level 1: [/input.32, 49] 
split level 2: [/70, 1466] 
split level 3: [/input.32, 43] 

all verified at 0th iter
pruning_in_iteration open status: False
ratio of positive domain = 16 / 16 = 1.0
pruning-in-iteration extra time: 0.00022029876708984375
Time: prepare 0.0047    beta_bound 0.0370    bound 0.0371    transfer 0.0017    finalize 0.0036    func 0.0471    
Accumulated time: func 0.0471    prepare 0.0064    bound 0.0371    beta_bound 0.0370    transfer 0.0017    finalize 0.0036    
batch bounding time:  0.04726696014404297
length of domains: 0
Time: pickout 0.0018    decision 0.5734    set_bounds 0.0036    solve 0.0473    add 0.0006    
Accumulated time: pickout 0.0018    decision 0.5734    set_bounds 0.0036    solve 0.0473    add 0.0006    
No domains left, verification finished!
Current (lb-rhs): 1.0000000116860974e-07
0 domains visited
Cumulative time: 1.152000904083252

Result: safe in 25.3043 seconds
############# Summary #############
Final verified acc: 100.0% (total 1 examples)
Problem instances count: 1 , total verified (safe/unsat): 1 , total falsified (unsafe/sat): 0 , timeout: 0
mean time for ALL instances (total 1):25.30406276480753, max time: 25.30431580543518
mean time for verified SAFE instances(total 1): 25.30431580543518, max time: 25.30431580543518
safe (total 1), index: [0]
